{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data = pd.read_csv('https://cocl.us/concrete_data')\n",
    "concrete_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    concrete_data.iloc[:, :-1], concrete_data['Strength'], test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train.copy()\n",
    "X_train_scaled = (X_train_scaled - X_train_scaled.mean()) / X_train_scaled.std()\n",
    "\n",
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled = (X_test_scaled - X_test_scaled.mean()) / X_test_scaled.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1559.5238\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1543.7112\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1528.0417\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1512.1356\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1495.9501\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1479.4436\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1462.3202\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1444.7148\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1426.7078\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1408.0381\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1388.7095\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1368.8394\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1348.1572\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1326.9230\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1304.7308\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1282.4526\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1259.3649\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1235.8605\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1211.4303\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1187.3008\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1162.0312\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1136.8531\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1111.4592\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1085.8066\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1060.3303\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1034.2087\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 955us/step - loss: 1008.6982\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 982.8782\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 957.3298\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 1000us/step - loss: 931.6550\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 906.4509\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 881.4279\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 856.7946\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 832.7279\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 808.9175\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 955us/step - loss: 785.9777\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 763.1920\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 740.9627\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 719.5977\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 698.6406\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 678.3346\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 658.9076\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 639.9371\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 621.8337\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 604.4976\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 587.7954\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 572.2318\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 556.8778\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 542.6499\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 528.8474\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 516.0668\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 503.6845\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 492.1168\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 481.1768\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 470.8480\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 461.0889\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 451.9370\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 443.3273\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 435.4095\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 427.7941\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 420.7733\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 414.2957\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 408.0872\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 402.4501\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 397.0759\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 391.9685\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 387.1556\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 383.0577\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 378.6590\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 374.9182\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 371.4960\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 368.1766\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 365.0706\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 362.2621\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 359.5747\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 356.9476\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 354.7027\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 352.6409\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 350.5234\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 348.6584\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 346.8808\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 345.2154\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 343.6524\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 955us/step - loss: 342.1545\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 340.7672\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 339.4659\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 338.2990\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 910us/step - loss: 337.1496\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 1000us/step - loss: 336.1430\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 335.1230\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 334.0894\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 333.2664\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 332.2928\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 331.4839\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 330.6826\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 329.9965\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 329.1419\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 328.4507\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 327.7831\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 327.1411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d611120dc8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_shape=(8,), activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 331.4328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "331.4328308105469"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 331.43279918652223 STD: 0.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "mean_square_error = mean_squared_error(y_test, y_pred)\n",
    "mean = np.mean(mean_square_error)\n",
    "standard_deviation = np.std(mean_square_error)\n",
    "print(\"Mean: \" + str(mean), \"STD: \" + str(standard_deviation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 1: 112.32266235351562\n",
      "MSE 2: 89.1823959350586\n",
      "MSE 3: 54.58342361450195\n",
      "MSE 4: 49.40469741821289\n",
      "MSE 5: 57.77333068847656\n",
      "MSE 6: 55.09471130371094\n",
      "MSE 7: 64.33087158203125\n",
      "MSE 8: 42.884239196777344\n",
      "MSE 9: 48.49934768676758\n",
      "MSE 10: 51.88378143310547\n",
      "MSE 11: 45.814903259277344\n",
      "MSE 12: 47.26670455932617\n",
      "MSE 13: 50.10564422607422\n",
      "MSE 14: 47.84538650512695\n",
      "MSE 15: 44.35374450683594\n",
      "MSE 16: 39.48094177246094\n",
      "MSE 17: 48.78947067260742\n",
      "MSE 18: 46.88994216918945\n",
      "MSE 19: 47.15180206298828\n",
      "MSE 20: 42.76715087890625\n",
      "MSE 21: 43.40544891357422\n",
      "MSE 22: 46.9803581237793\n",
      "MSE 23: 38.068931579589844\n",
      "MSE 24: 41.17778015136719\n",
      "MSE 25: 48.220584869384766\n",
      "MSE 26: 41.38252639770508\n",
      "MSE 27: 40.311607360839844\n",
      "MSE 28: 41.16737747192383\n",
      "MSE 29: 48.798561096191406\n",
      "MSE 30: 48.59563446044922\n",
      "MSE 31: 43.128719329833984\n",
      "MSE 32: 39.075347900390625\n",
      "MSE 33: 40.068912506103516\n",
      "MSE 34: 42.95033264160156\n",
      "MSE 35: 43.85302734375\n",
      "MSE 36: 51.265907287597656\n",
      "MSE 37: 39.31422805786133\n",
      "MSE 38: 49.260074615478516\n",
      "MSE 39: 42.152923583984375\n",
      "MSE 40: 39.40817642211914\n",
      "MSE 41: 49.79734420776367\n",
      "MSE 42: 43.932640075683594\n",
      "MSE 43: 47.96622848510742\n",
      "MSE 44: 46.25485610961914\n",
      "MSE 45: 46.38239669799805\n",
      "MSE 46: 49.42648696899414\n",
      "MSE 47: 44.3636589050293\n",
      "MSE 48: 44.242008209228516\n",
      "MSE 49: 39.235252380371094\n",
      "MSE 50: 45.78435134887695\n",
      "\n",
      "\n",
      "Below is the mean and standard deviation of 50 mean squared errors with normalized data. Total number of epochs for each training is: 100\n",
      "\n",
      "Mean: 48.247935659316425\n",
      "Standard Deviation: 12.095009241493253\n"
     ]
    }
   ],
   "source": [
    "total_mean_squared_errors = 50\n",
    "epochs = 100\n",
    "mean_squared_errors = []\n",
    "for i in range(0, total_mean_squared_errors):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        concrete_data.iloc[:, :-1], concrete_data['Strength'], test_size=0.3, random_state=i)\n",
    "    X_train = (X_train - X_train.mean()) / X_train.std()\n",
    "    X_test = (X_test - X_test.mean()) / X_test.std()\n",
    "    model.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
    "    MSE = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"MSE \"+str(i+1)+\": \"+str(MSE))\n",
    "    y_pred = model.predict(X_test)\n",
    "    mean_square_error = mean_squared_error(y_test, y_pred)\n",
    "    mean_squared_errors.append(mean_square_error)\n",
    "\n",
    "mean_squared_errors = np.array(mean_squared_errors)\n",
    "mean = np.mean(mean_squared_errors)\n",
    "standard_deviation = np.std(mean_squared_errors)\n",
    "\n",
    "print('\\n')\n",
    "print(\"Below is the mean and standard deviation of \" + str(total_mean_squared_errors) +\n",
    "      \" mean squared errors with normalized data. Total number of epochs for each training is: \" + str(epochs) + \"\\n\")\n",
    "print(\"Mean: \"+str(mean))\n",
    "print(\"Standard Deviation: \"+str(standard_deviation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f04500d8b91e362b0082c4fdd322d5d5d9540d13200024b86d78e7daf6d8bf4b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
