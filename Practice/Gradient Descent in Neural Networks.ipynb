{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "      <th>bought_insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  affordibility  bought_insurance\n",
       "0   22              1                 0\n",
       "1   25              0                 0\n",
       "2   47              1                 1\n",
       "3   52              0                 0\n",
       "4   46              1                 1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('insurance_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,:-1], df.iloc[:,-1], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scale the data inorder to increase the performance of the model. <br>\n",
    "So, we convert the age in the range of 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train.copy()\n",
    "X_train_scaled['age'] = X_train_scaled['age']/100\n",
    "\n",
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled['age'] = X_test_scaled['age']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  affordibility\n",
       "24  0.50              1\n",
       "13  0.29              0\n",
       "20  0.21              1\n",
       "25  0.54              1\n",
       "16  0.25              0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7960 - accuracy: 0.4091\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7955 - accuracy: 0.4091\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7950 - accuracy: 0.4091\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7944 - accuracy: 0.4091\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7939 - accuracy: 0.4091\n",
      "Epoch 6/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7934 - accuracy: 0.4091\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7929 - accuracy: 0.4091\n",
      "Epoch 8/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7923 - accuracy: 0.4091\n",
      "Epoch 9/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7918 - accuracy: 0.4091\n",
      "Epoch 10/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7913 - accuracy: 0.4091\n",
      "Epoch 11/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7908 - accuracy: 0.4091\n",
      "Epoch 12/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7902 - accuracy: 0.4091\n",
      "Epoch 13/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7897 - accuracy: 0.4091\n",
      "Epoch 14/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7892 - accuracy: 0.4091\n",
      "Epoch 15/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7887 - accuracy: 0.4091\n",
      "Epoch 16/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7882 - accuracy: 0.4091\n",
      "Epoch 17/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7876 - accuracy: 0.4091\n",
      "Epoch 18/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7871 - accuracy: 0.4091\n",
      "Epoch 19/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7866 - accuracy: 0.4091\n",
      "Epoch 20/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7861 - accuracy: 0.4091\n",
      "Epoch 21/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7856 - accuracy: 0.4091\n",
      "Epoch 22/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7851 - accuracy: 0.4091\n",
      "Epoch 23/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7846 - accuracy: 0.4091\n",
      "Epoch 24/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7841 - accuracy: 0.4091\n",
      "Epoch 25/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7835 - accuracy: 0.4091\n",
      "Epoch 26/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7830 - accuracy: 0.4091\n",
      "Epoch 27/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7825 - accuracy: 0.4091\n",
      "Epoch 28/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7820 - accuracy: 0.4091\n",
      "Epoch 29/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7815 - accuracy: 0.4091\n",
      "Epoch 30/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7810 - accuracy: 0.4091\n",
      "Epoch 31/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7805 - accuracy: 0.4091\n",
      "Epoch 32/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7800 - accuracy: 0.4091\n",
      "Epoch 33/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7795 - accuracy: 0.4091\n",
      "Epoch 34/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7790 - accuracy: 0.4091\n",
      "Epoch 35/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7785 - accuracy: 0.4091\n",
      "Epoch 36/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7780 - accuracy: 0.4091\n",
      "Epoch 37/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7775 - accuracy: 0.4091\n",
      "Epoch 38/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7770 - accuracy: 0.4091\n",
      "Epoch 39/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7765 - accuracy: 0.4091\n",
      "Epoch 40/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7760 - accuracy: 0.4091\n",
      "Epoch 41/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7755 - accuracy: 0.4091\n",
      "Epoch 42/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7750 - accuracy: 0.4091\n",
      "Epoch 43/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7745 - accuracy: 0.4091\n",
      "Epoch 44/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7740 - accuracy: 0.4091\n",
      "Epoch 45/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7736 - accuracy: 0.4091\n",
      "Epoch 46/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7731 - accuracy: 0.4091\n",
      "Epoch 47/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7726 - accuracy: 0.4091\n",
      "Epoch 48/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7721 - accuracy: 0.4091\n",
      "Epoch 49/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7716 - accuracy: 0.4091\n",
      "Epoch 50/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7711 - accuracy: 0.4091\n",
      "Epoch 51/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7706 - accuracy: 0.4091\n",
      "Epoch 52/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7702 - accuracy: 0.4091\n",
      "Epoch 53/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7697 - accuracy: 0.4091\n",
      "Epoch 54/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7692 - accuracy: 0.4091\n",
      "Epoch 55/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7687 - accuracy: 0.4091\n",
      "Epoch 56/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7682 - accuracy: 0.4091\n",
      "Epoch 57/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7678 - accuracy: 0.4091\n",
      "Epoch 58/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7673 - accuracy: 0.4091\n",
      "Epoch 59/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7668 - accuracy: 0.4091\n",
      "Epoch 60/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7663 - accuracy: 0.4091\n",
      "Epoch 61/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7659 - accuracy: 0.4091\n",
      "Epoch 62/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7654 - accuracy: 0.4091\n",
      "Epoch 63/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7649 - accuracy: 0.4091\n",
      "Epoch 64/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7645 - accuracy: 0.4091\n",
      "Epoch 65/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7640 - accuracy: 0.4091\n",
      "Epoch 66/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7635 - accuracy: 0.4091\n",
      "Epoch 67/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7630 - accuracy: 0.4091\n",
      "Epoch 68/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7626 - accuracy: 0.4091\n",
      "Epoch 69/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7621 - accuracy: 0.4091\n",
      "Epoch 70/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7617 - accuracy: 0.4091\n",
      "Epoch 71/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7612 - accuracy: 0.4091\n",
      "Epoch 72/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7607 - accuracy: 0.4091\n",
      "Epoch 73/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7603 - accuracy: 0.4091\n",
      "Epoch 74/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7598 - accuracy: 0.4091\n",
      "Epoch 75/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7594 - accuracy: 0.4091\n",
      "Epoch 76/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7589 - accuracy: 0.4091\n",
      "Epoch 77/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7584 - accuracy: 0.4091\n",
      "Epoch 78/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7580 - accuracy: 0.4091\n",
      "Epoch 79/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7575 - accuracy: 0.4091\n",
      "Epoch 80/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7571 - accuracy: 0.4091\n",
      "Epoch 81/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7566 - accuracy: 0.4091\n",
      "Epoch 82/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7562 - accuracy: 0.4091\n",
      "Epoch 83/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7557 - accuracy: 0.4091\n",
      "Epoch 84/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7553 - accuracy: 0.4091\n",
      "Epoch 85/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7548 - accuracy: 0.4091\n",
      "Epoch 86/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7544 - accuracy: 0.4091\n",
      "Epoch 87/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7540 - accuracy: 0.4091\n",
      "Epoch 88/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7535 - accuracy: 0.4091\n",
      "Epoch 89/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7531 - accuracy: 0.4091\n",
      "Epoch 90/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7526 - accuracy: 0.4091\n",
      "Epoch 91/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7522 - accuracy: 0.4091\n",
      "Epoch 92/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7517 - accuracy: 0.4091\n",
      "Epoch 93/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7513 - accuracy: 0.4091\n",
      "Epoch 94/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7509 - accuracy: 0.4091\n",
      "Epoch 95/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7504 - accuracy: 0.4091\n",
      "Epoch 96/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7500 - accuracy: 0.4091\n",
      "Epoch 97/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7496 - accuracy: 0.4091\n",
      "Epoch 98/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7491 - accuracy: 0.4091\n",
      "Epoch 99/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7487 - accuracy: 0.4091\n",
      "Epoch 100/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7483 - accuracy: 0.4091\n",
      "Epoch 101/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7478 - accuracy: 0.4091\n",
      "Epoch 102/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7474 - accuracy: 0.4091\n",
      "Epoch 103/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7470 - accuracy: 0.4091\n",
      "Epoch 104/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7466 - accuracy: 0.4091\n",
      "Epoch 105/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7461 - accuracy: 0.4091\n",
      "Epoch 106/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7457 - accuracy: 0.4091\n",
      "Epoch 107/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7453 - accuracy: 0.4091\n",
      "Epoch 108/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7449 - accuracy: 0.4091\n",
      "Epoch 109/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7444 - accuracy: 0.4091\n",
      "Epoch 110/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7440 - accuracy: 0.4091\n",
      "Epoch 111/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7436 - accuracy: 0.4091\n",
      "Epoch 112/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7432 - accuracy: 0.4091\n",
      "Epoch 113/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7428 - accuracy: 0.4091\n",
      "Epoch 114/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7424 - accuracy: 0.4091\n",
      "Epoch 115/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7419 - accuracy: 0.4091\n",
      "Epoch 116/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7415 - accuracy: 0.4091\n",
      "Epoch 117/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7411 - accuracy: 0.4091\n",
      "Epoch 118/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7407 - accuracy: 0.4091\n",
      "Epoch 119/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7403 - accuracy: 0.4091\n",
      "Epoch 120/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7399 - accuracy: 0.4091\n",
      "Epoch 121/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.4091\n",
      "Epoch 122/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.4091\n",
      "Epoch 123/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.4091\n",
      "Epoch 124/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7383 - accuracy: 0.4091\n",
      "Epoch 125/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.4091\n",
      "Epoch 126/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.4091\n",
      "Epoch 127/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.4091\n",
      "Epoch 128/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7366 - accuracy: 0.4091\n",
      "Epoch 129/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7362 - accuracy: 0.4091\n",
      "Epoch 130/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7359 - accuracy: 0.4091\n",
      "Epoch 131/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.4091\n",
      "Epoch 132/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.4091\n",
      "Epoch 133/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7347 - accuracy: 0.4091\n",
      "Epoch 134/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7343 - accuracy: 0.4091\n",
      "Epoch 135/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7339 - accuracy: 0.4091\n",
      "Epoch 136/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7335 - accuracy: 0.4091\n",
      "Epoch 137/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7331 - accuracy: 0.4091\n",
      "Epoch 138/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7327 - accuracy: 0.4091\n",
      "Epoch 139/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7323 - accuracy: 0.4091\n",
      "Epoch 140/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7319 - accuracy: 0.4091\n",
      "Epoch 141/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7315 - accuracy: 0.4091\n",
      "Epoch 142/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7311 - accuracy: 0.4091\n",
      "Epoch 143/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7308 - accuracy: 0.4091\n",
      "Epoch 144/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7304 - accuracy: 0.4091\n",
      "Epoch 145/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7300 - accuracy: 0.4091\n",
      "Epoch 146/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7296 - accuracy: 0.4091\n",
      "Epoch 147/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7292 - accuracy: 0.4091\n",
      "Epoch 148/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7288 - accuracy: 0.4091\n",
      "Epoch 149/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7285 - accuracy: 0.4091\n",
      "Epoch 150/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7281 - accuracy: 0.4091\n",
      "Epoch 151/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7277 - accuracy: 0.4091\n",
      "Epoch 152/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7273 - accuracy: 0.4091\n",
      "Epoch 153/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7270 - accuracy: 0.4091\n",
      "Epoch 154/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7266 - accuracy: 0.4091\n",
      "Epoch 155/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7262 - accuracy: 0.4091\n",
      "Epoch 156/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7258 - accuracy: 0.4091\n",
      "Epoch 157/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7255 - accuracy: 0.4091\n",
      "Epoch 158/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7251 - accuracy: 0.4091\n",
      "Epoch 159/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7247 - accuracy: 0.4091\n",
      "Epoch 160/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7244 - accuracy: 0.4091\n",
      "Epoch 161/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7240 - accuracy: 0.4091\n",
      "Epoch 162/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7236 - accuracy: 0.4091\n",
      "Epoch 163/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7233 - accuracy: 0.4091\n",
      "Epoch 164/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7229 - accuracy: 0.4091\n",
      "Epoch 165/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7225 - accuracy: 0.4091\n",
      "Epoch 166/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7222 - accuracy: 0.4091\n",
      "Epoch 167/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7218 - accuracy: 0.4091\n",
      "Epoch 168/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7215 - accuracy: 0.4091\n",
      "Epoch 169/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7211 - accuracy: 0.4545\n",
      "Epoch 170/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7207 - accuracy: 0.4545\n",
      "Epoch 171/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7204 - accuracy: 0.4545\n",
      "Epoch 172/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7200 - accuracy: 0.4545\n",
      "Epoch 173/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7197 - accuracy: 0.4545\n",
      "Epoch 174/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7193 - accuracy: 0.4545\n",
      "Epoch 175/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7190 - accuracy: 0.4545\n",
      "Epoch 176/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7186 - accuracy: 0.4545\n",
      "Epoch 177/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7183 - accuracy: 0.4545\n",
      "Epoch 178/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7179 - accuracy: 0.4545\n",
      "Epoch 179/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7176 - accuracy: 0.4545\n",
      "Epoch 180/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7172 - accuracy: 0.4545\n",
      "Epoch 181/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7169 - accuracy: 0.4545\n",
      "Epoch 182/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7165 - accuracy: 0.4545\n",
      "Epoch 183/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7162 - accuracy: 0.4545\n",
      "Epoch 184/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7158 - accuracy: 0.4545\n",
      "Epoch 185/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7155 - accuracy: 0.4545\n",
      "Epoch 186/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7152 - accuracy: 0.4545\n",
      "Epoch 187/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7148 - accuracy: 0.4545\n",
      "Epoch 188/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7145 - accuracy: 0.4545\n",
      "Epoch 189/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7141 - accuracy: 0.4545\n",
      "Epoch 190/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7138 - accuracy: 0.4545\n",
      "Epoch 191/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7135 - accuracy: 0.4545\n",
      "Epoch 192/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7131 - accuracy: 0.4545\n",
      "Epoch 193/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7128 - accuracy: 0.4545\n",
      "Epoch 194/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7125 - accuracy: 0.4545\n",
      "Epoch 195/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7121 - accuracy: 0.4545\n",
      "Epoch 196/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7118 - accuracy: 0.4545\n",
      "Epoch 197/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7115 - accuracy: 0.4545\n",
      "Epoch 198/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7111 - accuracy: 0.4545\n",
      "Epoch 199/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7108 - accuracy: 0.4545\n",
      "Epoch 200/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7105 - accuracy: 0.4545\n",
      "Epoch 201/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7101 - accuracy: 0.4545\n",
      "Epoch 202/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7098 - accuracy: 0.4545\n",
      "Epoch 203/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7095 - accuracy: 0.4545\n",
      "Epoch 204/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7092 - accuracy: 0.4545\n",
      "Epoch 205/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7088 - accuracy: 0.4545\n",
      "Epoch 206/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7085 - accuracy: 0.4545\n",
      "Epoch 207/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7082 - accuracy: 0.4545\n",
      "Epoch 208/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7079 - accuracy: 0.4545\n",
      "Epoch 209/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7076 - accuracy: 0.4545\n",
      "Epoch 210/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7072 - accuracy: 0.4545\n",
      "Epoch 211/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7069 - accuracy: 0.4545\n",
      "Epoch 212/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7066 - accuracy: 0.4545\n",
      "Epoch 213/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7063 - accuracy: 0.4545\n",
      "Epoch 214/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7060 - accuracy: 0.4545\n",
      "Epoch 215/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7057 - accuracy: 0.4545\n",
      "Epoch 216/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7053 - accuracy: 0.4545\n",
      "Epoch 217/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7050 - accuracy: 0.4545\n",
      "Epoch 218/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7047 - accuracy: 0.4545\n",
      "Epoch 219/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7044 - accuracy: 0.4545\n",
      "Epoch 220/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7041 - accuracy: 0.4545\n",
      "Epoch 221/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7038 - accuracy: 0.4545\n",
      "Epoch 222/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7035 - accuracy: 0.4545\n",
      "Epoch 223/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7032 - accuracy: 0.4545\n",
      "Epoch 224/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7029 - accuracy: 0.5000\n",
      "Epoch 225/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7026 - accuracy: 0.5000\n",
      "Epoch 226/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7023 - accuracy: 0.5000\n",
      "Epoch 227/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7020 - accuracy: 0.5000\n",
      "Epoch 228/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7017 - accuracy: 0.5000\n",
      "Epoch 229/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7014 - accuracy: 0.5000\n",
      "Epoch 230/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7011 - accuracy: 0.5000\n",
      "Epoch 231/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7008 - accuracy: 0.5455\n",
      "Epoch 232/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7005 - accuracy: 0.5455\n",
      "Epoch 233/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7002 - accuracy: 0.5455\n",
      "Epoch 234/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6999 - accuracy: 0.5455\n",
      "Epoch 235/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6996 - accuracy: 0.5455\n",
      "Epoch 236/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6993 - accuracy: 0.5455\n",
      "Epoch 237/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6990 - accuracy: 0.5455\n",
      "Epoch 238/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6987 - accuracy: 0.5455\n",
      "Epoch 239/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.5455\n",
      "Epoch 240/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.5455\n",
      "Epoch 241/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6978 - accuracy: 0.5455\n",
      "Epoch 242/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6975 - accuracy: 0.5455\n",
      "Epoch 243/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6973 - accuracy: 0.5455\n",
      "Epoch 244/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6970 - accuracy: 0.5455\n",
      "Epoch 245/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6967 - accuracy: 0.5455\n",
      "Epoch 246/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6964 - accuracy: 0.5909\n",
      "Epoch 247/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.5909\n",
      "Epoch 248/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6958 - accuracy: 0.5909\n",
      "Epoch 249/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.5909\n",
      "Epoch 250/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.5909\n",
      "Epoch 251/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6950 - accuracy: 0.5909\n",
      "Epoch 252/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.5909\n",
      "Epoch 253/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6944 - accuracy: 0.5909\n",
      "Epoch 254/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6941 - accuracy: 0.5909\n",
      "Epoch 255/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5909\n",
      "Epoch 256/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5909\n",
      "Epoch 257/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5909\n",
      "Epoch 258/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5909\n",
      "Epoch 259/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5909\n",
      "Epoch 260/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5909\n",
      "Epoch 261/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5909\n",
      "Epoch 262/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5909\n",
      "Epoch 263/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6917 - accuracy: 0.5909\n",
      "Epoch 264/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.5909\n",
      "Epoch 265/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6911 - accuracy: 0.5909\n",
      "Epoch 266/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6909 - accuracy: 0.5909\n",
      "Epoch 267/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6906 - accuracy: 0.5909\n",
      "Epoch 268/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.5909\n",
      "Epoch 269/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5909\n",
      "Epoch 270/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.5909\n",
      "Epoch 271/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6896 - accuracy: 0.5909\n",
      "Epoch 272/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6893 - accuracy: 0.5909\n",
      "Epoch 273/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6890 - accuracy: 0.5909\n",
      "Epoch 274/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6888 - accuracy: 0.5909\n",
      "Epoch 275/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5909\n",
      "Epoch 276/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5909\n",
      "Epoch 277/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5909\n",
      "Epoch 278/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6877 - accuracy: 0.5909\n",
      "Epoch 279/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.5909\n",
      "Epoch 280/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6872 - accuracy: 0.5909\n",
      "Epoch 281/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.5909\n",
      "Epoch 282/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6867 - accuracy: 0.5909\n",
      "Epoch 283/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6865 - accuracy: 0.5909\n",
      "Epoch 284/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6862 - accuracy: 0.5909\n",
      "Epoch 285/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6860 - accuracy: 0.5909\n",
      "Epoch 286/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6857 - accuracy: 0.5909\n",
      "Epoch 287/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.5909\n",
      "Epoch 288/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6852 - accuracy: 0.5909\n",
      "Epoch 289/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6850 - accuracy: 0.5909\n",
      "Epoch 290/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6847 - accuracy: 0.5909\n",
      "Epoch 291/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6845 - accuracy: 0.5909\n",
      "Epoch 292/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.5909\n",
      "Epoch 293/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6840 - accuracy: 0.5909\n",
      "Epoch 294/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6837 - accuracy: 0.5909\n",
      "Epoch 295/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6835 - accuracy: 0.5909\n",
      "Epoch 296/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6833 - accuracy: 0.5909\n",
      "Epoch 297/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6830 - accuracy: 0.5909\n",
      "Epoch 298/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6828 - accuracy: 0.5909\n",
      "Epoch 299/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6825 - accuracy: 0.5909\n",
      "Epoch 300/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6823 - accuracy: 0.5909\n",
      "Epoch 301/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6821 - accuracy: 0.5909\n",
      "Epoch 302/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6818 - accuracy: 0.5909\n",
      "Epoch 303/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6816 - accuracy: 0.5909\n",
      "Epoch 304/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.5909\n",
      "Epoch 305/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.5909\n",
      "Epoch 306/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6809 - accuracy: 0.5909\n",
      "Epoch 307/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6806 - accuracy: 0.5909\n",
      "Epoch 308/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6804 - accuracy: 0.5909\n",
      "Epoch 309/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6802 - accuracy: 0.5909\n",
      "Epoch 310/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6800 - accuracy: 0.5909\n",
      "Epoch 311/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6797 - accuracy: 0.5909\n",
      "Epoch 312/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6795 - accuracy: 0.5909\n",
      "Epoch 313/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.5909\n",
      "Epoch 314/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6790 - accuracy: 0.5909\n",
      "Epoch 315/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.5909\n",
      "Epoch 316/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.5909\n",
      "Epoch 317/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6784 - accuracy: 0.5909\n",
      "Epoch 318/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6781 - accuracy: 0.5909\n",
      "Epoch 319/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.5909\n",
      "Epoch 320/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6777 - accuracy: 0.5909\n",
      "Epoch 321/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6775 - accuracy: 0.5909\n",
      "Epoch 322/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6772 - accuracy: 0.5909\n",
      "Epoch 323/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6770 - accuracy: 0.5909\n",
      "Epoch 324/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6768 - accuracy: 0.5909\n",
      "Epoch 325/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6766 - accuracy: 0.5909\n",
      "Epoch 326/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6764 - accuracy: 0.5909\n",
      "Epoch 327/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.5909\n",
      "Epoch 328/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6759 - accuracy: 0.5909\n",
      "Epoch 329/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6757 - accuracy: 0.5909\n",
      "Epoch 330/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6755 - accuracy: 0.5909\n",
      "Epoch 331/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6753 - accuracy: 0.5909\n",
      "Epoch 332/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6751 - accuracy: 0.5909\n",
      "Epoch 333/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6749 - accuracy: 0.5909\n",
      "Epoch 334/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6747 - accuracy: 0.5909\n",
      "Epoch 335/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6744 - accuracy: 0.5909\n",
      "Epoch 336/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6742 - accuracy: 0.5909\n",
      "Epoch 337/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.5909\n",
      "Epoch 338/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6738 - accuracy: 0.5909\n",
      "Epoch 339/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.5909\n",
      "Epoch 340/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6734 - accuracy: 0.5909\n",
      "Epoch 341/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6732 - accuracy: 0.5909\n",
      "Epoch 342/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6730 - accuracy: 0.5909\n",
      "Epoch 343/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 0.5909\n",
      "Epoch 344/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6726 - accuracy: 0.5909\n",
      "Epoch 345/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.5909\n",
      "Epoch 346/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6722 - accuracy: 0.5909\n",
      "Epoch 347/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6720 - accuracy: 0.5909\n",
      "Epoch 348/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6718 - accuracy: 0.5909\n",
      "Epoch 349/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6716 - accuracy: 0.5909\n",
      "Epoch 350/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.5909\n",
      "Epoch 351/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.5909\n",
      "Epoch 352/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6710 - accuracy: 0.5909\n",
      "Epoch 353/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6708 - accuracy: 0.5909\n",
      "Epoch 354/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6706 - accuracy: 0.5909\n",
      "Epoch 355/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6704 - accuracy: 0.5909\n",
      "Epoch 356/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6702 - accuracy: 0.5909\n",
      "Epoch 357/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6700 - accuracy: 0.5909\n",
      "Epoch 358/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.5909\n",
      "Epoch 359/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6696 - accuracy: 0.5909\n",
      "Epoch 360/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.5909\n",
      "Epoch 361/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.5909\n",
      "Epoch 362/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.5909\n",
      "Epoch 363/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6688 - accuracy: 0.5909\n",
      "Epoch 364/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6686 - accuracy: 0.5909\n",
      "Epoch 365/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6684 - accuracy: 0.5909\n",
      "Epoch 366/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6682 - accuracy: 0.5909\n",
      "Epoch 367/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6681 - accuracy: 0.5909\n",
      "Epoch 368/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6679 - accuracy: 0.5909\n",
      "Epoch 369/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6677 - accuracy: 0.5909\n",
      "Epoch 370/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6675 - accuracy: 0.5909\n",
      "Epoch 371/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6673 - accuracy: 0.5909\n",
      "Epoch 372/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.5909\n",
      "Epoch 373/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6669 - accuracy: 0.5909\n",
      "Epoch 374/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6668 - accuracy: 0.5909\n",
      "Epoch 375/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6666 - accuracy: 0.5909\n",
      "Epoch 376/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6664 - accuracy: 0.5909\n",
      "Epoch 377/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6662 - accuracy: 0.5909\n",
      "Epoch 378/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6660 - accuracy: 0.5909\n",
      "Epoch 379/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6658 - accuracy: 0.5909\n",
      "Epoch 380/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6657 - accuracy: 0.5909\n",
      "Epoch 381/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6655 - accuracy: 0.5909\n",
      "Epoch 382/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6653 - accuracy: 0.5909\n",
      "Epoch 383/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6651 - accuracy: 0.5909\n",
      "Epoch 384/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6650 - accuracy: 0.5909\n",
      "Epoch 385/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6648 - accuracy: 0.5909\n",
      "Epoch 386/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6646 - accuracy: 0.5909\n",
      "Epoch 387/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6644 - accuracy: 0.5909\n",
      "Epoch 388/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6643 - accuracy: 0.5909\n",
      "Epoch 389/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6641 - accuracy: 0.5909\n",
      "Epoch 390/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6639 - accuracy: 0.5909\n",
      "Epoch 391/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6637 - accuracy: 0.5909\n",
      "Epoch 392/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6636 - accuracy: 0.5909\n",
      "Epoch 393/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.5909\n",
      "Epoch 394/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.5909\n",
      "Epoch 395/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 0.5909\n",
      "Epoch 396/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6629 - accuracy: 0.5909\n",
      "Epoch 397/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6627 - accuracy: 0.5909\n",
      "Epoch 398/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6625 - accuracy: 0.5909\n",
      "Epoch 399/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6624 - accuracy: 0.5909\n",
      "Epoch 400/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6622 - accuracy: 0.5909\n",
      "Epoch 401/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6620 - accuracy: 0.5909\n",
      "Epoch 402/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.5909\n",
      "Epoch 403/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.5909\n",
      "Epoch 404/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6615 - accuracy: 0.5909\n",
      "Epoch 405/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6614 - accuracy: 0.5909\n",
      "Epoch 406/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.5909\n",
      "Epoch 407/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.5909\n",
      "Epoch 408/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.5909\n",
      "Epoch 409/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6607 - accuracy: 0.5909\n",
      "Epoch 410/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.5909\n",
      "Epoch 411/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6604 - accuracy: 0.5909\n",
      "Epoch 412/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6603 - accuracy: 0.5909\n",
      "Epoch 413/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6601 - accuracy: 0.5909\n",
      "Epoch 414/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6599 - accuracy: 0.5909\n",
      "Epoch 415/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.5909\n",
      "Epoch 416/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6596 - accuracy: 0.6364\n",
      "Epoch 417/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6595 - accuracy: 0.6364\n",
      "Epoch 418/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.6364\n",
      "Epoch 419/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6592 - accuracy: 0.6364\n",
      "Epoch 420/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6590 - accuracy: 0.6364\n",
      "Epoch 421/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6588 - accuracy: 0.6364\n",
      "Epoch 422/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6587 - accuracy: 0.6364\n",
      "Epoch 423/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6585 - accuracy: 0.6364\n",
      "Epoch 424/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6584 - accuracy: 0.6364\n",
      "Epoch 425/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6582 - accuracy: 0.6364\n",
      "Epoch 426/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6581 - accuracy: 0.6364\n",
      "Epoch 427/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.6364\n",
      "Epoch 428/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.6364\n",
      "Epoch 429/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6576 - accuracy: 0.6364\n",
      "Epoch 430/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6575 - accuracy: 0.6364\n",
      "Epoch 431/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.6364\n",
      "Epoch 432/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.6364\n",
      "Epoch 433/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6570 - accuracy: 0.6364\n",
      "Epoch 434/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6569 - accuracy: 0.6364\n",
      "Epoch 435/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6567 - accuracy: 0.6364\n",
      "Epoch 436/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6566 - accuracy: 0.6364\n",
      "Epoch 437/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6564 - accuracy: 0.6364\n",
      "Epoch 438/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6563 - accuracy: 0.6364\n",
      "Epoch 439/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.6818\n",
      "Epoch 440/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.6818\n",
      "Epoch 441/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.6818\n",
      "Epoch 442/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6557 - accuracy: 0.6818\n",
      "Epoch 443/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6556 - accuracy: 0.6818\n",
      "Epoch 444/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6554 - accuracy: 0.6818\n",
      "Epoch 445/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.6818\n",
      "Epoch 446/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6552 - accuracy: 0.6818\n",
      "Epoch 447/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.6818\n",
      "Epoch 448/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6549 - accuracy: 0.6818\n",
      "Epoch 449/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6547 - accuracy: 0.6818\n",
      "Epoch 450/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6546 - accuracy: 0.6818\n",
      "Epoch 451/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6545 - accuracy: 0.6818\n",
      "Epoch 452/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6543 - accuracy: 0.6818\n",
      "Epoch 453/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6542 - accuracy: 0.6818\n",
      "Epoch 454/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.6818\n",
      "Epoch 455/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.6818\n",
      "Epoch 456/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6538 - accuracy: 0.6818\n",
      "Epoch 457/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.6818\n",
      "Epoch 458/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.6818\n",
      "Epoch 459/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6534 - accuracy: 0.6818\n",
      "Epoch 460/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.6818\n",
      "Epoch 461/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6531 - accuracy: 0.6818\n",
      "Epoch 462/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.6818\n",
      "Epoch 463/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6529 - accuracy: 0.6818\n",
      "Epoch 464/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6527 - accuracy: 0.6818\n",
      "Epoch 465/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6526 - accuracy: 0.6818\n",
      "Epoch 466/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.6818\n",
      "Epoch 467/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6523 - accuracy: 0.6818\n",
      "Epoch 468/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.6818\n",
      "Epoch 469/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6521 - accuracy: 0.6818\n",
      "Epoch 470/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6519 - accuracy: 0.6818\n",
      "Epoch 471/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6518 - accuracy: 0.6818\n",
      "Epoch 472/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6517 - accuracy: 0.6818\n",
      "Epoch 473/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.6818\n",
      "Epoch 474/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.6818\n",
      "Epoch 475/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.6818\n",
      "Epoch 476/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.6818\n",
      "Epoch 477/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6511 - accuracy: 0.6818\n",
      "Epoch 478/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6509 - accuracy: 0.6364\n",
      "Epoch 479/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6508 - accuracy: 0.6364\n",
      "Epoch 480/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6507 - accuracy: 0.6364\n",
      "Epoch 481/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6506 - accuracy: 0.6364\n",
      "Epoch 482/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6504 - accuracy: 0.6364\n",
      "Epoch 483/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.6364\n",
      "Epoch 484/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6502 - accuracy: 0.6364\n",
      "Epoch 485/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6501 - accuracy: 0.6364\n",
      "Epoch 486/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6500 - accuracy: 0.6364\n",
      "Epoch 487/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6498 - accuracy: 0.6364\n",
      "Epoch 488/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6497 - accuracy: 0.6364\n",
      "Epoch 489/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6364\n",
      "Epoch 490/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6495 - accuracy: 0.6364\n",
      "Epoch 491/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6494 - accuracy: 0.6364\n",
      "Epoch 492/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.6364\n",
      "Epoch 493/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.6364\n",
      "Epoch 494/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6490 - accuracy: 0.6364\n",
      "Epoch 495/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6489 - accuracy: 0.6364\n",
      "Epoch 496/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6488 - accuracy: 0.6364\n",
      "Epoch 497/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6487 - accuracy: 0.6364\n",
      "Epoch 498/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6485 - accuracy: 0.6364\n",
      "Epoch 499/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6484 - accuracy: 0.6364\n",
      "Epoch 500/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6483 - accuracy: 0.6364\n",
      "Epoch 501/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6482 - accuracy: 0.6364\n",
      "Epoch 502/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6481 - accuracy: 0.6364\n",
      "Epoch 503/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6480 - accuracy: 0.6364\n",
      "Epoch 504/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6479 - accuracy: 0.6364\n",
      "Epoch 505/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6477 - accuracy: 0.6364\n",
      "Epoch 506/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6476 - accuracy: 0.6364\n",
      "Epoch 507/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6475 - accuracy: 0.6364\n",
      "Epoch 508/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.6364\n",
      "Epoch 509/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6473 - accuracy: 0.6364\n",
      "Epoch 510/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6472 - accuracy: 0.6364\n",
      "Epoch 511/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6471 - accuracy: 0.6364\n",
      "Epoch 512/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6470 - accuracy: 0.6364\n",
      "Epoch 513/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.6364\n",
      "Epoch 514/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.6364\n",
      "Epoch 515/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6466 - accuracy: 0.6364\n",
      "Epoch 516/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6465 - accuracy: 0.6364\n",
      "Epoch 517/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.6364\n",
      "Epoch 518/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6463 - accuracy: 0.6364\n",
      "Epoch 519/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6462 - accuracy: 0.6364\n",
      "Epoch 520/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6461 - accuracy: 0.6364\n",
      "Epoch 521/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6460 - accuracy: 0.6364\n",
      "Epoch 522/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6459 - accuracy: 0.6364\n",
      "Epoch 523/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6458 - accuracy: 0.6364\n",
      "Epoch 524/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6457 - accuracy: 0.6364\n",
      "Epoch 525/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.6364\n",
      "Epoch 526/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6455 - accuracy: 0.6364\n",
      "Epoch 527/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.6364\n",
      "Epoch 528/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.6364\n",
      "Epoch 529/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6452 - accuracy: 0.6364\n",
      "Epoch 530/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.6364\n",
      "Epoch 531/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6449 - accuracy: 0.6364\n",
      "Epoch 532/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6448 - accuracy: 0.6364\n",
      "Epoch 533/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.6364\n",
      "Epoch 534/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6446 - accuracy: 0.6364\n",
      "Epoch 535/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.6364\n",
      "Epoch 536/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6444 - accuracy: 0.6364\n",
      "Epoch 537/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6443 - accuracy: 0.6364\n",
      "Epoch 538/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6442 - accuracy: 0.6364\n",
      "Epoch 539/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.6364\n",
      "Epoch 540/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.6364\n",
      "Epoch 541/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6439 - accuracy: 0.6364\n",
      "Epoch 542/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.6364\n",
      "Epoch 543/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6437 - accuracy: 0.6364\n",
      "Epoch 544/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6436 - accuracy: 0.6364\n",
      "Epoch 545/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6435 - accuracy: 0.6364\n",
      "Epoch 546/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6435 - accuracy: 0.6364\n",
      "Epoch 547/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6434 - accuracy: 0.6364\n",
      "Epoch 548/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6433 - accuracy: 0.6364\n",
      "Epoch 549/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6432 - accuracy: 0.6364\n",
      "Epoch 550/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6431 - accuracy: 0.6364\n",
      "Epoch 551/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.6364\n",
      "Epoch 552/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6429 - accuracy: 0.6364\n",
      "Epoch 553/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6428 - accuracy: 0.6364\n",
      "Epoch 554/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.6364\n",
      "Epoch 555/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6426 - accuracy: 0.6364\n",
      "Epoch 556/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.6364\n",
      "Epoch 557/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6424 - accuracy: 0.6364\n",
      "Epoch 558/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6423 - accuracy: 0.6364\n",
      "Epoch 559/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6422 - accuracy: 0.6364\n",
      "Epoch 560/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.6364\n",
      "Epoch 561/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6420 - accuracy: 0.6364\n",
      "Epoch 562/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.6364\n",
      "Epoch 563/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6418 - accuracy: 0.6364\n",
      "Epoch 564/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.6364\n",
      "Epoch 565/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.6364\n",
      "Epoch 566/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6416 - accuracy: 0.6364\n",
      "Epoch 567/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.6364\n",
      "Epoch 568/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.6364\n",
      "Epoch 569/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6364\n",
      "Epoch 570/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6412 - accuracy: 0.6364\n",
      "Epoch 571/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.6364\n",
      "Epoch 572/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.6364\n",
      "Epoch 573/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.6364\n",
      "Epoch 574/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.6364\n",
      "Epoch 575/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6408 - accuracy: 0.6364\n",
      "Epoch 576/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6407 - accuracy: 0.6364\n",
      "Epoch 577/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6406 - accuracy: 0.6364\n",
      "Epoch 578/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.6364\n",
      "Epoch 579/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.6364\n",
      "Epoch 580/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.6364\n",
      "Epoch 581/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6403 - accuracy: 0.6364\n",
      "Epoch 582/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6402 - accuracy: 0.6364\n",
      "Epoch 583/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6401 - accuracy: 0.6364\n",
      "Epoch 584/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6400 - accuracy: 0.6364\n",
      "Epoch 585/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6399 - accuracy: 0.6364\n",
      "Epoch 586/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6398 - accuracy: 0.6364\n",
      "Epoch 587/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6397 - accuracy: 0.6364\n",
      "Epoch 588/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6397 - accuracy: 0.6364\n",
      "Epoch 589/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 0.6364\n",
      "Epoch 590/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.6364\n",
      "Epoch 591/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6394 - accuracy: 0.6364\n",
      "Epoch 592/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6393 - accuracy: 0.6364\n",
      "Epoch 593/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.6364\n",
      "Epoch 594/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.6364\n",
      "Epoch 595/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6391 - accuracy: 0.6364\n",
      "Epoch 596/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6390 - accuracy: 0.6364\n",
      "Epoch 597/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6389 - accuracy: 0.6364\n",
      "Epoch 598/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6388 - accuracy: 0.6364\n",
      "Epoch 599/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.6364\n",
      "Epoch 600/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6387 - accuracy: 0.6364\n",
      "Epoch 601/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6386 - accuracy: 0.6364\n",
      "Epoch 602/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6385 - accuracy: 0.6364\n",
      "Epoch 603/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.6364\n",
      "Epoch 604/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6383 - accuracy: 0.6364\n",
      "Epoch 605/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.6364\n",
      "Epoch 606/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.6364\n",
      "Epoch 607/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6381 - accuracy: 0.6364\n",
      "Epoch 608/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.6364\n",
      "Epoch 609/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.6364\n",
      "Epoch 610/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6379 - accuracy: 0.6364\n",
      "Epoch 611/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.6364\n",
      "Epoch 612/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6377 - accuracy: 0.6364\n",
      "Epoch 613/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.6364\n",
      "Epoch 614/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6376 - accuracy: 0.6364\n",
      "Epoch 615/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.6364\n",
      "Epoch 616/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.6364\n",
      "Epoch 617/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.6364\n",
      "Epoch 618/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.6364\n",
      "Epoch 619/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6372 - accuracy: 0.6364\n",
      "Epoch 620/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.6364\n",
      "Epoch 621/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.6364\n",
      "Epoch 622/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.6364\n",
      "Epoch 623/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.6364\n",
      "Epoch 624/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6368 - accuracy: 0.6364\n",
      "Epoch 625/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.6364\n",
      "Epoch 626/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.6364\n",
      "Epoch 627/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.6364\n",
      "Epoch 628/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6365 - accuracy: 0.6364\n",
      "Epoch 629/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.6364\n",
      "Epoch 630/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.6364\n",
      "Epoch 631/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.6364\n",
      "Epoch 632/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.6364\n",
      "Epoch 633/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6361 - accuracy: 0.6364\n",
      "Epoch 634/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6361 - accuracy: 0.6364\n",
      "Epoch 635/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6360 - accuracy: 0.6364\n",
      "Epoch 636/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6359 - accuracy: 0.6364\n",
      "Epoch 637/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6358 - accuracy: 0.6364\n",
      "Epoch 638/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6358 - accuracy: 0.6364\n",
      "Epoch 639/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6357 - accuracy: 0.6364\n",
      "Epoch 640/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.6364\n",
      "Epoch 641/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6356 - accuracy: 0.6364\n",
      "Epoch 642/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6355 - accuracy: 0.6364\n",
      "Epoch 643/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.6364\n",
      "Epoch 644/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.6364\n",
      "Epoch 645/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.6364\n",
      "Epoch 646/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6352 - accuracy: 0.6364\n",
      "Epoch 647/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.6364\n",
      "Epoch 648/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6351 - accuracy: 0.6364\n",
      "Epoch 649/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.6364\n",
      "Epoch 650/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.6364\n",
      "Epoch 651/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.6364\n",
      "Epoch 652/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.6364\n",
      "Epoch 653/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6347 - accuracy: 0.6364\n",
      "Epoch 654/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.6364\n",
      "Epoch 655/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.6364\n",
      "Epoch 656/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6345 - accuracy: 0.6364\n",
      "Epoch 657/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6344 - accuracy: 0.6364\n",
      "Epoch 658/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6344 - accuracy: 0.6364\n",
      "Epoch 659/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.6364\n",
      "Epoch 660/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6342 - accuracy: 0.6364\n",
      "Epoch 661/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6342 - accuracy: 0.6364\n",
      "Epoch 662/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6341 - accuracy: 0.6364\n",
      "Epoch 663/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6340 - accuracy: 0.6364\n",
      "Epoch 664/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6340 - accuracy: 0.6364\n",
      "Epoch 665/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6339 - accuracy: 0.6364\n",
      "Epoch 666/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.6364\n",
      "Epoch 667/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.6364\n",
      "Epoch 668/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.6364\n",
      "Epoch 669/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6336 - accuracy: 0.6364\n",
      "Epoch 670/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6336 - accuracy: 0.6364\n",
      "Epoch 671/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6335 - accuracy: 0.6364\n",
      "Epoch 672/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6334 - accuracy: 0.6364\n",
      "Epoch 673/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6334 - accuracy: 0.6364\n",
      "Epoch 674/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.6364\n",
      "Epoch 675/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.6364\n",
      "Epoch 676/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.6364\n",
      "Epoch 677/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6331 - accuracy: 0.6364\n",
      "Epoch 678/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6330 - accuracy: 0.6364\n",
      "Epoch 679/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6330 - accuracy: 0.6364\n",
      "Epoch 680/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6329 - accuracy: 0.6364\n",
      "Epoch 681/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6328 - accuracy: 0.6364\n",
      "Epoch 682/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6328 - accuracy: 0.6364\n",
      "Epoch 683/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6327 - accuracy: 0.6364\n",
      "Epoch 684/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6326 - accuracy: 0.6364\n",
      "Epoch 685/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6326 - accuracy: 0.6364\n",
      "Epoch 686/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.6364\n",
      "Epoch 687/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.6364\n",
      "Epoch 688/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.6364\n",
      "Epoch 689/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.6364\n",
      "Epoch 690/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.6364\n",
      "Epoch 691/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.6364\n",
      "Epoch 692/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.6364\n",
      "Epoch 693/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.6364\n",
      "Epoch 694/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.6364\n",
      "Epoch 695/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.6364\n",
      "Epoch 696/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6319 - accuracy: 0.6364\n",
      "Epoch 697/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.6364\n",
      "Epoch 698/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.6364\n",
      "Epoch 699/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.6364\n",
      "Epoch 700/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.6364\n",
      "Epoch 701/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.6364\n",
      "Epoch 702/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.6364\n",
      "Epoch 703/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6315 - accuracy: 0.6364\n",
      "Epoch 704/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.6364\n",
      "Epoch 705/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6313 - accuracy: 0.6364\n",
      "Epoch 706/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6313 - accuracy: 0.6364\n",
      "Epoch 707/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.6364\n",
      "Epoch 708/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6312 - accuracy: 0.6364\n",
      "Epoch 709/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6311 - accuracy: 0.6364\n",
      "Epoch 710/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.6364\n",
      "Epoch 711/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6310 - accuracy: 0.6364\n",
      "Epoch 712/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6309 - accuracy: 0.6364\n",
      "Epoch 713/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.6364\n",
      "Epoch 714/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6308 - accuracy: 0.6364\n",
      "Epoch 715/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6307 - accuracy: 0.6364\n",
      "Epoch 716/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6307 - accuracy: 0.6364\n",
      "Epoch 717/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6306 - accuracy: 0.6364\n",
      "Epoch 718/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6306 - accuracy: 0.6364\n",
      "Epoch 719/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6305 - accuracy: 0.6364\n",
      "Epoch 720/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6304 - accuracy: 0.6364\n",
      "Epoch 721/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6304 - accuracy: 0.6364\n",
      "Epoch 722/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6303 - accuracy: 0.6364\n",
      "Epoch 723/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6303 - accuracy: 0.6364\n",
      "Epoch 724/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6302 - accuracy: 0.6364\n",
      "Epoch 725/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6301 - accuracy: 0.6364\n",
      "Epoch 726/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6301 - accuracy: 0.6364\n",
      "Epoch 727/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6300 - accuracy: 0.6364\n",
      "Epoch 728/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6300 - accuracy: 0.6364\n",
      "Epoch 729/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6299 - accuracy: 0.6364\n",
      "Epoch 730/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6299 - accuracy: 0.6364\n",
      "Epoch 731/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6298 - accuracy: 0.6364\n",
      "Epoch 732/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6297 - accuracy: 0.6364\n",
      "Epoch 733/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6297 - accuracy: 0.6364\n",
      "Epoch 734/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6296 - accuracy: 0.6364\n",
      "Epoch 735/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6296 - accuracy: 0.6364\n",
      "Epoch 736/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6295 - accuracy: 0.6364\n",
      "Epoch 737/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6295 - accuracy: 0.6364\n",
      "Epoch 738/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6294 - accuracy: 0.6364\n",
      "Epoch 739/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6293 - accuracy: 0.6364\n",
      "Epoch 740/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6293 - accuracy: 0.6364\n",
      "Epoch 741/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.6364\n",
      "Epoch 742/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.6364\n",
      "Epoch 743/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.6364\n",
      "Epoch 744/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.6364\n",
      "Epoch 745/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6290 - accuracy: 0.6364\n",
      "Epoch 746/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.6364\n",
      "Epoch 747/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.6364\n",
      "Epoch 748/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6288 - accuracy: 0.6364\n",
      "Epoch 749/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6288 - accuracy: 0.6364\n",
      "Epoch 750/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6287 - accuracy: 0.6364\n",
      "Epoch 751/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6287 - accuracy: 0.6364\n",
      "Epoch 752/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6286 - accuracy: 0.6364\n",
      "Epoch 753/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6286 - accuracy: 0.6364\n",
      "Epoch 754/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6285 - accuracy: 0.6364\n",
      "Epoch 755/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6284 - accuracy: 0.6364\n",
      "Epoch 756/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6284 - accuracy: 0.6364\n",
      "Epoch 757/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6283 - accuracy: 0.6364\n",
      "Epoch 758/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6283 - accuracy: 0.6364\n",
      "Epoch 759/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6282 - accuracy: 0.6364\n",
      "Epoch 760/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6282 - accuracy: 0.6364\n",
      "Epoch 761/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6281 - accuracy: 0.6364\n",
      "Epoch 762/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6281 - accuracy: 0.6364\n",
      "Epoch 763/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6280 - accuracy: 0.6364\n",
      "Epoch 764/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6279 - accuracy: 0.6364\n",
      "Epoch 765/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6279 - accuracy: 0.6364\n",
      "Epoch 766/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6278 - accuracy: 0.6364\n",
      "Epoch 767/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6278 - accuracy: 0.6364\n",
      "Epoch 768/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6277 - accuracy: 0.6364\n",
      "Epoch 769/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6277 - accuracy: 0.6364\n",
      "Epoch 770/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6276 - accuracy: 0.6364\n",
      "Epoch 771/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6276 - accuracy: 0.6364\n",
      "Epoch 772/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6275 - accuracy: 0.6364\n",
      "Epoch 773/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6275 - accuracy: 0.6364\n",
      "Epoch 774/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.6364\n",
      "Epoch 775/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.6364\n",
      "Epoch 776/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.6364\n",
      "Epoch 777/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6272 - accuracy: 0.6364\n",
      "Epoch 778/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6272 - accuracy: 0.6364\n",
      "Epoch 779/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6271 - accuracy: 0.6364\n",
      "Epoch 780/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6271 - accuracy: 0.6364\n",
      "Epoch 781/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.6364\n",
      "Epoch 782/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6270 - accuracy: 0.6364\n",
      "Epoch 783/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6269 - accuracy: 0.6364\n",
      "Epoch 784/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6269 - accuracy: 0.6364\n",
      "Epoch 785/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6268 - accuracy: 0.6364\n",
      "Epoch 786/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6268 - accuracy: 0.6364\n",
      "Epoch 787/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6267 - accuracy: 0.6364\n",
      "Epoch 788/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.6364\n",
      "Epoch 789/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.6364\n",
      "Epoch 790/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.6364\n",
      "Epoch 791/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6265 - accuracy: 0.6364\n",
      "Epoch 792/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6264 - accuracy: 0.6364\n",
      "Epoch 793/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6264 - accuracy: 0.6364\n",
      "Epoch 794/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6263 - accuracy: 0.6364\n",
      "Epoch 795/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6263 - accuracy: 0.6364\n",
      "Epoch 796/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6262 - accuracy: 0.6364\n",
      "Epoch 797/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6262 - accuracy: 0.6364\n",
      "Epoch 798/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.6364\n",
      "Epoch 799/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.6364\n",
      "Epoch 800/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6260 - accuracy: 0.6364\n",
      "Epoch 801/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6260 - accuracy: 0.6364\n",
      "Epoch 802/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6259 - accuracy: 0.6364\n",
      "Epoch 803/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6259 - accuracy: 0.6364\n",
      "Epoch 804/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.6364\n",
      "Epoch 805/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6258 - accuracy: 0.6364\n",
      "Epoch 806/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6257 - accuracy: 0.6364\n",
      "Epoch 807/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6257 - accuracy: 0.6364\n",
      "Epoch 808/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.6364\n",
      "Epoch 809/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6256 - accuracy: 0.6364\n",
      "Epoch 810/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.6364\n",
      "Epoch 811/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.6364\n",
      "Epoch 812/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6254 - accuracy: 0.6364\n",
      "Epoch 813/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6254 - accuracy: 0.6364\n",
      "Epoch 814/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6253 - accuracy: 0.6364\n",
      "Epoch 815/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6253 - accuracy: 0.6364\n",
      "Epoch 816/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6252 - accuracy: 0.6364\n",
      "Epoch 817/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6251 - accuracy: 0.6364\n",
      "Epoch 818/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6251 - accuracy: 0.6364\n",
      "Epoch 819/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6250 - accuracy: 0.6364\n",
      "Epoch 820/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6250 - accuracy: 0.6364\n",
      "Epoch 821/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6249 - accuracy: 0.6364\n",
      "Epoch 822/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6249 - accuracy: 0.6364\n",
      "Epoch 823/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6248 - accuracy: 0.6364\n",
      "Epoch 824/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6248 - accuracy: 0.6364\n",
      "Epoch 825/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6247 - accuracy: 0.6364\n",
      "Epoch 826/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6247 - accuracy: 0.6364\n",
      "Epoch 827/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6246 - accuracy: 0.6364\n",
      "Epoch 828/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6246 - accuracy: 0.6364\n",
      "Epoch 829/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6245 - accuracy: 0.6364\n",
      "Epoch 830/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6245 - accuracy: 0.6364\n",
      "Epoch 831/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6244 - accuracy: 0.6364\n",
      "Epoch 832/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6244 - accuracy: 0.6364\n",
      "Epoch 833/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6243 - accuracy: 0.6364\n",
      "Epoch 834/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6243 - accuracy: 0.6364\n",
      "Epoch 835/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6242 - accuracy: 0.6364\n",
      "Epoch 836/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6242 - accuracy: 0.6364\n",
      "Epoch 837/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6241 - accuracy: 0.6364\n",
      "Epoch 838/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6241 - accuracy: 0.6364\n",
      "Epoch 839/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6240 - accuracy: 0.6364\n",
      "Epoch 840/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6240 - accuracy: 0.6364\n",
      "Epoch 841/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6239 - accuracy: 0.6364\n",
      "Epoch 842/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6239 - accuracy: 0.6364\n",
      "Epoch 843/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6238 - accuracy: 0.6364\n",
      "Epoch 844/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6238 - accuracy: 0.6364\n",
      "Epoch 845/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6237 - accuracy: 0.6364\n",
      "Epoch 846/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6237 - accuracy: 0.6364\n",
      "Epoch 847/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6236 - accuracy: 0.6364\n",
      "Epoch 848/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6236 - accuracy: 0.6364\n",
      "Epoch 849/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.6364\n",
      "Epoch 850/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.6364\n",
      "Epoch 851/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6234 - accuracy: 0.6364\n",
      "Epoch 852/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6234 - accuracy: 0.6364\n",
      "Epoch 853/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6233 - accuracy: 0.6364\n",
      "Epoch 854/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6233 - accuracy: 0.6364\n",
      "Epoch 855/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6232 - accuracy: 0.6364\n",
      "Epoch 856/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6232 - accuracy: 0.6364\n",
      "Epoch 857/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6231 - accuracy: 0.6364\n",
      "Epoch 858/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6231 - accuracy: 0.6364\n",
      "Epoch 859/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6230 - accuracy: 0.6364\n",
      "Epoch 860/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6230 - accuracy: 0.6364\n",
      "Epoch 861/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6229 - accuracy: 0.6364\n",
      "Epoch 862/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6229 - accuracy: 0.6364\n",
      "Epoch 863/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6228 - accuracy: 0.6364\n",
      "Epoch 864/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6228 - accuracy: 0.6364\n",
      "Epoch 865/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.6364\n",
      "Epoch 866/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.6364\n",
      "Epoch 867/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.6364\n",
      "Epoch 868/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6226 - accuracy: 0.6364\n",
      "Epoch 869/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6225 - accuracy: 0.6364\n",
      "Epoch 870/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6225 - accuracy: 0.6364\n",
      "Epoch 871/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.6364\n",
      "Epoch 872/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6224 - accuracy: 0.6364\n",
      "Epoch 873/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6224 - accuracy: 0.6364\n",
      "Epoch 874/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6223 - accuracy: 0.6364\n",
      "Epoch 875/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6223 - accuracy: 0.6364\n",
      "Epoch 876/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6222 - accuracy: 0.6364\n",
      "Epoch 877/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6222 - accuracy: 0.6364\n",
      "Epoch 878/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6221 - accuracy: 0.6364\n",
      "Epoch 879/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6221 - accuracy: 0.6364\n",
      "Epoch 880/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6220 - accuracy: 0.6364\n",
      "Epoch 881/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6220 - accuracy: 0.6364\n",
      "Epoch 882/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.6364\n",
      "Epoch 883/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6219 - accuracy: 0.6364\n",
      "Epoch 884/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.6364\n",
      "Epoch 885/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.6364\n",
      "Epoch 886/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6217 - accuracy: 0.6364\n",
      "Epoch 887/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.6364\n",
      "Epoch 888/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6216 - accuracy: 0.6364\n",
      "Epoch 889/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6216 - accuracy: 0.6364\n",
      "Epoch 890/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.6364\n",
      "Epoch 891/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.6364\n",
      "Epoch 892/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6214 - accuracy: 0.6364\n",
      "Epoch 893/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6214 - accuracy: 0.6364\n",
      "Epoch 894/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6213 - accuracy: 0.6364\n",
      "Epoch 895/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6213 - accuracy: 0.6364\n",
      "Epoch 896/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6212 - accuracy: 0.6364\n",
      "Epoch 897/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6212 - accuracy: 0.6364\n",
      "Epoch 898/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6211 - accuracy: 0.6364\n",
      "Epoch 899/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6211 - accuracy: 0.6364\n",
      "Epoch 900/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6210 - accuracy: 0.6364\n",
      "Epoch 901/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6210 - accuracy: 0.6364\n",
      "Epoch 902/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6209 - accuracy: 0.6364\n",
      "Epoch 903/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6209 - accuracy: 0.6364\n",
      "Epoch 904/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6208 - accuracy: 0.6364\n",
      "Epoch 905/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6208 - accuracy: 0.6364\n",
      "Epoch 906/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6208 - accuracy: 0.6364\n",
      "Epoch 907/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.6364\n",
      "Epoch 908/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6207 - accuracy: 0.6364\n",
      "Epoch 909/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.6364\n",
      "Epoch 910/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.6364\n",
      "Epoch 911/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.6364\n",
      "Epoch 912/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.6364\n",
      "Epoch 913/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6204 - accuracy: 0.6364\n",
      "Epoch 914/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6204 - accuracy: 0.6364\n",
      "Epoch 915/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6203 - accuracy: 0.6364\n",
      "Epoch 916/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6203 - accuracy: 0.6364\n",
      "Epoch 917/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6202 - accuracy: 0.6364\n",
      "Epoch 918/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6202 - accuracy: 0.6364\n",
      "Epoch 919/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6201 - accuracy: 0.6364\n",
      "Epoch 920/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6201 - accuracy: 0.6364\n",
      "Epoch 921/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6200 - accuracy: 0.6364\n",
      "Epoch 922/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6200 - accuracy: 0.6364\n",
      "Epoch 923/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.6364\n",
      "Epoch 924/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6199 - accuracy: 0.6364\n",
      "Epoch 925/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.6364\n",
      "Epoch 926/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.6364\n",
      "Epoch 927/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6197 - accuracy: 0.6364\n",
      "Epoch 928/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6197 - accuracy: 0.6364\n",
      "Epoch 929/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.6364\n",
      "Epoch 930/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.7273\n",
      "Epoch 931/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6196 - accuracy: 0.7273\n",
      "Epoch 932/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6195 - accuracy: 0.7273\n",
      "Epoch 933/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6195 - accuracy: 0.7273\n",
      "Epoch 934/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6194 - accuracy: 0.7273\n",
      "Epoch 935/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6194 - accuracy: 0.7273\n",
      "Epoch 936/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6193 - accuracy: 0.7273\n",
      "Epoch 937/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6193 - accuracy: 0.7273\n",
      "Epoch 938/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6192 - accuracy: 0.7273\n",
      "Epoch 939/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6192 - accuracy: 0.7273\n",
      "Epoch 940/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6191 - accuracy: 0.7273\n",
      "Epoch 941/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6191 - accuracy: 0.7273\n",
      "Epoch 942/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6190 - accuracy: 0.7273\n",
      "Epoch 943/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6190 - accuracy: 0.7273\n",
      "Epoch 944/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6189 - accuracy: 0.7273\n",
      "Epoch 945/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6189 - accuracy: 0.7273\n",
      "Epoch 946/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6188 - accuracy: 0.7273\n",
      "Epoch 947/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6188 - accuracy: 0.7273\n",
      "Epoch 948/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.7273\n",
      "Epoch 949/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.7273\n",
      "Epoch 950/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6186 - accuracy: 0.7273\n",
      "Epoch 951/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6186 - accuracy: 0.7273\n",
      "Epoch 952/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6186 - accuracy: 0.7273\n",
      "Epoch 953/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6185 - accuracy: 0.7273\n",
      "Epoch 954/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6185 - accuracy: 0.7273\n",
      "Epoch 955/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6184 - accuracy: 0.7273\n",
      "Epoch 956/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6184 - accuracy: 0.7273\n",
      "Epoch 957/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6183 - accuracy: 0.7273\n",
      "Epoch 958/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6183 - accuracy: 0.7273\n",
      "Epoch 959/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.7273\n",
      "Epoch 960/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.7273\n",
      "Epoch 961/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6181 - accuracy: 0.7273\n",
      "Epoch 962/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6181 - accuracy: 0.7273\n",
      "Epoch 963/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.7273\n",
      "Epoch 964/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6180 - accuracy: 0.7273\n",
      "Epoch 965/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6179 - accuracy: 0.7273\n",
      "Epoch 966/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6179 - accuracy: 0.7273\n",
      "Epoch 967/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6178 - accuracy: 0.7273\n",
      "Epoch 968/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6178 - accuracy: 0.7273\n",
      "Epoch 969/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6177 - accuracy: 0.7273\n",
      "Epoch 970/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.7273\n",
      "Epoch 971/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.7273\n",
      "Epoch 972/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6176 - accuracy: 0.7273\n",
      "Epoch 973/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6176 - accuracy: 0.7273\n",
      "Epoch 974/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6175 - accuracy: 0.7273\n",
      "Epoch 975/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6175 - accuracy: 0.7273\n",
      "Epoch 976/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6174 - accuracy: 0.7273\n",
      "Epoch 977/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.7273\n",
      "Epoch 978/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6173 - accuracy: 0.7273\n",
      "Epoch 979/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6173 - accuracy: 0.7273\n",
      "Epoch 980/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6172 - accuracy: 0.7273\n",
      "Epoch 981/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6172 - accuracy: 0.7273\n",
      "Epoch 982/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6171 - accuracy: 0.7273\n",
      "Epoch 983/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6171 - accuracy: 0.7273\n",
      "Epoch 984/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6170 - accuracy: 0.7273\n",
      "Epoch 985/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6170 - accuracy: 0.7273\n",
      "Epoch 986/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6169 - accuracy: 0.7273\n",
      "Epoch 987/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6169 - accuracy: 0.7273\n",
      "Epoch 988/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6168 - accuracy: 0.7273\n",
      "Epoch 989/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6168 - accuracy: 0.7273\n",
      "Epoch 990/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6168 - accuracy: 0.7273\n",
      "Epoch 991/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6167 - accuracy: 0.7273\n",
      "Epoch 992/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6167 - accuracy: 0.7727\n",
      "Epoch 993/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6166 - accuracy: 0.7727\n",
      "Epoch 994/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6166 - accuracy: 0.7727\n",
      "Epoch 995/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.7727\n",
      "Epoch 996/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6165 - accuracy: 0.7727\n",
      "Epoch 997/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6164 - accuracy: 0.7727\n",
      "Epoch 998/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6164 - accuracy: 0.7727\n",
      "Epoch 999/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6163 - accuracy: 0.7727\n",
      "Epoch 1000/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6163 - accuracy: 0.7727\n",
      "Epoch 1001/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6162 - accuracy: 0.7727\n",
      "Epoch 1002/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6162 - accuracy: 0.7727\n",
      "Epoch 1003/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6161 - accuracy: 0.7727\n",
      "Epoch 1004/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6161 - accuracy: 0.7727\n",
      "Epoch 1005/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6160 - accuracy: 0.7727\n",
      "Epoch 1006/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6160 - accuracy: 0.7727\n",
      "Epoch 1007/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6160 - accuracy: 0.7727\n",
      "Epoch 1008/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6159 - accuracy: 0.7727\n",
      "Epoch 1009/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6159 - accuracy: 0.7727\n",
      "Epoch 1010/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6158 - accuracy: 0.7727\n",
      "Epoch 1011/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6158 - accuracy: 0.7727\n",
      "Epoch 1012/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6157 - accuracy: 0.7727\n",
      "Epoch 1013/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6157 - accuracy: 0.7727\n",
      "Epoch 1014/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.7727\n",
      "Epoch 1015/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6156 - accuracy: 0.7727\n",
      "Epoch 1016/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.7727\n",
      "Epoch 1017/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.8182\n",
      "Epoch 1018/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6154 - accuracy: 0.8182\n",
      "Epoch 1019/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6154 - accuracy: 0.8182\n",
      "Epoch 1020/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6153 - accuracy: 0.8182\n",
      "Epoch 1021/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6153 - accuracy: 0.8182\n",
      "Epoch 1022/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6152 - accuracy: 0.8182\n",
      "Epoch 1023/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6152 - accuracy: 0.8182\n",
      "Epoch 1024/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6151 - accuracy: 0.8182\n",
      "Epoch 1025/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6151 - accuracy: 0.8182\n",
      "Epoch 1026/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6151 - accuracy: 0.8182\n",
      "Epoch 1027/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6150 - accuracy: 0.8182\n",
      "Epoch 1028/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6150 - accuracy: 0.8182\n",
      "Epoch 1029/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6149 - accuracy: 0.8182\n",
      "Epoch 1030/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.8182\n",
      "Epoch 1031/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6148 - accuracy: 0.8182\n",
      "Epoch 1032/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6148 - accuracy: 0.8182\n",
      "Epoch 1033/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6147 - accuracy: 0.8182\n",
      "Epoch 1034/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6147 - accuracy: 0.8182\n",
      "Epoch 1035/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6146 - accuracy: 0.8182\n",
      "Epoch 1036/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6146 - accuracy: 0.8182\n",
      "Epoch 1037/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6145 - accuracy: 0.8182\n",
      "Epoch 1038/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6145 - accuracy: 0.8182\n",
      "Epoch 1039/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6144 - accuracy: 0.8182\n",
      "Epoch 1040/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6144 - accuracy: 0.8182\n",
      "Epoch 1041/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6143 - accuracy: 0.8182\n",
      "Epoch 1042/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.8182\n",
      "Epoch 1043/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6143 - accuracy: 0.8182\n",
      "Epoch 1044/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6142 - accuracy: 0.8636\n",
      "Epoch 1045/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6142 - accuracy: 0.8636\n",
      "Epoch 1046/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6141 - accuracy: 0.8636\n",
      "Epoch 1047/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6141 - accuracy: 0.8636\n",
      "Epoch 1048/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6140 - accuracy: 0.8636\n",
      "Epoch 1049/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.8636\n",
      "Epoch 1050/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.8636\n",
      "Epoch 1051/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.8636\n",
      "Epoch 1052/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.8636\n",
      "Epoch 1053/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.8636\n",
      "Epoch 1054/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6137 - accuracy: 0.8636\n",
      "Epoch 1055/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6137 - accuracy: 0.8636\n",
      "Epoch 1056/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.8636\n",
      "Epoch 1057/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.8636\n",
      "Epoch 1058/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6135 - accuracy: 0.8636\n",
      "Epoch 1059/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6135 - accuracy: 0.8636\n",
      "Epoch 1060/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6134 - accuracy: 0.8636\n",
      "Epoch 1061/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6134 - accuracy: 0.8636\n",
      "Epoch 1062/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6134 - accuracy: 0.8636\n",
      "Epoch 1063/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6133 - accuracy: 0.8636\n",
      "Epoch 1064/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6133 - accuracy: 0.8636\n",
      "Epoch 1065/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6132 - accuracy: 0.8636\n",
      "Epoch 1066/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6132 - accuracy: 0.8636\n",
      "Epoch 1067/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6131 - accuracy: 0.8636\n",
      "Epoch 1068/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6131 - accuracy: 0.8636\n",
      "Epoch 1069/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6130 - accuracy: 0.8636\n",
      "Epoch 1070/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6130 - accuracy: 0.8636\n",
      "Epoch 1071/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6129 - accuracy: 0.8636\n",
      "Epoch 1072/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6129 - accuracy: 0.8636\n",
      "Epoch 1073/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6128 - accuracy: 0.8636\n",
      "Epoch 1074/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6128 - accuracy: 0.8636\n",
      "Epoch 1075/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6127 - accuracy: 0.8636\n",
      "Epoch 1076/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6127 - accuracy: 0.8636\n",
      "Epoch 1077/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.8636\n",
      "Epoch 1078/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6126 - accuracy: 0.8636\n",
      "Epoch 1079/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6126 - accuracy: 0.8636\n",
      "Epoch 1080/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.8636\n",
      "Epoch 1081/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6125 - accuracy: 0.8636\n",
      "Epoch 1082/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.8636\n",
      "Epoch 1083/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.8636\n",
      "Epoch 1084/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6123 - accuracy: 0.8636\n",
      "Epoch 1085/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6123 - accuracy: 0.8636\n",
      "Epoch 1086/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6122 - accuracy: 0.8636\n",
      "Epoch 1087/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6122 - accuracy: 0.8636\n",
      "Epoch 1088/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6121 - accuracy: 0.8636\n",
      "Epoch 1089/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6121 - accuracy: 0.8636\n",
      "Epoch 1090/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6120 - accuracy: 0.8636\n",
      "Epoch 1091/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6120 - accuracy: 0.8636\n",
      "Epoch 1092/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6119 - accuracy: 0.8636\n",
      "Epoch 1093/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6119 - accuracy: 0.8636\n",
      "Epoch 1094/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6118 - accuracy: 0.8636\n",
      "Epoch 1095/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6118 - accuracy: 0.8636\n",
      "Epoch 1096/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6117 - accuracy: 0.8636\n",
      "Epoch 1097/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.8636\n",
      "Epoch 1098/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.8636\n",
      "Epoch 1099/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6116 - accuracy: 0.8636\n",
      "Epoch 1100/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6116 - accuracy: 0.8636\n",
      "Epoch 1101/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.8636\n",
      "Epoch 1102/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6115 - accuracy: 0.8636\n",
      "Epoch 1103/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.8636\n",
      "Epoch 1104/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6114 - accuracy: 0.8636\n",
      "Epoch 1105/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6113 - accuracy: 0.8636\n",
      "Epoch 1106/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6113 - accuracy: 0.8636\n",
      "Epoch 1107/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6112 - accuracy: 0.8636\n",
      "Epoch 1108/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6112 - accuracy: 0.8636\n",
      "Epoch 1109/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6111 - accuracy: 0.8636\n",
      "Epoch 1110/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6111 - accuracy: 0.8636\n",
      "Epoch 1111/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6110 - accuracy: 0.8636\n",
      "Epoch 1112/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6110 - accuracy: 0.8636\n",
      "Epoch 1113/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6109 - accuracy: 0.8636\n",
      "Epoch 1114/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6109 - accuracy: 0.8636\n",
      "Epoch 1115/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6108 - accuracy: 0.8636\n",
      "Epoch 1116/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6108 - accuracy: 0.8636\n",
      "Epoch 1117/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6108 - accuracy: 0.8636\n",
      "Epoch 1118/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6107 - accuracy: 0.8636\n",
      "Epoch 1119/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6107 - accuracy: 0.8636\n",
      "Epoch 1120/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.8636\n",
      "Epoch 1121/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.8636\n",
      "Epoch 1122/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.8636\n",
      "Epoch 1123/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.8636\n",
      "Epoch 1124/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6104 - accuracy: 0.8636\n",
      "Epoch 1125/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6104 - accuracy: 0.8636\n",
      "Epoch 1126/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6103 - accuracy: 0.8636\n",
      "Epoch 1127/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6103 - accuracy: 0.8636\n",
      "Epoch 1128/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.8636\n",
      "Epoch 1129/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.8636\n",
      "Epoch 1130/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.8636\n",
      "Epoch 1131/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.8636\n",
      "Epoch 1132/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.8636\n",
      "Epoch 1133/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.8636\n",
      "Epoch 1134/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6099 - accuracy: 0.8636\n",
      "Epoch 1135/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6099 - accuracy: 0.8636\n",
      "Epoch 1136/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6099 - accuracy: 0.8636\n",
      "Epoch 1137/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6098 - accuracy: 0.8636\n",
      "Epoch 1138/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6098 - accuracy: 0.8636\n",
      "Epoch 1139/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.8636\n",
      "Epoch 1140/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.8636\n",
      "Epoch 1141/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.8636\n",
      "Epoch 1142/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.8636\n",
      "Epoch 1143/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.8636\n",
      "Epoch 1144/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.8636\n",
      "Epoch 1145/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6094 - accuracy: 0.8636\n",
      "Epoch 1146/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6094 - accuracy: 0.8636\n",
      "Epoch 1147/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6093 - accuracy: 0.8636\n",
      "Epoch 1148/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6093 - accuracy: 0.8636\n",
      "Epoch 1149/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6092 - accuracy: 0.8636\n",
      "Epoch 1150/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.8636\n",
      "Epoch 1151/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6091 - accuracy: 0.8636\n",
      "Epoch 1152/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6091 - accuracy: 0.8636\n",
      "Epoch 1153/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6090 - accuracy: 0.8636\n",
      "Epoch 1154/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6090 - accuracy: 0.8636\n",
      "Epoch 1155/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6090 - accuracy: 0.8636\n",
      "Epoch 1156/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.8636\n",
      "Epoch 1157/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6089 - accuracy: 0.8636\n",
      "Epoch 1158/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6088 - accuracy: 0.8636\n",
      "Epoch 1159/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6088 - accuracy: 0.8636\n",
      "Epoch 1160/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6087 - accuracy: 0.8636\n",
      "Epoch 1161/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.8636\n",
      "Epoch 1162/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.8636\n",
      "Epoch 1163/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.8636\n",
      "Epoch 1164/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.8636\n",
      "Epoch 1165/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.8636\n",
      "Epoch 1166/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.8636\n",
      "Epoch 1167/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.8636\n",
      "Epoch 1168/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.8636\n",
      "Epoch 1169/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.8636\n",
      "Epoch 1170/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.8636\n",
      "Epoch 1171/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6082 - accuracy: 0.8636\n",
      "Epoch 1172/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.8636\n",
      "Epoch 1173/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.8636\n",
      "Epoch 1174/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.8636\n",
      "Epoch 1175/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.8636\n",
      "Epoch 1176/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6080 - accuracy: 0.8636\n",
      "Epoch 1177/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.8636\n",
      "Epoch 1178/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.8636\n",
      "Epoch 1179/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6078 - accuracy: 0.8636\n",
      "Epoch 1180/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6078 - accuracy: 0.8636\n",
      "Epoch 1181/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.8636\n",
      "Epoch 1182/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.8636\n",
      "Epoch 1183/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6076 - accuracy: 0.8636\n",
      "Epoch 1184/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6076 - accuracy: 0.8636\n",
      "Epoch 1185/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.8636\n",
      "Epoch 1186/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.8636\n",
      "Epoch 1187/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6074 - accuracy: 0.8636\n",
      "Epoch 1188/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6074 - accuracy: 0.8636\n",
      "Epoch 1189/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6073 - accuracy: 0.8636\n",
      "Epoch 1190/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6073 - accuracy: 0.8636\n",
      "Epoch 1191/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6072 - accuracy: 0.8636\n",
      "Epoch 1192/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.8636\n",
      "Epoch 1193/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6071 - accuracy: 0.8636\n",
      "Epoch 1194/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6071 - accuracy: 0.8636\n",
      "Epoch 1195/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6070 - accuracy: 0.8636\n",
      "Epoch 1196/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6070 - accuracy: 0.8636\n",
      "Epoch 1197/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.8636\n",
      "Epoch 1198/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.8636\n",
      "Epoch 1199/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.8636\n",
      "Epoch 1200/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.8636\n",
      "Epoch 1201/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.8636\n",
      "Epoch 1202/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.8636\n",
      "Epoch 1203/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.8636\n",
      "Epoch 1204/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6066 - accuracy: 0.8636\n",
      "Epoch 1205/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6066 - accuracy: 0.8636\n",
      "Epoch 1206/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6065 - accuracy: 0.8636\n",
      "Epoch 1207/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6065 - accuracy: 0.8636\n",
      "Epoch 1208/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6064 - accuracy: 0.8636\n",
      "Epoch 1209/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6064 - accuracy: 0.8636\n",
      "Epoch 1210/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.8636\n",
      "Epoch 1211/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.8636\n",
      "Epoch 1212/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.8636\n",
      "Epoch 1213/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.8636\n",
      "Epoch 1214/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.8636\n",
      "Epoch 1215/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6061 - accuracy: 0.8636\n",
      "Epoch 1216/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6060 - accuracy: 0.8636\n",
      "Epoch 1217/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6060 - accuracy: 0.8636\n",
      "Epoch 1218/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6059 - accuracy: 0.8636\n",
      "Epoch 1219/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6059 - accuracy: 0.8636\n",
      "Epoch 1220/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6059 - accuracy: 0.8636\n",
      "Epoch 1221/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6058 - accuracy: 0.8636\n",
      "Epoch 1222/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.8636\n",
      "Epoch 1223/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6057 - accuracy: 0.8636\n",
      "Epoch 1224/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6057 - accuracy: 0.8636\n",
      "Epoch 1225/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6056 - accuracy: 0.8636\n",
      "Epoch 1226/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6056 - accuracy: 0.8636\n",
      "Epoch 1227/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6055 - accuracy: 0.8636\n",
      "Epoch 1228/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6055 - accuracy: 0.8636\n",
      "Epoch 1229/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6054 - accuracy: 0.8636\n",
      "Epoch 1230/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6054 - accuracy: 0.8636\n",
      "Epoch 1231/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6053 - accuracy: 0.8636\n",
      "Epoch 1232/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6053 - accuracy: 0.8636\n",
      "Epoch 1233/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.8636\n",
      "Epoch 1234/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6052 - accuracy: 0.8636\n",
      "Epoch 1235/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.8636\n",
      "Epoch 1236/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6051 - accuracy: 0.8636\n",
      "Epoch 1237/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6050 - accuracy: 0.8636\n",
      "Epoch 1238/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6050 - accuracy: 0.8636\n",
      "Epoch 1239/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.8636\n",
      "Epoch 1240/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.8636\n",
      "Epoch 1241/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.8636\n",
      "Epoch 1242/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6048 - accuracy: 0.8636\n",
      "Epoch 1243/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6048 - accuracy: 0.8636\n",
      "Epoch 1244/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6047 - accuracy: 0.8636\n",
      "Epoch 1245/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.8636\n",
      "Epoch 1246/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6046 - accuracy: 0.8636\n",
      "Epoch 1247/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6046 - accuracy: 0.8636\n",
      "Epoch 1248/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6045 - accuracy: 0.8636\n",
      "Epoch 1249/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6045 - accuracy: 0.8636\n",
      "Epoch 1250/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6044 - accuracy: 0.8636\n",
      "Epoch 1251/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6044 - accuracy: 0.8636\n",
      "Epoch 1252/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.8636\n",
      "Epoch 1253/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6043 - accuracy: 0.8636\n",
      "Epoch 1254/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6042 - accuracy: 0.8636\n",
      "Epoch 1255/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6042 - accuracy: 0.8636\n",
      "Epoch 1256/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.8636\n",
      "Epoch 1257/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.8636\n",
      "Epoch 1258/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6040 - accuracy: 0.8636\n",
      "Epoch 1259/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6040 - accuracy: 0.8636\n",
      "Epoch 1260/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6039 - accuracy: 0.8636\n",
      "Epoch 1261/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6039 - accuracy: 0.8636\n",
      "Epoch 1262/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6038 - accuracy: 0.8636\n",
      "Epoch 1263/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6038 - accuracy: 0.8636\n",
      "Epoch 1264/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6037 - accuracy: 0.8636\n",
      "Epoch 1265/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6037 - accuracy: 0.8636\n",
      "Epoch 1266/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6036 - accuracy: 0.8636\n",
      "Epoch 1267/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6036 - accuracy: 0.8636\n",
      "Epoch 1268/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6036 - accuracy: 0.8636\n",
      "Epoch 1269/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6035 - accuracy: 0.8636\n",
      "Epoch 1270/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6035 - accuracy: 0.8636\n",
      "Epoch 1271/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6034 - accuracy: 0.8636\n",
      "Epoch 1272/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6034 - accuracy: 0.8636\n",
      "Epoch 1273/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6033 - accuracy: 0.8636\n",
      "Epoch 1274/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6033 - accuracy: 0.8636\n",
      "Epoch 1275/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6032 - accuracy: 0.8636\n",
      "Epoch 1276/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6032 - accuracy: 0.8636\n",
      "Epoch 1277/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6031 - accuracy: 0.8636\n",
      "Epoch 1278/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6031 - accuracy: 0.8636\n",
      "Epoch 1279/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.8636\n",
      "Epoch 1280/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6030 - accuracy: 0.8636\n",
      "Epoch 1281/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6029 - accuracy: 0.8636\n",
      "Epoch 1282/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6029 - accuracy: 0.8636\n",
      "Epoch 1283/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6028 - accuracy: 0.8636\n",
      "Epoch 1284/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6028 - accuracy: 0.8636\n",
      "Epoch 1285/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6027 - accuracy: 0.8636\n",
      "Epoch 1286/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6027 - accuracy: 0.8636\n",
      "Epoch 1287/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6026 - accuracy: 0.8636\n",
      "Epoch 1288/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6026 - accuracy: 0.8636\n",
      "Epoch 1289/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6025 - accuracy: 0.8636\n",
      "Epoch 1290/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6025 - accuracy: 0.8636\n",
      "Epoch 1291/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6024 - accuracy: 0.8636\n",
      "Epoch 1292/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6024 - accuracy: 0.8636\n",
      "Epoch 1293/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.8636\n",
      "Epoch 1294/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.8636\n",
      "Epoch 1295/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.8636\n",
      "Epoch 1296/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6022 - accuracy: 0.8636\n",
      "Epoch 1297/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6022 - accuracy: 0.8636\n",
      "Epoch 1298/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6021 - accuracy: 0.8636\n",
      "Epoch 1299/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6021 - accuracy: 0.8636\n",
      "Epoch 1300/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6020 - accuracy: 0.8636\n",
      "Epoch 1301/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6020 - accuracy: 0.8636\n",
      "Epoch 1302/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6019 - accuracy: 0.8636\n",
      "Epoch 1303/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6019 - accuracy: 0.8636\n",
      "Epoch 1304/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6018 - accuracy: 0.8636\n",
      "Epoch 1305/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6018 - accuracy: 0.8636\n",
      "Epoch 1306/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6017 - accuracy: 0.8636\n",
      "Epoch 1307/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6017 - accuracy: 0.8636\n",
      "Epoch 1308/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.8636\n",
      "Epoch 1309/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.8636\n",
      "Epoch 1310/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6015 - accuracy: 0.8636\n",
      "Epoch 1311/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6015 - accuracy: 0.8636\n",
      "Epoch 1312/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6014 - accuracy: 0.8636\n",
      "Epoch 1313/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6014 - accuracy: 0.8636\n",
      "Epoch 1314/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6013 - accuracy: 0.8636\n",
      "Epoch 1315/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6013 - accuracy: 0.8636\n",
      "Epoch 1316/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6012 - accuracy: 0.8636\n",
      "Epoch 1317/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6012 - accuracy: 0.8636\n",
      "Epoch 1318/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.8636\n",
      "Epoch 1319/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6011 - accuracy: 0.8636\n",
      "Epoch 1320/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6010 - accuracy: 0.8636\n",
      "Epoch 1321/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6010 - accuracy: 0.8636\n",
      "Epoch 1322/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6009 - accuracy: 0.8636\n",
      "Epoch 1323/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6009 - accuracy: 0.8636\n",
      "Epoch 1324/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6009 - accuracy: 0.8636\n",
      "Epoch 1325/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6008 - accuracy: 0.8636\n",
      "Epoch 1326/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6008 - accuracy: 0.8636\n",
      "Epoch 1327/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.8636\n",
      "Epoch 1328/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.8636\n",
      "Epoch 1329/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6006 - accuracy: 0.8636\n",
      "Epoch 1330/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6006 - accuracy: 0.8636\n",
      "Epoch 1331/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6005 - accuracy: 0.8636\n",
      "Epoch 1332/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6005 - accuracy: 0.8636\n",
      "Epoch 1333/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6004 - accuracy: 0.8636\n",
      "Epoch 1334/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6004 - accuracy: 0.8636\n",
      "Epoch 1335/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6003 - accuracy: 0.8636\n",
      "Epoch 1336/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6003 - accuracy: 0.8636\n",
      "Epoch 1337/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6002 - accuracy: 0.8636\n",
      "Epoch 1338/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6002 - accuracy: 0.8636\n",
      "Epoch 1339/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.8636\n",
      "Epoch 1340/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.8636\n",
      "Epoch 1341/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.8636\n",
      "Epoch 1342/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.8636\n",
      "Epoch 1343/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5999 - accuracy: 0.8636\n",
      "Epoch 1344/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5999 - accuracy: 0.8636\n",
      "Epoch 1345/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5998 - accuracy: 0.8636\n",
      "Epoch 1346/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5998 - accuracy: 0.8636\n",
      "Epoch 1347/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5997 - accuracy: 0.8636\n",
      "Epoch 1348/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5997 - accuracy: 0.8636\n",
      "Epoch 1349/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5996 - accuracy: 0.8636\n",
      "Epoch 1350/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5996 - accuracy: 0.8636\n",
      "Epoch 1351/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.8636\n",
      "Epoch 1352/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5995 - accuracy: 0.8636\n",
      "Epoch 1353/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5995 - accuracy: 0.8636\n",
      "Epoch 1354/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.8636\n",
      "Epoch 1355/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.8636\n",
      "Epoch 1356/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5993 - accuracy: 0.8636\n",
      "Epoch 1357/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5993 - accuracy: 0.8636\n",
      "Epoch 1358/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5992 - accuracy: 0.8636\n",
      "Epoch 1359/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.8636\n",
      "Epoch 1360/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5991 - accuracy: 0.8636\n",
      "Epoch 1361/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5991 - accuracy: 0.8636\n",
      "Epoch 1362/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.8636\n",
      "Epoch 1363/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.8636\n",
      "Epoch 1364/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5989 - accuracy: 0.8636\n",
      "Epoch 1365/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5989 - accuracy: 0.8636\n",
      "Epoch 1366/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5988 - accuracy: 0.8636\n",
      "Epoch 1367/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5988 - accuracy: 0.8636\n",
      "Epoch 1368/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5987 - accuracy: 0.8636\n",
      "Epoch 1369/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.8636\n",
      "Epoch 1370/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5986 - accuracy: 0.8636\n",
      "Epoch 1371/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5986 - accuracy: 0.8636\n",
      "Epoch 1372/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5985 - accuracy: 0.8636\n",
      "Epoch 1373/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5985 - accuracy: 0.8636\n",
      "Epoch 1374/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5984 - accuracy: 0.8636\n",
      "Epoch 1375/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5984 - accuracy: 0.8636\n",
      "Epoch 1376/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5983 - accuracy: 0.8636\n",
      "Epoch 1377/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5983 - accuracy: 0.8636\n",
      "Epoch 1378/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5982 - accuracy: 0.8636\n",
      "Epoch 1379/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5982 - accuracy: 0.8636\n",
      "Epoch 1380/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5981 - accuracy: 0.8636\n",
      "Epoch 1381/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5981 - accuracy: 0.8636\n",
      "Epoch 1382/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5980 - accuracy: 0.8636\n",
      "Epoch 1383/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5980 - accuracy: 0.8636\n",
      "Epoch 1384/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5980 - accuracy: 0.8636\n",
      "Epoch 1385/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5979 - accuracy: 0.8636\n",
      "Epoch 1386/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5979 - accuracy: 0.8636\n",
      "Epoch 1387/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5978 - accuracy: 0.8636\n",
      "Epoch 1388/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5978 - accuracy: 0.8636\n",
      "Epoch 1389/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5977 - accuracy: 0.8636\n",
      "Epoch 1390/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5977 - accuracy: 0.8636\n",
      "Epoch 1391/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.8636\n",
      "Epoch 1392/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5976 - accuracy: 0.8636\n",
      "Epoch 1393/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5975 - accuracy: 0.8636\n",
      "Epoch 1394/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5975 - accuracy: 0.8636\n",
      "Epoch 1395/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5974 - accuracy: 0.8636\n",
      "Epoch 1396/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5974 - accuracy: 0.8636\n",
      "Epoch 1397/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5973 - accuracy: 0.8636\n",
      "Epoch 1398/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5973 - accuracy: 0.8636\n",
      "Epoch 1399/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.8636\n",
      "Epoch 1400/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5972 - accuracy: 0.8636\n",
      "Epoch 1401/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.8636\n",
      "Epoch 1402/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.8636\n",
      "Epoch 1403/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5970 - accuracy: 0.8636\n",
      "Epoch 1404/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5970 - accuracy: 0.8636\n",
      "Epoch 1405/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5969 - accuracy: 0.8636\n",
      "Epoch 1406/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5969 - accuracy: 0.8636\n",
      "Epoch 1407/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5968 - accuracy: 0.8636\n",
      "Epoch 1408/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.8636\n",
      "Epoch 1409/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.8636\n",
      "Epoch 1410/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5967 - accuracy: 0.8636\n",
      "Epoch 1411/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5966 - accuracy: 0.8636\n",
      "Epoch 1412/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5966 - accuracy: 0.8636\n",
      "Epoch 1413/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.8636\n",
      "Epoch 1414/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.8636\n",
      "Epoch 1415/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5964 - accuracy: 0.8636\n",
      "Epoch 1416/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5964 - accuracy: 0.8636\n",
      "Epoch 1417/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.8636\n",
      "Epoch 1418/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.8636\n",
      "Epoch 1419/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.8636\n",
      "Epoch 1420/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5962 - accuracy: 0.8636\n",
      "Epoch 1421/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5962 - accuracy: 0.8636\n",
      "Epoch 1422/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.8636\n",
      "Epoch 1423/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.8636\n",
      "Epoch 1424/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5960 - accuracy: 0.8636\n",
      "Epoch 1425/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.8636\n",
      "Epoch 1426/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5959 - accuracy: 0.8636\n",
      "Epoch 1427/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5959 - accuracy: 0.8636\n",
      "Epoch 1428/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5958 - accuracy: 0.8636\n",
      "Epoch 1429/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5958 - accuracy: 0.8636\n",
      "Epoch 1430/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5957 - accuracy: 0.8636\n",
      "Epoch 1431/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5957 - accuracy: 0.8636\n",
      "Epoch 1432/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.8636\n",
      "Epoch 1433/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5956 - accuracy: 0.8636\n",
      "Epoch 1434/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.8636\n",
      "Epoch 1435/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.8636\n",
      "Epoch 1436/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.8636\n",
      "Epoch 1437/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5954 - accuracy: 0.8636\n",
      "Epoch 1438/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5953 - accuracy: 0.8636\n",
      "Epoch 1439/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5953 - accuracy: 0.8636\n",
      "Epoch 1440/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5952 - accuracy: 0.8636\n",
      "Epoch 1441/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.8636\n",
      "Epoch 1442/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.8636\n",
      "Epoch 1443/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.8636\n",
      "Epoch 1444/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5950 - accuracy: 0.8636\n",
      "Epoch 1445/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5950 - accuracy: 0.8636\n",
      "Epoch 1446/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5949 - accuracy: 0.8636\n",
      "Epoch 1447/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5949 - accuracy: 0.8636\n",
      "Epoch 1448/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5948 - accuracy: 0.8636\n",
      "Epoch 1449/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5948 - accuracy: 0.8636\n",
      "Epoch 1450/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5947 - accuracy: 0.8636\n",
      "Epoch 1451/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5947 - accuracy: 0.8636\n",
      "Epoch 1452/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5946 - accuracy: 0.8636\n",
      "Epoch 1453/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5946 - accuracy: 0.8636\n",
      "Epoch 1454/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5946 - accuracy: 0.8636\n",
      "Epoch 1455/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5945 - accuracy: 0.8636\n",
      "Epoch 1456/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5945 - accuracy: 0.8636\n",
      "Epoch 1457/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5944 - accuracy: 0.8636\n",
      "Epoch 1458/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5944 - accuracy: 0.8636\n",
      "Epoch 1459/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5943 - accuracy: 0.8636\n",
      "Epoch 1460/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.8636\n",
      "Epoch 1461/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5942 - accuracy: 0.8636\n",
      "Epoch 1462/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5942 - accuracy: 0.8636\n",
      "Epoch 1463/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5941 - accuracy: 0.8636\n",
      "Epoch 1464/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5941 - accuracy: 0.8636\n",
      "Epoch 1465/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5940 - accuracy: 0.8636\n",
      "Epoch 1466/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5940 - accuracy: 0.8636\n",
      "Epoch 1467/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5939 - accuracy: 0.8636\n",
      "Epoch 1468/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5939 - accuracy: 0.8636\n",
      "Epoch 1469/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5938 - accuracy: 0.8636\n",
      "Epoch 1470/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5938 - accuracy: 0.8636\n",
      "Epoch 1471/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5937 - accuracy: 0.8636\n",
      "Epoch 1472/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5937 - accuracy: 0.8636\n",
      "Epoch 1473/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5936 - accuracy: 0.8636\n",
      "Epoch 1474/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5936 - accuracy: 0.8636\n",
      "Epoch 1475/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5935 - accuracy: 0.8636\n",
      "Epoch 1476/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5935 - accuracy: 0.8636\n",
      "Epoch 1477/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5934 - accuracy: 0.8636\n",
      "Epoch 1478/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5934 - accuracy: 0.8636\n",
      "Epoch 1479/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5933 - accuracy: 0.8636\n",
      "Epoch 1480/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5933 - accuracy: 0.8636\n",
      "Epoch 1481/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5932 - accuracy: 0.8636\n",
      "Epoch 1482/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5932 - accuracy: 0.8636\n",
      "Epoch 1483/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5931 - accuracy: 0.8636\n",
      "Epoch 1484/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5931 - accuracy: 0.8636\n",
      "Epoch 1485/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5930 - accuracy: 0.8636\n",
      "Epoch 1486/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5930 - accuracy: 0.8636\n",
      "Epoch 1487/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5929 - accuracy: 0.8636\n",
      "Epoch 1488/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5929 - accuracy: 0.8636\n",
      "Epoch 1489/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5928 - accuracy: 0.8636\n",
      "Epoch 1490/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5928 - accuracy: 0.8636\n",
      "Epoch 1491/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5928 - accuracy: 0.8636\n",
      "Epoch 1492/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.8636\n",
      "Epoch 1493/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5927 - accuracy: 0.8636\n",
      "Epoch 1494/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.8636\n",
      "Epoch 1495/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5926 - accuracy: 0.8636\n",
      "Epoch 1496/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5925 - accuracy: 0.8636\n",
      "Epoch 1497/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5925 - accuracy: 0.8636\n",
      "Epoch 1498/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5924 - accuracy: 0.8636\n",
      "Epoch 1499/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5924 - accuracy: 0.8636\n",
      "Epoch 1500/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5923 - accuracy: 0.8636\n",
      "Epoch 1501/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5923 - accuracy: 0.8636\n",
      "Epoch 1502/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.8636\n",
      "Epoch 1503/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5922 - accuracy: 0.8636\n",
      "Epoch 1504/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5921 - accuracy: 0.8636\n",
      "Epoch 1505/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5921 - accuracy: 0.8636\n",
      "Epoch 1506/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5920 - accuracy: 0.8636\n",
      "Epoch 1507/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5920 - accuracy: 0.8636\n",
      "Epoch 1508/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5919 - accuracy: 0.8636\n",
      "Epoch 1509/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5919 - accuracy: 0.8636\n",
      "Epoch 1510/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.8636\n",
      "Epoch 1511/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.8636\n",
      "Epoch 1512/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.8636\n",
      "Epoch 1513/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5917 - accuracy: 0.8636\n",
      "Epoch 1514/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.8636\n",
      "Epoch 1515/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.8636\n",
      "Epoch 1516/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5915 - accuracy: 0.8636\n",
      "Epoch 1517/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5915 - accuracy: 0.8636\n",
      "Epoch 1518/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5914 - accuracy: 0.8636\n",
      "Epoch 1519/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5914 - accuracy: 0.8636\n",
      "Epoch 1520/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5913 - accuracy: 0.8636\n",
      "Epoch 1521/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5913 - accuracy: 0.8636\n",
      "Epoch 1522/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.8636\n",
      "Epoch 1523/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.8636\n",
      "Epoch 1524/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5911 - accuracy: 0.8636\n",
      "Epoch 1525/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.8636\n",
      "Epoch 1526/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.8636\n",
      "Epoch 1527/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.8636\n",
      "Epoch 1528/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.8636\n",
      "Epoch 1529/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.8636\n",
      "Epoch 1530/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5909 - accuracy: 0.8636\n",
      "Epoch 1531/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.8636\n",
      "Epoch 1532/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.8636\n",
      "Epoch 1533/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5907 - accuracy: 0.8636\n",
      "Epoch 1534/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5907 - accuracy: 0.8636\n",
      "Epoch 1535/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.8636\n",
      "Epoch 1536/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5906 - accuracy: 0.8636\n",
      "Epoch 1537/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.8636\n",
      "Epoch 1538/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.8636\n",
      "Epoch 1539/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.8636\n",
      "Epoch 1540/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5904 - accuracy: 0.8636\n",
      "Epoch 1541/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5903 - accuracy: 0.8636\n",
      "Epoch 1542/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5903 - accuracy: 0.8636\n",
      "Epoch 1543/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.8636\n",
      "Epoch 1544/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.8636\n",
      "Epoch 1545/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.8636\n",
      "Epoch 1546/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.8636\n",
      "Epoch 1547/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.8636\n",
      "Epoch 1548/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.8636\n",
      "Epoch 1549/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5899 - accuracy: 0.8636\n",
      "Epoch 1550/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5899 - accuracy: 0.8636\n",
      "Epoch 1551/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.8636\n",
      "Epoch 1552/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.8636\n",
      "Epoch 1553/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.8636\n",
      "Epoch 1554/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5897 - accuracy: 0.8636\n",
      "Epoch 1555/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5896 - accuracy: 0.8636\n",
      "Epoch 1556/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5896 - accuracy: 0.8636\n",
      "Epoch 1557/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5895 - accuracy: 0.8636\n",
      "Epoch 1558/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5895 - accuracy: 0.8636\n",
      "Epoch 1559/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.8636\n",
      "Epoch 1560/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5894 - accuracy: 0.8636\n",
      "Epoch 1561/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5893 - accuracy: 0.8636\n",
      "Epoch 1562/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5893 - accuracy: 0.8636\n",
      "Epoch 1563/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.8636\n",
      "Epoch 1564/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5892 - accuracy: 0.8636\n",
      "Epoch 1565/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5891 - accuracy: 0.8636\n",
      "Epoch 1566/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.8636\n",
      "Epoch 1567/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.8636\n",
      "Epoch 1568/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.8636\n",
      "Epoch 1569/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5890 - accuracy: 0.8636\n",
      "Epoch 1570/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.8636\n",
      "Epoch 1571/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.8636\n",
      "Epoch 1572/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.8636\n",
      "Epoch 1573/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.8636\n",
      "Epoch 1574/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5887 - accuracy: 0.8636\n",
      "Epoch 1575/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5887 - accuracy: 0.8636\n",
      "Epoch 1576/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.8636\n",
      "Epoch 1577/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5886 - accuracy: 0.8636\n",
      "Epoch 1578/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5885 - accuracy: 0.8636\n",
      "Epoch 1579/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5885 - accuracy: 0.8636\n",
      "Epoch 1580/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5884 - accuracy: 0.8636\n",
      "Epoch 1581/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5884 - accuracy: 0.8636\n",
      "Epoch 1582/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5883 - accuracy: 0.8636\n",
      "Epoch 1583/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5883 - accuracy: 0.8636\n",
      "Epoch 1584/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5882 - accuracy: 0.8636\n",
      "Epoch 1585/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5882 - accuracy: 0.8636\n",
      "Epoch 1586/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5881 - accuracy: 0.8636\n",
      "Epoch 1587/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5881 - accuracy: 0.8636\n",
      "Epoch 1588/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5880 - accuracy: 0.8636\n",
      "Epoch 1589/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5880 - accuracy: 0.8636\n",
      "Epoch 1590/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5879 - accuracy: 0.8636\n",
      "Epoch 1591/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5879 - accuracy: 0.8636\n",
      "Epoch 1592/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5878 - accuracy: 0.8636\n",
      "Epoch 1593/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5878 - accuracy: 0.8636\n",
      "Epoch 1594/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5877 - accuracy: 0.8636\n",
      "Epoch 1595/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5877 - accuracy: 0.8636\n",
      "Epoch 1596/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5876 - accuracy: 0.8636\n",
      "Epoch 1597/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5876 - accuracy: 0.8636\n",
      "Epoch 1598/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5875 - accuracy: 0.8636\n",
      "Epoch 1599/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5875 - accuracy: 0.8636\n",
      "Epoch 1600/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5874 - accuracy: 0.8636\n",
      "Epoch 1601/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.8636\n",
      "Epoch 1602/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.8636\n",
      "Epoch 1603/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5873 - accuracy: 0.8636\n",
      "Epoch 1604/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5872 - accuracy: 0.8636\n",
      "Epoch 1605/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5872 - accuracy: 0.8636\n",
      "Epoch 1606/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5871 - accuracy: 0.8636\n",
      "Epoch 1607/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5871 - accuracy: 0.8636\n",
      "Epoch 1608/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5871 - accuracy: 0.8636\n",
      "Epoch 1609/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.8636\n",
      "Epoch 1610/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5870 - accuracy: 0.8636\n",
      "Epoch 1611/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5869 - accuracy: 0.8636\n",
      "Epoch 1612/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5869 - accuracy: 0.8636\n",
      "Epoch 1613/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.8636\n",
      "Epoch 1614/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5868 - accuracy: 0.8636\n",
      "Epoch 1615/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5867 - accuracy: 0.8636\n",
      "Epoch 1616/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5867 - accuracy: 0.8636\n",
      "Epoch 1617/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.8636\n",
      "Epoch 1618/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.8636\n",
      "Epoch 1619/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5865 - accuracy: 0.8636\n",
      "Epoch 1620/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5865 - accuracy: 0.8636\n",
      "Epoch 1621/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5864 - accuracy: 0.8636\n",
      "Epoch 1622/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 0.8636\n",
      "Epoch 1623/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.8636\n",
      "Epoch 1624/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5863 - accuracy: 0.8636\n",
      "Epoch 1625/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5862 - accuracy: 0.8636\n",
      "Epoch 1626/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5862 - accuracy: 0.8636\n",
      "Epoch 1627/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5861 - accuracy: 0.8636\n",
      "Epoch 1628/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.8636\n",
      "Epoch 1629/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.8636\n",
      "Epoch 1630/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.8636\n",
      "Epoch 1631/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5859 - accuracy: 0.8636\n",
      "Epoch 1632/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5859 - accuracy: 0.8636\n",
      "Epoch 1633/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.8636\n",
      "Epoch 1634/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5858 - accuracy: 0.8636\n",
      "Epoch 1635/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5857 - accuracy: 0.8636\n",
      "Epoch 1636/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.8636\n",
      "Epoch 1637/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.8636\n",
      "Epoch 1638/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.8636\n",
      "Epoch 1639/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5855 - accuracy: 0.8636\n",
      "Epoch 1640/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.8636\n",
      "Epoch 1641/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.8636\n",
      "Epoch 1642/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.8636\n",
      "Epoch 1643/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5853 - accuracy: 0.8636\n",
      "Epoch 1644/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5853 - accuracy: 0.8636\n",
      "Epoch 1645/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.8636\n",
      "Epoch 1646/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.8636\n",
      "Epoch 1647/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5852 - accuracy: 0.8636\n",
      "Epoch 1648/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5851 - accuracy: 0.8636\n",
      "Epoch 1649/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.8636\n",
      "Epoch 1650/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5850 - accuracy: 0.8636\n",
      "Epoch 1651/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5850 - accuracy: 0.8636\n",
      "Epoch 1652/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5849 - accuracy: 0.8636\n",
      "Epoch 1653/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5849 - accuracy: 0.8636\n",
      "Epoch 1654/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5848 - accuracy: 0.8636\n",
      "Epoch 1655/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5848 - accuracy: 0.8636\n",
      "Epoch 1656/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5847 - accuracy: 0.8636\n",
      "Epoch 1657/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.8636\n",
      "Epoch 1658/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.8636\n",
      "Epoch 1659/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.8636\n",
      "Epoch 1660/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5845 - accuracy: 0.8636\n",
      "Epoch 1661/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5845 - accuracy: 0.8636\n",
      "Epoch 1662/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.8636\n",
      "Epoch 1663/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.8636\n",
      "Epoch 1664/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.8636\n",
      "Epoch 1665/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5843 - accuracy: 0.8636\n",
      "Epoch 1666/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5842 - accuracy: 0.8636\n",
      "Epoch 1667/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5842 - accuracy: 0.8636\n",
      "Epoch 1668/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5841 - accuracy: 0.8636\n",
      "Epoch 1669/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5841 - accuracy: 0.8636\n",
      "Epoch 1670/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5840 - accuracy: 0.8636\n",
      "Epoch 1671/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.8636\n",
      "Epoch 1672/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5839 - accuracy: 0.8636\n",
      "Epoch 1673/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.8636\n",
      "Epoch 1674/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5838 - accuracy: 0.8636\n",
      "Epoch 1675/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5838 - accuracy: 0.8636\n",
      "Epoch 1676/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5837 - accuracy: 0.8636\n",
      "Epoch 1677/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5837 - accuracy: 0.8636\n",
      "Epoch 1678/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.8636\n",
      "Epoch 1679/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.8636\n",
      "Epoch 1680/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5835 - accuracy: 0.8636\n",
      "Epoch 1681/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5835 - accuracy: 0.8636\n",
      "Epoch 1682/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.8636\n",
      "Epoch 1683/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.8636\n",
      "Epoch 1684/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.8636\n",
      "Epoch 1685/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.8636\n",
      "Epoch 1686/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.8636\n",
      "Epoch 1687/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.8636\n",
      "Epoch 1688/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5832 - accuracy: 0.8636\n",
      "Epoch 1689/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5831 - accuracy: 0.8636\n",
      "Epoch 1690/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.8636\n",
      "Epoch 1691/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.8636\n",
      "Epoch 1692/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.8636\n",
      "Epoch 1693/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.8636\n",
      "Epoch 1694/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.8636\n",
      "Epoch 1695/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5828 - accuracy: 0.8636\n",
      "Epoch 1696/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.8636\n",
      "Epoch 1697/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.8636\n",
      "Epoch 1698/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.8636\n",
      "Epoch 1699/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.8636\n",
      "Epoch 1700/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.8636\n",
      "Epoch 1701/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.8636\n",
      "Epoch 1702/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5825 - accuracy: 0.8636\n",
      "Epoch 1703/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.8636\n",
      "Epoch 1704/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.8636\n",
      "Epoch 1705/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5823 - accuracy: 0.8636\n",
      "Epoch 1706/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5823 - accuracy: 0.8636\n",
      "Epoch 1707/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.8636\n",
      "Epoch 1708/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.8636\n",
      "Epoch 1709/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.8636\n",
      "Epoch 1710/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.8636\n",
      "Epoch 1711/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5820 - accuracy: 0.8636\n",
      "Epoch 1712/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.8636\n",
      "Epoch 1713/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.8636\n",
      "Epoch 1714/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.8636\n",
      "Epoch 1715/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5818 - accuracy: 0.8636\n",
      "Epoch 1716/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.8636\n",
      "Epoch 1717/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.8636\n",
      "Epoch 1718/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.8636\n",
      "Epoch 1719/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.8636\n",
      "Epoch 1720/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.8636\n",
      "Epoch 1721/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.8636\n",
      "Epoch 1722/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.8636\n",
      "Epoch 1723/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5815 - accuracy: 0.8636\n",
      "Epoch 1724/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.8636\n",
      "Epoch 1725/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.8636\n",
      "Epoch 1726/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.8636\n",
      "Epoch 1727/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5813 - accuracy: 0.8636\n",
      "Epoch 1728/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.8636\n",
      "Epoch 1729/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5812 - accuracy: 0.8636\n",
      "Epoch 1730/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.8636\n",
      "Epoch 1731/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.8636\n",
      "Epoch 1732/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5810 - accuracy: 0.8636\n",
      "Epoch 1733/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5810 - accuracy: 0.8636\n",
      "Epoch 1734/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.8636\n",
      "Epoch 1735/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5809 - accuracy: 0.8636\n",
      "Epoch 1736/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5808 - accuracy: 0.8636\n",
      "Epoch 1737/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.8636\n",
      "Epoch 1738/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5807 - accuracy: 0.8636\n",
      "Epoch 1739/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5807 - accuracy: 0.8636\n",
      "Epoch 1740/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5806 - accuracy: 0.8636\n",
      "Epoch 1741/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5806 - accuracy: 0.8636\n",
      "Epoch 1742/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.8636\n",
      "Epoch 1743/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5805 - accuracy: 0.8636\n",
      "Epoch 1744/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.8636\n",
      "Epoch 1745/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5804 - accuracy: 0.8636\n",
      "Epoch 1746/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5803 - accuracy: 0.8636\n",
      "Epoch 1747/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.8636\n",
      "Epoch 1748/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.8636\n",
      "Epoch 1749/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.8636\n",
      "Epoch 1750/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.8636\n",
      "Epoch 1751/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5801 - accuracy: 0.8636\n",
      "Epoch 1752/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5800 - accuracy: 0.8636\n",
      "Epoch 1753/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5800 - accuracy: 0.8636\n",
      "Epoch 1754/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.8636\n",
      "Epoch 1755/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5799 - accuracy: 0.8636\n",
      "Epoch 1756/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5799 - accuracy: 0.8636\n",
      "Epoch 1757/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5798 - accuracy: 0.8636\n",
      "Epoch 1758/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5798 - accuracy: 0.8636\n",
      "Epoch 1759/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5797 - accuracy: 0.8636\n",
      "Epoch 1760/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5797 - accuracy: 0.8636\n",
      "Epoch 1761/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.8636\n",
      "Epoch 1762/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.8636\n",
      "Epoch 1763/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.8636\n",
      "Epoch 1764/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.8636\n",
      "Epoch 1765/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.8636\n",
      "Epoch 1766/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.8636\n",
      "Epoch 1767/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.8636\n",
      "Epoch 1768/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.8636\n",
      "Epoch 1769/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5792 - accuracy: 0.8636\n",
      "Epoch 1770/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5792 - accuracy: 0.8636\n",
      "Epoch 1771/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5791 - accuracy: 0.8636\n",
      "Epoch 1772/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5791 - accuracy: 0.8636\n",
      "Epoch 1773/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5790 - accuracy: 0.8636\n",
      "Epoch 1774/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.8636\n",
      "Epoch 1775/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.8636\n",
      "Epoch 1776/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5789 - accuracy: 0.8636\n",
      "Epoch 1777/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.8636\n",
      "Epoch 1778/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5788 - accuracy: 0.8636\n",
      "Epoch 1779/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5787 - accuracy: 0.8636\n",
      "Epoch 1780/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5787 - accuracy: 0.8636\n",
      "Epoch 1781/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.8636\n",
      "Epoch 1782/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5786 - accuracy: 0.8636\n",
      "Epoch 1783/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.8636\n",
      "Epoch 1784/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.8636\n",
      "Epoch 1785/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.8636\n",
      "Epoch 1786/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5784 - accuracy: 0.8636\n",
      "Epoch 1787/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.8636\n",
      "Epoch 1788/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.8636\n",
      "Epoch 1789/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.8636\n",
      "Epoch 1790/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5782 - accuracy: 0.8636\n",
      "Epoch 1791/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.8636\n",
      "Epoch 1792/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5781 - accuracy: 0.8636\n",
      "Epoch 1793/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.8636\n",
      "Epoch 1794/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5780 - accuracy: 0.8636\n",
      "Epoch 1795/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5780 - accuracy: 0.8636\n",
      "Epoch 1796/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5779 - accuracy: 0.8636\n",
      "Epoch 1797/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5779 - accuracy: 0.8636\n",
      "Epoch 1798/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5778 - accuracy: 0.8636\n",
      "Epoch 1799/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5778 - accuracy: 0.8636\n",
      "Epoch 1800/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5777 - accuracy: 0.8636\n",
      "Epoch 1801/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5777 - accuracy: 0.8636\n",
      "Epoch 1802/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5776 - accuracy: 0.8636\n",
      "Epoch 1803/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5776 - accuracy: 0.8636\n",
      "Epoch 1804/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5775 - accuracy: 0.8636\n",
      "Epoch 1805/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5775 - accuracy: 0.8636\n",
      "Epoch 1806/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5774 - accuracy: 0.8636\n",
      "Epoch 1807/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5774 - accuracy: 0.8636\n",
      "Epoch 1808/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5773 - accuracy: 0.8636\n",
      "Epoch 1809/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5773 - accuracy: 0.8636\n",
      "Epoch 1810/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5772 - accuracy: 0.8636\n",
      "Epoch 1811/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5772 - accuracy: 0.8636\n",
      "Epoch 1812/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.8636\n",
      "Epoch 1813/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5771 - accuracy: 0.8636\n",
      "Epoch 1814/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5770 - accuracy: 0.8636\n",
      "Epoch 1815/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.8636\n",
      "Epoch 1816/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5769 - accuracy: 0.8636\n",
      "Epoch 1817/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5769 - accuracy: 0.8636\n",
      "Epoch 1818/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5768 - accuracy: 0.8636\n",
      "Epoch 1819/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5768 - accuracy: 0.8636\n",
      "Epoch 1820/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5768 - accuracy: 0.8636\n",
      "Epoch 1821/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5767 - accuracy: 0.8636\n",
      "Epoch 1822/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5767 - accuracy: 0.8636\n",
      "Epoch 1823/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5766 - accuracy: 0.8636\n",
      "Epoch 1824/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5766 - accuracy: 0.8636\n",
      "Epoch 1825/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.8636\n",
      "Epoch 1826/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5765 - accuracy: 0.8636\n",
      "Epoch 1827/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5764 - accuracy: 0.8636\n",
      "Epoch 1828/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.8636\n",
      "Epoch 1829/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.8636\n",
      "Epoch 1830/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.8636\n",
      "Epoch 1831/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.8636\n",
      "Epoch 1832/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.8636\n",
      "Epoch 1833/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.8636\n",
      "Epoch 1834/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.8636\n",
      "Epoch 1835/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5760 - accuracy: 0.8636\n",
      "Epoch 1836/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5760 - accuracy: 0.8636\n",
      "Epoch 1837/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5759 - accuracy: 0.8636\n",
      "Epoch 1838/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5759 - accuracy: 0.8636\n",
      "Epoch 1839/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.8636\n",
      "Epoch 1840/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.8636\n",
      "Epoch 1841/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5757 - accuracy: 0.8636\n",
      "Epoch 1842/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5757 - accuracy: 0.8636\n",
      "Epoch 1843/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.8636\n",
      "Epoch 1844/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.8636\n",
      "Epoch 1845/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5755 - accuracy: 0.8636\n",
      "Epoch 1846/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5755 - accuracy: 0.8636\n",
      "Epoch 1847/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5754 - accuracy: 0.8636\n",
      "Epoch 1848/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5754 - accuracy: 0.8636\n",
      "Epoch 1849/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5754 - accuracy: 0.8636\n",
      "Epoch 1850/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5753 - accuracy: 0.8636\n",
      "Epoch 1851/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.8636\n",
      "Epoch 1852/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5752 - accuracy: 0.8636\n",
      "Epoch 1853/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5752 - accuracy: 0.8636\n",
      "Epoch 1854/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5751 - accuracy: 0.8636\n",
      "Epoch 1855/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5751 - accuracy: 0.8636\n",
      "Epoch 1856/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.8636\n",
      "Epoch 1857/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.8636\n",
      "Epoch 1858/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5749 - accuracy: 0.8636\n",
      "Epoch 1859/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5749 - accuracy: 0.8636\n",
      "Epoch 1860/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.8636\n",
      "Epoch 1861/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.8636\n",
      "Epoch 1862/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.8636\n",
      "Epoch 1863/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.8636\n",
      "Epoch 1864/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5746 - accuracy: 0.8636\n",
      "Epoch 1865/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5746 - accuracy: 0.8636\n",
      "Epoch 1866/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.8636\n",
      "Epoch 1867/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5745 - accuracy: 0.8636\n",
      "Epoch 1868/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5744 - accuracy: 0.8636\n",
      "Epoch 1869/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5744 - accuracy: 0.8636\n",
      "Epoch 1870/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.8636\n",
      "Epoch 1871/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5743 - accuracy: 0.8636\n",
      "Epoch 1872/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.8636\n",
      "Epoch 1873/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.8636\n",
      "Epoch 1874/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5741 - accuracy: 0.8636\n",
      "Epoch 1875/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5741 - accuracy: 0.8636\n",
      "Epoch 1876/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.8636\n",
      "Epoch 1877/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.8636\n",
      "Epoch 1878/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.8636\n",
      "Epoch 1879/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5739 - accuracy: 0.8636\n",
      "Epoch 1880/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5739 - accuracy: 0.8636\n",
      "Epoch 1881/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.8636\n",
      "Epoch 1882/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.8636\n",
      "Epoch 1883/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.8636\n",
      "Epoch 1884/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.8636\n",
      "Epoch 1885/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.8636\n",
      "Epoch 1886/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.8636\n",
      "Epoch 1887/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5735 - accuracy: 0.8636\n",
      "Epoch 1888/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5735 - accuracy: 0.8636\n",
      "Epoch 1889/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.8636\n",
      "Epoch 1890/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.8636\n",
      "Epoch 1891/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5733 - accuracy: 0.8636\n",
      "Epoch 1892/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5733 - accuracy: 0.8636\n",
      "Epoch 1893/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5732 - accuracy: 0.8636\n",
      "Epoch 1894/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.8636\n",
      "Epoch 1895/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.8636\n",
      "Epoch 1896/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.8636\n",
      "Epoch 1897/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.8636\n",
      "Epoch 1898/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5730 - accuracy: 0.8636\n",
      "Epoch 1899/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5729 - accuracy: 0.8636\n",
      "Epoch 1900/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5729 - accuracy: 0.8636\n",
      "Epoch 1901/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5728 - accuracy: 0.8636\n",
      "Epoch 1902/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5728 - accuracy: 0.8636\n",
      "Epoch 1903/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.8636\n",
      "Epoch 1904/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.8636\n",
      "Epoch 1905/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.8636\n",
      "Epoch 1906/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5726 - accuracy: 0.8636\n",
      "Epoch 1907/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.8636\n",
      "Epoch 1908/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.8636\n",
      "Epoch 1909/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.8636\n",
      "Epoch 1910/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.8636\n",
      "Epoch 1911/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.8636\n",
      "Epoch 1912/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.8636\n",
      "Epoch 1913/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5723 - accuracy: 0.8636\n",
      "Epoch 1914/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.8636\n",
      "Epoch 1915/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5722 - accuracy: 0.8636\n",
      "Epoch 1916/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5721 - accuracy: 0.8636\n",
      "Epoch 1917/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5721 - accuracy: 0.8636\n",
      "Epoch 1918/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5720 - accuracy: 0.8636\n",
      "Epoch 1919/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.8636\n",
      "Epoch 1920/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5719 - accuracy: 0.8636\n",
      "Epoch 1921/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5719 - accuracy: 0.8636\n",
      "Epoch 1922/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.8636\n",
      "Epoch 1923/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.8636\n",
      "Epoch 1924/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.8636\n",
      "Epoch 1925/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.8636\n",
      "Epoch 1926/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5716 - accuracy: 0.8636\n",
      "Epoch 1927/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5716 - accuracy: 0.8636\n",
      "Epoch 1928/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5716 - accuracy: 0.8636\n",
      "Epoch 1929/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5715 - accuracy: 0.8636\n",
      "Epoch 1930/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5715 - accuracy: 0.8636\n",
      "Epoch 1931/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5714 - accuracy: 0.8636\n",
      "Epoch 1932/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5714 - accuracy: 0.8636\n",
      "Epoch 1933/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.8636\n",
      "Epoch 1934/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.8636\n",
      "Epoch 1935/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5712 - accuracy: 0.8636\n",
      "Epoch 1936/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5712 - accuracy: 0.8636\n",
      "Epoch 1937/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.8636\n",
      "Epoch 1938/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.8636\n",
      "Epoch 1939/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5710 - accuracy: 0.8636\n",
      "Epoch 1940/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5710 - accuracy: 0.8636\n",
      "Epoch 1941/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.8636\n",
      "Epoch 1942/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.8636\n",
      "Epoch 1943/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.8636\n",
      "Epoch 1944/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.8636\n",
      "Epoch 1945/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.8636\n",
      "Epoch 1946/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.8636\n",
      "Epoch 1947/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.8636\n",
      "Epoch 1948/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5706 - accuracy: 0.8636\n",
      "Epoch 1949/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.8636\n",
      "Epoch 1950/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.8636\n",
      "Epoch 1951/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.8636\n",
      "Epoch 1952/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.8636\n",
      "Epoch 1953/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.8636\n",
      "Epoch 1954/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.8636\n",
      "Epoch 1955/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.8636\n",
      "Epoch 1956/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.8636\n",
      "Epoch 1957/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5702 - accuracy: 0.8636\n",
      "Epoch 1958/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5701 - accuracy: 0.8636\n",
      "Epoch 1959/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.8636\n",
      "Epoch 1960/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.8636\n",
      "Epoch 1961/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5700 - accuracy: 0.8636\n",
      "Epoch 1962/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.8636\n",
      "Epoch 1963/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.8636\n",
      "Epoch 1964/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.8636\n",
      "Epoch 1965/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5698 - accuracy: 0.8636\n",
      "Epoch 1966/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.8636\n",
      "Epoch 1967/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.8636\n",
      "Epoch 1968/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.8636\n",
      "Epoch 1969/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5696 - accuracy: 0.8636\n",
      "Epoch 1970/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5695 - accuracy: 0.8636\n",
      "Epoch 1971/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5695 - accuracy: 0.8636\n",
      "Epoch 1972/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5694 - accuracy: 0.8636\n",
      "Epoch 1973/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5694 - accuracy: 0.8636\n",
      "Epoch 1974/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5693 - accuracy: 0.8636\n",
      "Epoch 1975/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5693 - accuracy: 0.8636\n",
      "Epoch 1976/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5693 - accuracy: 0.8636\n",
      "Epoch 1977/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.8636\n",
      "Epoch 1978/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.8636\n",
      "Epoch 1979/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.8636\n",
      "Epoch 1980/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.8636\n",
      "Epoch 1981/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.8636\n",
      "Epoch 1982/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.8636\n",
      "Epoch 1983/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5689 - accuracy: 0.8636\n",
      "Epoch 1984/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5689 - accuracy: 0.8636\n",
      "Epoch 1985/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.8636\n",
      "Epoch 1986/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.8636\n",
      "Epoch 1987/2000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.8636\n",
      "Epoch 1988/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.8636\n",
      "Epoch 1989/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5686 - accuracy: 0.8636\n",
      "Epoch 1990/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5686 - accuracy: 0.8636\n",
      "Epoch 1991/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5685 - accuracy: 0.8636\n",
      "Epoch 1992/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5685 - accuracy: 0.8636\n",
      "Epoch 1993/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.8636\n",
      "Epoch 1994/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.8636\n",
      "Epoch 1995/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5683 - accuracy: 0.8636\n",
      "Epoch 1996/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5683 - accuracy: 0.8636\n",
      "Epoch 1997/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5683 - accuracy: 0.8636\n",
      "Epoch 1998/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5682 - accuracy: 0.8636\n",
      "Epoch 1999/2000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5682 - accuracy: 0.8636\n",
      "Epoch 2000/2000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.8636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17e978d6388>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model attributes\n",
    "# 1 - one neuron\n",
    "# input_shape = (2, ) - 2 independent attributes\n",
    "# activation = 'sigmoid' - activation function\n",
    "# loss = 'binary_crossentropy' - loss function (log loss)\n",
    "# kernel_initializer = 'ones' - initializer for the weights\n",
    "# bias_initializer = 'zeros' - initializer for the bias\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(1, input_shape=(2,), activation='sigmoid', kernel_initializer='ones', bias_initializer='zeros'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 182ms/step - loss: 0.5763 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5762953758239746, 1.0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55879223],\n",
       "       [0.5293582 ],\n",
       "       [0.56713575],\n",
       "       [0.60414857],\n",
       "       [0.5960103 ],\n",
       "       [0.47853637]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#construct a confusion matrix\n",
    "y_pred_class = np.where(y_pred > 0.5, 1, 0)\n",
    "y_pred_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[1, 0],\n",
       "       [0, 5]])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consfusion matrix from tensorflow\n",
    "tf.math.confusion_matrix(y_test, y_pred_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weights and biases after the last epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight 1: [1.6956285]\n",
      "Weight 2: [0.63263583]\n",
      "Bias: [-1.1933192]\n"
     ]
    }
   ],
   "source": [
    "coef, intercept = model.get_weights()\n",
    "\n",
    "print(\"Weight 1: \" + str(coef[0]))\n",
    "print(\"Weight 2: \" + str(coef[1]))\n",
    "\n",
    "print(\"Bias: \" + str(intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Tensorflow - (From Scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_function(age, affordance):\n",
    "    return sigmoid(coef[0]*age + coef[1]*affordance + intercept) # sigmoid of weighted sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5587923], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_function(.47, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(age              0.47\n",
       " affordibility    1.00\n",
       " Name: 2, dtype: float64,\n",
       " array([0.55879223], dtype=float32))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled.iloc[0, :], y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, the prediction_function and tensorflow model are giving the same output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the logarithmic loss\n",
    "\n",
    "def log_loss(y_true, y_predicted):\n",
    "    epsilon = 1e-15\n",
    "    y_predicted_new = [max(i, epsilon) for i in y_predicted]\n",
    "    y_predicted_new = [min(i, 1-epsilon) for i in y_predicted_new]\n",
    "    y_predicted_new = np.array(y_predicted_new)\n",
    "    return -np.mean(y_true*np.log(y_predicted_new)+(1-y_true)*np.log(1-y_predicted_new))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](GD_partial_derivatives.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent function\n",
    "def gradient_descent(age, affordability, y_true, epochs, loss_threshold):\n",
    "    w1 = w2 = 1\n",
    "    bias = 0\n",
    "    learning_rate = 0.01\n",
    "    n = len(age)\n",
    "    for i in range(epochs):\n",
    "        weighted_sum = w1*age + w2*affordability + bias\n",
    "        y_pred = sigmoid(weighted_sum)\n",
    "\n",
    "        loss = log_loss(y_true, y_pred)\n",
    "\n",
    "        # derivatives to change the weights and biases\n",
    "        w1d = -(1/n) * np.dot(np.transpose(age), (y_true - y_pred))\n",
    "        w2d = -(1/n) * np.dot(np.transpose(affordability), (y_true - y_pred))\n",
    "\n",
    "        bias_derivative = np.mean(y_pred - y_true)\n",
    "\n",
    "        w1 = w1 - learning_rate * w1d\n",
    "        w2 = w2 - learning_rate * w2d\n",
    "\n",
    "        bias = bias - learning_rate * bias_derivative\n",
    "\n",
    "        print(\"Epoch: \" + str(i + 1) + \" Loss: \" + str(loss) + \"Weight 1: \" + str(w1) + \" Weight 2: \" + str(w2) + \" Bias: \" + str(bias))\n",
    "\n",
    "        if loss <= loss_threshold:\n",
    "            break\n",
    "\n",
    "\n",
    "    return w1, w2, bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.7960362503355486Weight 1: 0.9992898313363374 Weight 2: 0.9984485000394037 Bias: -0.00304348887567105\n",
      "Epoch: 2 Loss: 0.7948204667256131Weight 1: 0.9985825883662556 Weight 2: 0.9969015718319503 Bias: -0.006079157358744767\n",
      "Epoch: 3 Loss: 0.7936112629710453Weight 1: 0.9978782692102469 Weight 2: 0.9953592159610566 Bias: -0.009107011729941526\n",
      "Epoch: 4 Loss: 0.7924086170393032Weight 1: 0.9971768719398659 Weight 2: 0.9938214329097408 Bias: -0.012127058394218626\n",
      "Epoch: 5 Loss: 0.7912125068166399Weight 1: 0.9964783945779571 Weight 2: 0.992288223060877 Bias: -0.015139303880105436\n",
      "Epoch: 6 Loss: 0.790022910109845Weight 1: 0.9957828350988852 Weight 2: 0.9907595866974589 Bias: -0.018143754839031235\n",
      "Epoch: 7 Loss: 0.788839804647986Weight 1: 0.9950901914287696 Weight 2: 0.9892355240028714 Bias: -0.021140418044645875\n",
      "Epoch: 8 Loss: 0.7876631680841442Weight 1: 0.9944004614457213 Weight 2: 0.9877160350611711 Bias: -0.024129300392133388\n",
      "Epoch: 9 Loss: 0.7864929779971526Weight 1: 0.9937136429800818 Weight 2: 0.9862011198573742 Bias: -0.02711040889751868\n",
      "Epoch: 10 Loss: 0.7853292118933299Weight 1: 0.9930297338146671 Weight 2: 0.9846907782777534 Bias: -0.030083750696967414\n",
      "Epoch: 11 Loss: 0.7841718472082108Weight 1: 0.9923487316850125 Weight 2: 0.9831850101101419 Bias: -0.03304933304607923\n",
      "Epoch: 12 Loss: 0.7830208613082763Weight 1: 0.9916706342796217 Weight 2: 0.9816838150442464 Bias: -0.03600716331917443\n",
      "Epoch: 13 Loss: 0.7818762314926797Weight 1: 0.9909954392402176 Weight 2: 0.9801871926719671 Bias: -0.03895724900857422\n",
      "Epoch: 14 Loss: 0.7807379349949681Weight 1: 0.9903231441619968 Weight 2: 0.9786951424877255 Bias: -0.04189959772387467\n",
      "Epoch: 15 Loss: 0.7796059489848026Weight 1: 0.9896537465938862 Weight 2: 0.9772076638888006 Bias: -0.044834217191214575\n",
      "Epoch: 16 Loss: 0.7784802505696731Weight 1: 0.9889872440388018 Weight 2: 0.975724756175672 Bias: -0.047761115252537165\n",
      "Epoch: 17 Loss: 0.7773608167966098Weight 1: 0.9883236339539117 Weight 2: 0.9742464185523702 Bias: -0.050680299864846054\n",
      "Epoch: 18 Loss: 0.7762476246538916Weight 1: 0.9876629137508999 Weight 2: 0.9727726501268352 Bias: -0.053591779099455304\n",
      "Epoch: 19 Loss: 0.7751406510727463Weight 1: 0.9870050807962335 Weight 2: 0.9713034499112818 Bias: -0.056495561141233906\n",
      "Epoch: 20 Loss: 0.7740398729290514Weight 1: 0.9863501324114323 Weight 2: 0.9698388168225717 Bias: -0.05939165428784476\n",
      "Epoch: 21 Loss: 0.7729452670450246Weight 1: 0.9856980658733405 Weight 2: 0.9683787496825934 Bias: -0.06228006694897821\n",
      "Epoch: 22 Loss: 0.7718568101909135Weight 1: 0.9850488784144011 Weight 2: 0.9669232472186488 Bias: -0.06516080764558041\n",
      "Epoch: 23 Loss: 0.7707744790866766Weight 1: 0.9844025672229324 Weight 2: 0.9654723080638461 Bias: -0.0680338850090765\n",
      "Epoch: 24 Loss: 0.7696982504036604Weight 1: 0.9837591294434065 Weight 2: 0.9640259307575008 Bias: -0.07089930778058885\n",
      "Epoch: 25 Loss: 0.7686281007662707Weight 1: 0.9831185621767308 Weight 2: 0.9625841137455413 Bias: -0.07375708481015038\n",
      "Epoch: 26 Loss: 0.7675640067536367Weight 1: 0.9824808624805307 Weight 2: 0.9611468553809236 Bias: -0.0766072250559132\n",
      "Epoch: 27 Loss: 0.7665059449012689Weight 1: 0.9818460273694352 Weight 2: 0.9597141539240499 Bias: -0.07944973758335269\n",
      "Epoch: 28 Loss: 0.7654538917027124Weight 1: 0.9812140538153639 Weight 2: 0.9582860075431954 Bias: -0.08228463156446696\n",
      "Epoch: 29 Loss: 0.7644078236111898Weight 1: 0.9805849387478165 Weight 2: 0.9568624143149405 Bias: -0.08511191627697215\n",
      "Epoch: 30 Loss: 0.7633677170412408Weight 1: 0.979958679054164 Weight 2: 0.9554433722246091 Bias: -0.08793160110349342\n",
      "Epoch: 31 Loss: 0.7623335483703527Weight 1: 0.9793352715799419 Weight 2: 0.9540288791667135 Bias: -0.09074369553075187\n",
      "Epoch: 32 Loss: 0.7613052939405844Weight 1: 0.9787147131291453 Weight 2: 0.9526189329454045 Bias: -0.09354820914874754\n",
      "Epoch: 33 Loss: 0.7602829300601802Weight 1: 0.9780970004645253 Weight 2: 0.9512135312749276 Bias: -0.09634515164993854\n",
      "Epoch: 34 Loss: 0.7592664330051817Weight 1: 0.9774821303078884 Weight 2: 0.9498126717800852 Bias: -0.09913453282841657\n",
      "Epoch: 35 Loss: 0.7582557790210228Weight 1: 0.9768700993403961 Weight 2: 0.9484163519967039 Bias: -0.10191636257907881\n",
      "Epoch: 36 Loss: 0.7572509443241274Weight 1: 0.9762609042028673 Weight 2: 0.9470245693721077 Bias: -0.1046906508967964\n",
      "Epoch: 37 Loss: 0.7562519051034896Weight 1: 0.9756545414960812 Weight 2: 0.945637321265596 Bias: -0.10745740787557957\n",
      "Epoch: 38 Loss: 0.7552586375222483Weight 1: 0.9750510077810834 Weight 2: 0.9442546049489277 Bias: -0.1102166437077397\n",
      "Epoch: 39 Loss: 0.7542711177192573Weight 1: 0.9744502995794918 Weight 2: 0.9428764176068097 Bias: -0.11296836868304821\n",
      "Epoch: 40 Loss: 0.753289321810639Weight 1: 0.973852413373805 Weight 2: 0.9415027563373912 Bias: -0.11571259318789258\n",
      "Epoch: 41 Loss: 0.7523132258913356Weight 1: 0.9732573456077116 Weight 2: 0.9401336181527619 Bias: -0.11844932770442958\n",
      "Epoch: 42 Loss: 0.7513428060366473Weight 1: 0.9726650926864013 Weight 2: 0.938768999979456 Bias: -0.1211785828097358\n",
      "Epoch: 43 Loss: 0.7503780383037625Weight 1: 0.9720756509768771 Weight 2: 0.9374088986589606 Bias: -0.12390036917495566\n",
      "Epoch: 44 Loss: 0.7494188987332787Weight 1: 0.9714890168082683 Weight 2: 0.9360533109482287 Bias: -0.12661469756444693\n",
      "Epoch: 45 Loss: 0.7484653633507129Weight 1: 0.9709051864721456 Weight 2: 0.9347022335201968 Bias: -0.12932157883492412\n",
      "Epoch: 46 Loss: 0.7475174081680035Weight 1: 0.9703241562228372 Weight 2: 0.9333556629643062 Bias: -0.1320210239345994\n",
      "Epoch: 47 Loss: 0.7465750091849999Weight 1: 0.9697459222777448 Weight 2: 0.9320135957870301 Bias: -0.13471304390232183\n",
      "Epoch: 48 Loss: 0.7456381423909447Weight 1: 0.9691704808176627 Weight 2: 0.9306760284124037 Bias: -0.13739764986671427\n",
      "Epoch: 49 Loss: 0.7447067837659431Weight 1: 0.9685978279870959 Weight 2: 0.9293429571825581 Bias: -0.14007485304530887\n",
      "Epoch: 50 Loss: 0.7437809092824249Weight 1: 0.968027959894581 Weight 2: 0.9280143783582596 Bias: -0.14274466474368053\n",
      "Epoch: 51 Loss: 0.7428604949065926Weight 1: 0.9674608726130065 Weight 2: 0.9266902881194516 Bias: -0.145407096354579\n",
      "Epoch: 52 Loss: 0.7419455165998614Weight 1: 0.9668965621799349 Weight 2: 0.9253706825658008 Bias: -0.14806215935705946\n",
      "Epoch: 53 Loss: 0.7410359503202877Weight 1: 0.9663350245979254 Weight 2: 0.9240555577172466 Bias: -0.15070986531561184\n",
      "Epoch: 54 Loss: 0.7401317720239853Weight 1: 0.9657762558348574 Weight 2: 0.9227449095145549 Bias: -0.15335022587928868\n",
      "Epoch: 55 Loss: 0.7392329576665329Weight 1: 0.9652202518242544 Weight 2: 0.9214387338198745 Bias: -0.15598325278083222\n",
      "Epoch: 56 Loss: 0.7383394832043695Weight 1: 0.9646670084656095 Weight 2: 0.9201370264172973 Bias: -0.15860895783580028\n",
      "Epoch: 57 Loss: 0.7374513245961769Weight 1: 0.9641165216247103 Weight 2: 0.9188397830134216 Bias: -0.16122735294169144\n",
      "Epoch: 58 Loss: 0.736568457804254Weight 1: 0.9635687871339655 Weight 2: 0.9175469992379183 Bias: -0.16383845007706918\n",
      "Epoch: 59 Loss: 0.7356908587958774Weight 1: 0.9630238007927316 Weight 2: 0.9162586706441003 Bias: -0.1664422613006858\n",
      "Epoch: 60 Loss: 0.7348185035446506Weight 1: 0.96248155836764 Weight 2: 0.9149747927094954 Bias: -0.16903879875060535\n",
      "Epoch: 61 Loss: 0.7339513680318422Weight 1: 0.9619420555929248 Weight 2: 0.913695360836421 Bias: -0.17162807464332655\n",
      "Epoch: 62 Loss: 0.7330894282477132Weight 1: 0.9614052881707509 Weight 2: 0.9124203703525618 Bias: -0.17421010127290512\n",
      "Epoch: 63 Loss: 0.7322326601928293Weight 1: 0.9608712517715425 Weight 2: 0.9111498165115509 Bias: -0.17678489101007602\n",
      "Epoch: 64 Loss: 0.7313810398793649Weight 1: 0.9603399420343123 Weight 2: 0.9098836944935521 Bias: -0.17935245630137558\n",
      "Epoch: 65 Loss: 0.7305345433323929Weight 1: 0.9598113545669902 Weight 2: 0.9086219994058459 Bias: -0.1819128096682637\n",
      "Epoch: 66 Loss: 0.7296931465911644Weight 1: 0.959285484946753 Weight 2: 0.9073647262834168 Bias: -0.18446596370624607\n",
      "Epoch: 67 Loss: 0.7288568257103722Weight 1: 0.9587623287203542 Weight 2: 0.9061118700895433 Bias: -0.1870119310839967\n",
      "Epoch: 68 Loss: 0.728025556761408Weight 1: 0.9582418814044533 Weight 2: 0.90486342571639 Bias: -0.18955072454248073\n",
      "Epoch: 69 Loss: 0.7271993158336013Weight 1: 0.9577241384859464 Weight 2: 0.9036193879856016 Bias: -0.1920823568940777\n",
      "Epoch: 70 Loss: 0.7263780790354508Weight 1: 0.9572090954222957 Weight 2: 0.9023797516488986 Bias: -0.1946068410217054\n",
      "Epoch: 71 Loss: 0.7255618224958401Weight 1: 0.9566967476418599 Weight 2: 0.9011445113886754 Bias: -0.19712418987794417\n",
      "Epoch: 72 Loss: 0.7247505223652427Weight 1: 0.9561870905442241 Weight 2: 0.8999136618185993 Bias: -0.19963441648416222\n",
      "Epoch: 73 Loss: 0.7239441548169129Weight 1: 0.9556801195005302 Weight 2: 0.8986871974842121 Bias: -0.20213753392964157\n",
      "Epoch: 74 Loss: 0.7231426960480668Weight 1: 0.9551758298538064 Weight 2: 0.8974651128635321 Bias: -0.20463355537070493\n",
      "Epoch: 75 Loss: 0.7223461222810476Weight 1: 0.9546742169192975 Weight 2: 0.8962474023676588 Bias: -0.20712249402984378\n",
      "Epoch: 76 Loss: 0.7215544097644798Weight 1: 0.9541752759847943 Weight 2: 0.8950340603413774 Bias: -0.20960436319484735\n",
      "Epoch: 77 Loss: 0.720767534774411Weight 1: 0.9536790023109635 Weight 2: 0.8938250810637662 Bias: -0.21207917621793299\n",
      "Epoch: 78 Loss: 0.7199854736154396Weight 1: 0.9531853911316764 Weight 2: 0.8926204587488039 Bias: -0.2145469465148777\n",
      "Epoch: 79 Loss: 0.7192082026218313Weight 1: 0.952694437654339 Weight 2: 0.8914201875459784 Bias: -0.21700768756415129\n",
      "Epoch: 80 Loss: 0.7184356981586212Weight 1: 0.9522061370602196 Weight 2: 0.8902242615408966 Bias: -0.21946141290605065\n",
      "Epoch: 81 Loss: 0.7176679366227039Weight 1: 0.951720484504778 Weight 2: 0.8890326747558953 Bias: -0.22190813614183602\n",
      "Epoch: 82 Loss: 0.7169048944439113Weight 1: 0.9512374751179931 Weight 2: 0.8878454211506523 Bias: -0.2243478709328687\n",
      "Epoch: 83 Loss: 0.7161465480860764Weight 1: 0.9507571040046908 Weight 2: 0.8866624946227987 Bias: -0.22678063099975052\n",
      "Epoch: 84 Loss: 0.7153928740480845Weight 1: 0.9502793662448713 Weight 2: 0.8854838890085314 Bias: -0.22920643012146513\n",
      "Epoch: 85 Loss: 0.7146438488649107Weight 1: 0.9498042568940352 Weight 2: 0.8843095980832267 Bias: -0.23162528213452138\n",
      "Epoch: 86 Loss: 0.713899449108647Weight 1: 0.9493317709835104 Weight 2: 0.8831396155620541 Bias: -0.2340372009320985\n",
      "Epoch: 87 Loss: 0.7131596513895132Weight 1: 0.9488619035207774 Weight 2: 0.8819739351005897 Bias: -0.23644220046319353\n",
      "Epoch: 88 Loss: 0.7124244323568573Weight 1: 0.9483946494897941 Weight 2: 0.8808125502954314 Bias: -0.23884029473177074\n",
      "Epoch: 89 Loss: 0.7116937687001411Weight 1: 0.9479300038513211 Weight 2: 0.8796554546848125 Bias: -0.24123149779591355\n",
      "Epoch: 90 Loss: 0.7109676371499137Weight 1: 0.9474679615432444 Weight 2: 0.8785026417492174 Bias: -0.24361582376697852\n",
      "Epoch: 91 Loss: 0.7102460144787733Weight 1: 0.9470085174808995 Weight 2: 0.8773541049119955 Bias: -0.24599328680875188\n",
      "Epoch: 92 Loss: 0.7095288775023127Weight 1: 0.9465516665573933 Weight 2: 0.8762098375399759 Bias: -0.24836390113660858\n",
      "Epoch: 93 Loss: 0.7088162030800544Weight 1: 0.9460974036439257 Weight 2: 0.8750698329440824 Bias: -0.25072768101667375\n",
      "Epoch: 94 Loss: 0.7081079681163732Weight 1: 0.9456457235901108 Weight 2: 0.873934084379947 Bias: -0.2530846407649869\n",
      "Epoch: 95 Loss: 0.7074041495614032Weight 1: 0.9451966212242969 Weight 2: 0.8728025850485247 Bias: -0.25543479474666864\n",
      "Epoch: 96 Loss: 0.7067047244119341Weight 1: 0.9447500913538858 Weight 2: 0.8716753280967064 Bias: -0.2577781573750907\n",
      "Epoch: 97 Loss: 0.7060096697122934Weight 1: 0.9443061287656508 Weight 2: 0.8705523066179328 Bias: -0.2601147431110479\n",
      "Epoch: 98 Loss: 0.7053189625552171Weight 1: 0.9438647282260549 Weight 2: 0.8694335136528064 Bias: -0.2624445664619338\n",
      "Epoch: 99 Loss: 0.7046325800827052Weight 1: 0.9434258844815671 Weight 2: 0.8683189421897042 Bias: -0.2647676419809192\n",
      "Epoch: 100 Loss: 0.7039504994868664Weight 1: 0.9429895922589775 Weight 2: 0.8672085851653886 Bias: -0.26708398426613295\n",
      "Epoch: 101 Loss: 0.7032726980107494Weight 1: 0.9425558462657129 Weight 2: 0.8661024354656187 Bias: -0.2693936079598471\n",
      "Epoch: 102 Loss: 0.70259915294916Weight 1: 0.9421246411901497 Weight 2: 0.86500048592576 Bias: -0.2716965277476642\n",
      "Epoch: 103 Loss: 0.7019298416494677Weight 1: 0.9416959717019273 Weight 2: 0.8639027293313929 Bias: -0.273992758357708\n",
      "Epoch: 104 Loss: 0.7012647415123978Weight 1: 0.9412698324522589 Weight 2: 0.8628091584189219 Bias: -0.27628231455981805\n",
      "Epoch: 105 Loss: 0.7006038299928122Weight 1: 0.9408462180742424 Weight 2: 0.8617197658761819 Bias: -0.278565211164747\n",
      "Epoch: 106 Loss: 0.6999470846004746Weight 1: 0.94042512318317 Weight 2: 0.8606345443430445 Bias: -0.28084146302336127\n",
      "Epoch: 107 Loss: 0.6992944829008072Weight 1: 0.9400065423768358 Weight 2: 0.8595534864120231 Bias: -0.28311108502584587\n",
      "Epoch: 108 Loss: 0.6986460025156324Weight 1: 0.9395904702358439 Weight 2: 0.8584765846288763 Bias: -0.2853740921009119\n",
      "Epoch: 109 Loss: 0.6980016211239006Weight 1: 0.9391769013239135 Weight 2: 0.8574038314932106 Bias: -0.2876304992150083\n",
      "Epoch: 110 Loss: 0.6973613164624088Weight 1: 0.938765830188184 Weight 2: 0.8563352194590818 Bias: -0.2898803213715366\n",
      "Epoch: 111 Loss: 0.6967250663265044Weight 1: 0.9383572513595186 Weight 2: 0.8552707409355939 Bias: -0.29212357361006996\n",
      "Epoch: 112 Loss: 0.6960928485707762Weight 1: 0.9379511593528064 Weight 2: 0.8542103882874985 Bias: -0.29436027100557566\n",
      "Epoch: 113 Loss: 0.6954646411097359Weight 1: 0.9375475486672634 Weight 2: 0.8531541538357911 Bias: -0.2965904286676411\n",
      "Epoch: 114 Loss: 0.6948404219184834Weight 1: 0.9371464137867325 Weight 2: 0.8521020298583063 Bias: -0.29881406173970415\n",
      "Epoch: 115 Loss: 0.6942201690333625Weight 1: 0.9367477491799815 Weight 2: 0.8510540085903118 Bias: -0.3010311853982868\n",
      "Epoch: 116 Loss: 0.6936038605526037Weight 1: 0.9363515493010006 Weight 2: 0.8500100822250998 Bias: -0.30324181485223345\n",
      "Epoch: 117 Loss: 0.6929914746369545Weight 1: 0.9359578085892979 Weight 2: 0.848970242914578 Bias: -0.3054459653419523\n",
      "Epoch: 118 Loss: 0.6923829895102973Weight 1: 0.9355665214701938 Weight 2: 0.8479344827698577 Bias: -0.30764365213866135\n",
      "Epoch: 119 Loss: 0.6917783834602574Weight 1: 0.9351776823551141 Weight 2: 0.8469027938618403 Bias: -0.3098348905436385\n",
      "Epoch: 120 Loss: 0.6911776348387945Weight 1: 0.9347912856418815 Weight 2: 0.8458751682218024 Bias: -0.31201969588747513\n",
      "Epoch: 121 Loss: 0.6905807220627876Weight 1: 0.9344073257150057 Weight 2: 0.8448515978419785 Bias: -0.3141980835293345\n",
      "Epoch: 122 Loss: 0.6899876236146049Weight 1: 0.9340257969459722 Weight 2: 0.8438320746761416 Bias: -0.3163700688562137\n",
      "Epoch: 123 Loss: 0.6893983180426612Weight 1: 0.9336466936935296 Weight 2: 0.8428165906401827 Bias: -0.3185356672822105\n",
      "Epoch: 124 Loss: 0.6888127839619667Weight 1: 0.9332700103039752 Weight 2: 0.8418051376126865 Bias: -0.3206948942477937\n",
      "Epoch: 125 Loss: 0.6882310000546611Weight 1: 0.9328957411114395 Weight 2: 0.8407977074355071 Bias: -0.32284776521907826\n",
      "Epoch: 126 Loss: 0.6876529450705371Weight 1: 0.9325238804381688 Weight 2: 0.8397942919143397 Bias: -0.32499429568710464\n",
      "Epoch: 127 Loss: 0.6870785978275539Weight 1: 0.9321544225948067 Weight 2: 0.8387948828192912 Bias: -0.32713450116712234\n",
      "Epoch: 128 Loss: 0.6865079372123369Weight 1: 0.9317873618806738 Weight 2: 0.8377994718854476 Bias: -0.3292683971978779\n",
      "Epoch: 129 Loss: 0.685940942180666Weight 1: 0.9314226925840454 Weight 2: 0.8368080508134405 Bias: -0.3313959993409074\n",
      "Epoch: 130 Loss: 0.6853775917579564Weight 1: 0.9310604089824288 Weight 2: 0.8358206112700096 Bias: -0.3335173231798331\n",
      "Epoch: 131 Loss: 0.6848178650397223Weight 1: 0.9307005053428379 Weight 2: 0.8348371448885642 Bias: -0.3356323843196651\n",
      "Epoch: 132 Loss: 0.684261741192035Weight 1: 0.9303429759220666 Weight 2: 0.8338576432697412 Bias: -0.33774119838610667\n",
      "Epoch: 133 Loss: 0.6837091994519648Weight 1: 0.929987814966961 Weight 2: 0.8328820979819616 Bias: -0.339843781024865\n",
      "Epoch: 134 Loss: 0.6831602191280178Weight 1: 0.9296350167146893 Weight 2: 0.8319105005619833 Bias: -0.34194014790096594\n",
      "Epoch: 135 Loss: 0.6826147796005544Weight 1: 0.9292845753930103 Weight 2: 0.8309428425154531 Bias: -0.34403031469807327\n",
      "Epoch: 136 Loss: 0.6820728603222056Weight 1: 0.9289364852205408 Weight 2: 0.829979115317454 Bias: -0.34611429711781283\n",
      "Epoch: 137 Loss: 0.6815344408182691Weight 1: 0.9285907404070205 Weight 2: 0.8290193104130518 Bias: -0.34819211087910124\n",
      "Epoch: 138 Loss: 0.6809995006871044Weight 1: 0.9282473351535755 Weight 2: 0.8280634192178375 Bias: -0.3502637717174791\n",
      "Epoch: 139 Loss: 0.6804680196005083Weight 1: 0.9279062636529808 Weight 2: 0.8271114331184686 Bias: -0.35232929538444885\n",
      "Epoch: 140 Loss: 0.6799399773040874Weight 1: 0.92756752008992 Weight 2: 0.826163343473206 Bias: -0.3543886976468175\n",
      "Epoch: 141 Loss: 0.6794153536176138Weight 1: 0.9272310986412443 Weight 2: 0.8252191416124496 Bias: -0.3564419942860439\n",
      "Epoch: 142 Loss: 0.6788941284353766Weight 1: 0.9268969934762291 Weight 2: 0.82427881883927 Bias: -0.35848920109759064\n",
      "Epoch: 143 Loss: 0.6783762817265168Weight 1: 0.9265651987568292 Weight 2: 0.8233423664299383 Bias: -0.360530333890281\n",
      "Epoch: 144 Loss: 0.6778617935353577Weight 1: 0.9262357086379324 Weight 2: 0.8224097756344523 Bias: -0.3625654084856602\n",
      "Epoch: 145 Loss: 0.6773506439817222Weight 1: 0.9259085172676109 Weight 2: 0.8214810376770606 Bias: -0.3645944407173619\n",
      "Epoch: 146 Loss: 0.6768428132612395Weight 1: 0.9255836187873717 Weight 2: 0.8205561437567831 Bias: -0.36661744643047905\n",
      "Epoch: 147 Loss: 0.6763382816456445Weight 1: 0.9252610073324046 Weight 2: 0.8196350850479289 Bias: -0.3686344414809396\n",
      "Epoch: 148 Loss: 0.6758370294830651Weight 1: 0.9249406770318285 Weight 2: 0.8187178527006115 Bias: -0.3706454417348874\n",
      "Epoch: 149 Loss: 0.6753390371983009Weight 1: 0.9246226220089365 Weight 2: 0.8178044378412602 Bias: -0.3726504630680674\n",
      "Epoch: 150 Loss: 0.6748442852930912Weight 1: 0.9243068363814387 Weight 2: 0.8168948315731299 Bias: -0.3746495213652158\n",
      "Epoch: 151 Loss: 0.6743527543463759Weight 1: 0.9239933142617033 Weight 2: 0.8159890249768065 Bias: -0.37664263251945534\n",
      "Epoch: 152 Loss: 0.6738644250145428Weight 1: 0.9236820497569961 Weight 2: 0.8150870091107097 Bias: -0.37862981243169513\n",
      "Epoch: 153 Loss: 0.6733792780316705Weight 1: 0.9233730369697182 Weight 2: 0.8141887750115936 Bias: -0.3806110770100352\n",
      "Epoch: 154 Loss: 0.6728972942097581Weight 1: 0.9230662699976417 Weight 2: 0.8132943136950425 Bias: -0.3825864421691763\n",
      "Epoch: 155 Loss: 0.672418454438946Weight 1: 0.9227617429341441 Weight 2: 0.8124036161559655 Bias: -0.3845559238298343\n",
      "Epoch: 156 Loss: 0.6719427396877311Weight 1: 0.9224594498684403 Weight 2: 0.8115166733690864 Bias: -0.3865195379181594\n",
      "Epoch: 157 Loss: 0.6714701310031692Weight 1: 0.9221593848858128 Weight 2: 0.8106334762894316 Bias: -0.38847730036516054\n",
      "Epoch: 158 Loss: 0.6710006095110692Weight 1: 0.9218615420678412 Weight 2: 0.8097540158528141 Bias: -0.3904292271061341\n",
      "Epoch: 159 Loss: 0.670534156416181Weight 1: 0.9215659154926282 Weight 2: 0.8088782829763149 Bias: -0.3923753340800981\n",
      "Epoch: 160 Loss: 0.6700707530023711Weight 1: 0.9212724992350254 Weight 2: 0.8080062685587605 Bias: -0.39431563722923096\n",
      "Epoch: 161 Loss: 0.6696103806327923Weight 1: 0.9209812873668559 Weight 2: 0.8071379634811978 Bias: -0.396250152498315\n",
      "Epoch: 162 Loss: 0.6691530207500431Weight 1: 0.9206922739571363 Weight 2: 0.8062733586073659 Bias: -0.3981788958341852\n",
      "Epoch: 163 Loss: 0.6686986548763199Weight 1: 0.9204054530722959 Weight 2: 0.8054124447841641 Bias: -0.4001018831851825\n",
      "Epoch: 164 Loss: 0.6682472646135604Weight 1: 0.9201208187763952 Weight 2: 0.8045552128421167 Bias: -0.40201913050061217\n",
      "Epoch: 165 Loss: 0.667798831643578Weight 1: 0.9198383651313408 Weight 2: 0.8037016535958353 Bias: -0.4039306537302069\n",
      "Epoch: 166 Loss: 0.6673533377281892Weight 1: 0.9195580861971007 Weight 2: 0.8028517578444769 Bias: -0.40583646882359503\n",
      "Epoch: 167 Loss: 0.6669107647093324Weight 1: 0.9192799760319159 Weight 2: 0.8020055163721994 Bias: -0.40773659172977317\n",
      "Epoch: 168 Loss: 0.6664710945091792Weight 1: 0.9190040286925115 Weight 2: 0.8011629199486133 Bias: -0.40963103839658427\n",
      "Epoch: 169 Loss: 0.666034309130236Weight 1: 0.918730238234305 Weight 2: 0.8003239593292305 Bias: -0.41151982477020016\n",
      "Epoch: 170 Loss: 0.6656003906554401Weight 1: 0.9184585987116134 Weight 2: 0.7994886252559096 Bias: -0.4134029667946091\n",
      "Epoch: 171 Loss: 0.6651693212482473Weight 1: 0.9181891041778584 Weight 2: 0.7986569084572979 Bias: -0.41528048041110793\n",
      "Epoch: 172 Loss: 0.6647410831527113Weight 1: 0.9179217486857694 Weight 2: 0.7978287996492701 Bias: -0.4171523815577996\n",
      "Epoch: 173 Loss: 0.664315658693556Weight 1: 0.9176565262875852 Weight 2: 0.7970042895353636 Bias: -0.419018686169095\n",
      "Epoch: 174 Loss: 0.6638930302762407Weight 1: 0.9173934310352535 Weight 2: 0.7961833688072107 Bias: -0.4208794101752198\n",
      "Epoch: 175 Loss: 0.6634731803870173Weight 1: 0.917132456980629 Weight 2: 0.7953660281449672 Bias: -0.4227345695017262\n",
      "Epoch: 176 Loss: 0.6630560915929808Weight 1: 0.9168735981756687 Weight 2: 0.7945522582177375 Bias: -0.4245841800690096\n",
      "Epoch: 177 Loss: 0.6626417465421132Weight 1: 0.9166168486726272 Weight 2: 0.793742049683997 Bias: -0.4264282577918296\n",
      "Epoch: 178 Loss: 0.6622301279633173Weight 1: 0.9163622025242479 Weight 2: 0.7929353931920103 Bias: -0.42826681857883625\n",
      "Epoch: 179 Loss: 0.6618212186664493Weight 1: 0.9161096537839547 Weight 2: 0.7921322793802471 Bias: -0.4300998783321011\n",
      "Epoch: 180 Loss: 0.6614150015423377Weight 1: 0.9158591965060399 Weight 2: 0.7913326988777932 Bias: -0.43192745294665263\n",
      "Epoch: 181 Loss: 0.6610114595628015Weight 1: 0.9156108247458514 Weight 2: 0.7905366423047597 Bias: -0.43374955831001677\n",
      "Epoch: 182 Loss: 0.6606105757806566Weight 1: 0.9153645325599784 Weight 2: 0.7897441002726882 Bias: -0.43556621030176207\n",
      "Epoch: 183 Loss: 0.6602123333297204Weight 1: 0.9151203140064339 Weight 2: 0.788955063384952 Bias: -0.43737742479304964\n",
      "Epoch: 184 Loss: 0.6598167154248058Weight 1: 0.9148781631448372 Weight 2: 0.7881695222371553 Bias: -0.4391832176461878\n",
      "Epoch: 185 Loss: 0.6594237053617112Weight 1: 0.9146380740365928 Weight 2: 0.7873874674175275 Bias: -0.44098360471419135\n",
      "Epoch: 186 Loss: 0.6590332865172029Weight 1: 0.9144000407450692 Weight 2: 0.7866088895073157 Bias: -0.4427786018403458\n",
      "Epoch: 187 Loss: 0.6586454423489928Weight 1: 0.9141640573357745 Weight 2: 0.7858337790811721 Bias: -0.4445682248577759\n",
      "Epoch: 188 Loss: 0.6582601563957078Weight 1: 0.9139301178765316 Weight 2: 0.78506212670754 Bias: -0.4463524895890193\n",
      "Epoch: 189 Loss: 0.6578774122768555Weight 1: 0.9136982164376496 Weight 2: 0.7842939229490344 Bias: -0.4481314118456043\n",
      "Epoch: 190 Loss: 0.6574971936927814Weight 1: 0.9134683470920962 Weight 2: 0.7835291583628209 Bias: -0.44990500742763284\n",
      "Epoch: 191 Loss: 0.6571194844246232Weight 1: 0.9132405039156659 Weight 2: 0.7827678235009902 Bias: -0.4516732921233677\n",
      "Epoch: 192 Loss: 0.6567442683342555Weight 1: 0.9130146809871477 Weight 2: 0.7820099089109298 Bias: -0.45343628170882444\n",
      "Epoch: 193 Loss: 0.6563715293642335Weight 1: 0.9127908723884904 Weight 2: 0.7812554051356922 Bias: -0.45519399194736787\n",
      "Epoch: 194 Loss: 0.656001251537726Weight 1: 0.9125690722049671 Weight 2: 0.7805043027143596 Bias: -0.45694643858931333\n",
      "Epoch: 195 Loss: 0.6556334189584477Weight 1: 0.9123492745253367 Weight 2: 0.779756592182405 Bias: -0.4586936373715322\n",
      "Epoch: 196 Loss: 0.6552680158105815Weight 1: 0.9121314734420046 Weight 2: 0.7790122640720512 Bias: -0.460435604017062\n",
      "Epoch: 197 Loss: 0.6549050263586994Weight 1: 0.9119156630511815 Weight 2: 0.7782713089126247 Bias: -0.4621723542347214\n",
      "Epoch: 198 Loss: 0.6545444349476754Weight 1: 0.91170183745304 Weight 2: 0.7775337172309079 Bias: -0.46390390371872914\n",
      "Epoch: 199 Loss: 0.6541862260025952Weight 1: 0.91148999075187 Weight 2: 0.7767994795514866 Bias: -0.46563026814832786\n",
      "Epoch: 200 Loss: 0.6538303840286583Weight 1: 0.9112801170562322 Weight 2: 0.7760685863970952 Bias: -0.4673514631874122\n",
      "Epoch: 201 Loss: 0.6534768936110771Weight 1: 0.91107221047911 Weight 2: 0.775341028288958 Bias: -0.4690675044841615\n",
      "Epoch: 202 Loss: 0.6531257394149717Weight 1: 0.9108662651380594 Weight 2: 0.7746167957471276 Bias: -0.4707784076706767\n",
      "Epoch: 203 Loss: 0.6527769061852571Weight 1: 0.9106622751553572 Weight 2: 0.7738958792908198 Bias: -0.47248418836262174\n",
      "Epoch: 204 Loss: 0.6524303787465273Weight 1: 0.9104602346581485 Weight 2: 0.7731782694387451 Bias: -0.47418486215886957\n",
      "Epoch: 205 Loss: 0.6520861420029357Weight 1: 0.9102601377785908 Weight 2: 0.7724639567094371 Bias: -0.47588044464115203\n",
      "Epoch: 206 Loss: 0.6517441809380679Weight 1: 0.910061978653998 Weight 2: 0.7717529316215777 Bias: -0.4775709513737145\n",
      "Epoch: 207 Loss: 0.6514044806148135Weight 1: 0.9098657514269815 Weight 2: 0.7710451846943186 Bias: -0.47925639790297486\n",
      "Epoch: 208 Loss: 0.6510670261752307Weight 1: 0.9096714502455909 Weight 2: 0.7703407064476004 Bias: -0.48093679975718634\n",
      "Epoch: 209 Loss: 0.650731802840408Weight 1: 0.9094790692634521 Weight 2: 0.7696394874024676 Bias: -0.48261217244610505\n",
      "Epoch: 210 Loss: 0.6503987959103203Weight 1: 0.9092886026399036 Weight 2: 0.7689415180813803 Bias: -0.48428253146066164\n",
      "Epoch: 211 Loss: 0.6500679907636827Weight 1: 0.9091000445401324 Weight 2: 0.7682467890085242 Bias: -0.4859478922726372\n",
      "Epoch: 212 Loss: 0.6497393728577981Weight 1: 0.9089133891353066 Weight 2: 0.767555290710115 Bias: -0.4876082703343431\n",
      "Epoch: 213 Loss: 0.649412927728402Weight 1: 0.9087286306027079 Weight 2: 0.7668670137147019 Bias: -0.48926368107830576\n",
      "Epoch: 214 Loss: 0.6490886409895039Weight 1: 0.9085457631258617 Weight 2: 0.7661819485534663 Bias: -0.49091413991695443\n",
      "Epoch: 215 Loss: 0.6487664983332212Weight 1: 0.9083647808946653 Weight 2: 0.7655000857605182 Bias: -0.49255966224231434\n",
      "Epoch: 216 Loss: 0.6484464855296154Weight 1: 0.9081856781055154 Weight 2: 0.7648214158731889 Bias: -0.494200263425703\n",
      "Epoch: 217 Loss: 0.6481285884265175Weight 1: 0.9080084489614334 Weight 2: 0.764145929432321 Bias: -0.49583595881743114\n",
      "Epoch: 218 Loss: 0.6478127929493559Weight 1: 0.9078330876721891 Weight 2: 0.7634736169825549 Bias: -0.49746676374650756\n",
      "Epoch: 219 Loss: 0.6474990851009768Weight 1: 0.907659588454423 Weight 2: 0.7628044690726127 Bias: -0.4990926935203479\n",
      "Epoch: 220 Loss: 0.6471874509614617Weight 1: 0.9074879455317673 Weight 2: 0.7621384762555782 Bias: -0.5007137634244877\n",
      "Epoch: 221 Loss: 0.646877876687943Weight 1: 0.9073181531349646 Weight 2: 0.7614756290891743 Bias: -0.5023299887222991\n",
      "Epoch: 222 Loss: 0.6465703485144147Weight 1: 0.9071502055019858 Weight 2: 0.7608159181360374 Bias: -0.5039413846547118\n",
      "Epoch: 223 Loss: 0.6462648527515399Weight 1: 0.9069840968781463 Weight 2: 0.7601593339639886 Bias: -0.5055479664399382\n",
      "Epoch: 224 Loss: 0.645961375786455Weight 1: 0.9068198215162201 Weight 2: 0.7595058671463015 Bias: -0.5071497492732012\n",
      "Epoch: 225 Loss: 0.6456599040825722Weight 1: 0.9066573736765531 Weight 2: 0.7588555082619676 Bias: -0.508746748326468\n",
      "Epoch: 226 Loss: 0.6453604241793762Weight 1: 0.9064967476271745 Weight 2: 0.7582082478959579 Bias: -0.5103389787481859\n",
      "Epoch: 227 Loss: 0.6450629226922203Weight 1: 0.906337937643907 Weight 2: 0.7575640766394823 Bias: -0.5119264556630225\n",
      "Epoch: 228 Loss: 0.6447673863121176Weight 1: 0.9061809380104751 Weight 2: 0.7569229850902457 Bias: -0.5135091941716106\n",
      "Epoch: 229 Loss: 0.6444738018055307Weight 1: 0.9060257430186119 Weight 2: 0.7562849638527003 Bias: -0.5150872093502952\n",
      "Epoch: 230 Loss: 0.6441821560141582Weight 1: 0.9058723469681654 Weight 2: 0.7556500035382965 Bias: -0.5166605162508862\n",
      "Epoch: 231 Loss: 0.6438924358547167Weight 1: 0.9057207441672016 Weight 2: 0.7550180947657293 Bias: -0.518229129900413\n",
      "Epoch: 232 Loss: 0.6436046283187232Weight 1: 0.9055709289321078 Weight 2: 0.7543892281611831 Bias: -0.5197930653008845\n",
      "Epoch: 233 Loss: 0.6433187204722729Weight 1: 0.9054228955876935 Weight 2: 0.7537633943585723 Bias: -0.5213523374290513\n",
      "Epoch: 234 Loss: 0.643034699455812Weight 1: 0.9052766384672902 Weight 2: 0.7531405839997798 Bias: -0.5229069612361724\n",
      "Epoch: 235 Loss: 0.6427525524839152Weight 1: 0.9051321519128497 Weight 2: 0.7525207877348924 Bias: -0.5244569516477858\n",
      "Epoch: 236 Loss: 0.6424722668450513Weight 1: 0.9049894302750406 Weight 2: 0.7519039962224336 Bias: -0.5260023235634819\n",
      "Epoch: 237 Loss: 0.6421938299013544Weight 1: 0.9048484679133446 Weight 2: 0.751290200129593 Bias: -0.5275430918566808\n",
      "Epoch: 238 Loss: 0.6419172290883879Weight 1: 0.9047092591961498 Weight 2: 0.7506793901324529 Bias: -0.5290792713744137\n",
      "Epoch: 239 Loss: 0.6416424519149078Weight 1: 0.9045717985008435 Weight 2: 0.7500715569162126 Bias: -0.530610876937107\n",
      "Epoch: 240 Loss: 0.6413694859626243Weight 1: 0.9044360802139038 Weight 2: 0.7494666911754095 Bias: -0.5321379233383703\n",
      "Epoch: 241 Loss: 0.6410983188859596Weight 1: 0.9043020987309891 Weight 2: 0.7488647836141376 Bias: -0.5336604253447883\n",
      "Epoch: 242 Loss: 0.6408289384118055Weight 1: 0.904169848457027 Weight 2: 0.7482658249462624 Bias: -0.5351783976957153\n",
      "Epoch: 243 Loss: 0.640561332339278Weight 1: 0.9040393238063013 Weight 2: 0.7476698058956347 Bias: -0.5366918551030737\n",
      "Epoch: 244 Loss: 0.6402954885394684Weight 1: 0.9039105192025378 Weight 2: 0.7470767171962999 Bias: -0.5382008122511558\n",
      "Epoch: 245 Loss: 0.6400313949551955Weight 1: 0.9037834290789891 Weight 2: 0.7464865495927057 Bias: -0.5397052837964289\n",
      "Epoch: 246 Loss: 0.6397690396007532Weight 1: 0.9036580478785173 Weight 2: 0.7458992938399065 Bias: -0.5412052843673439\n",
      "Epoch: 247 Loss: 0.6395084105616579Weight 1: 0.9035343700536763 Weight 2: 0.7453149407037656 Bias: -0.5427008285641473\n",
      "Epoch: 248 Loss: 0.6392494959943927Weight 1: 0.9034123900667921 Weight 2: 0.7447334809611541 Bias: -0.5441919309586954\n",
      "Epoch: 249 Loss: 0.6389922841261524Weight 1: 0.9032921023900422 Weight 2: 0.7441549054001477 Bias: -0.5456786060942743\n",
      "Epoch: 250 Loss: 0.6387367632545821Weight 1: 0.9031735015055335 Weight 2: 0.7435792048202204 Bias: -0.54716086848542\n",
      "Epoch: 251 Loss: 0.6384829217475199Weight 1: 0.9030565819053792 Weight 2: 0.7430063700324362 Bias: -0.5486387326177442\n",
      "Epoch: 252 Loss: 0.6382307480427336Weight 1: 0.9029413380917739 Weight 2: 0.7424363918596373 Bias: -0.5501122129477621\n",
      "Epoch: 253 Loss: 0.6379802306476579Weight 1: 0.9028277645770679 Weight 2: 0.7418692611366304 Bias: -0.5515813239027236\n",
      "Epoch: 254 Loss: 0.63773135813913Weight 1: 0.9027158558838404 Weight 2: 0.7413049687103703 Bias: -0.5530460798804476\n",
      "Epoch: 255 Loss: 0.6374841191631221Weight 1: 0.9026056065449708 Weight 2: 0.7407435054401408 Bias: -0.5545064952491596\n",
      "Epoch: 256 Loss: 0.6372385024344754Weight 1: 0.9024970111037093 Weight 2: 0.7401848621977328 Bias: -0.5559625843473324\n",
      "Epoch: 257 Loss: 0.6369944967366309Weight 1: 0.9023900641137462 Weight 2: 0.7396290298676209 Bias: -0.5574143614835294\n",
      "Epoch: 258 Loss: 0.6367520909213573Weight 1: 0.90228476013928 Weight 2: 0.7390759993471359 Bias: -0.5588618409362517\n",
      "Epoch: 259 Loss: 0.6365112739084822Weight 1: 0.902181093755084 Weight 2: 0.7385257615466362 Bias: -0.5603050369537873\n",
      "Epoch: 260 Loss: 0.6362720346856171Weight 1: 0.9020790595465721 Weight 2: 0.7379783073896763 Bias: -0.5617439637540643\n",
      "Epoch: 261 Loss: 0.6360343623078853Weight 1: 0.9019786521098632 Weight 2: 0.7374336278131725 Bias: -0.5631786355245061\n",
      "Epoch: 262 Loss: 0.6357982458976457Weight 1: 0.9018798660518446 Weight 2: 0.7368917137675665 Bias: -0.5646090664218901\n",
      "Epoch: 263 Loss: 0.6355636746442167Weight 1: 0.901782695990234 Weight 2: 0.7363525562169866 Bias: -0.5660352705722094\n",
      "Epoch: 264 Loss: 0.6353306378036004Weight 1: 0.9016871365536405 Weight 2: 0.7358161461394063 Bias: -0.5674572620705366\n",
      "Epoch: 265 Loss: 0.6350991246982031Weight 1: 0.9015931823816248 Weight 2: 0.7352824745268007 Bias: -0.5688750549808916\n",
      "Epoch: 266 Loss: 0.6348691247165565Weight 1: 0.9015008281247572 Weight 2: 0.7347515323853006 Bias: -0.5702886633361114\n",
      "Epoch: 267 Loss: 0.6346406273130388Weight 1: 0.9014100684446759 Weight 2: 0.7342233107353436 Bias: -0.5716981011377227\n",
      "Epoch: 268 Loss: 0.6344136220075925Weight 1: 0.9013208980141428 Weight 2: 0.7336978006118243 Bias: -0.5731033823558178\n",
      "Epoch: 269 Loss: 0.6341880983854438Weight 1: 0.9012333115170997 Weight 2: 0.7331749930642403 Bias: -0.574504520928933\n",
      "Epoch: 270 Loss: 0.6339640460968193Weight 1: 0.9011473036487219 Weight 2: 0.7326548791568376 Bias: -0.5759015307639295\n",
      "Epoch: 271 Loss: 0.6337414548566644Weight 1: 0.9010628691154714 Weight 2: 0.7321374499687527 Bias: -0.5772944257358772\n",
      "Epoch: 272 Loss: 0.6335203144443576Weight 1: 0.9009800026351497 Weight 2: 0.7316226965941531 Bias: -0.5786832196879415\n",
      "Epoch: 273 Loss: 0.6333006147034272Weight 1: 0.900898698936948 Weight 2: 0.7311106101423747 Bias: -0.5800679264312717\n",
      "Epoch: 274 Loss: 0.6330823455412659Weight 1: 0.9008189527614978 Weight 2: 0.7306011817380578 Bias: -0.5814485597448937\n",
      "Epoch: 275 Loss: 0.6328654969288446Weight 1: 0.9007407588609199 Weight 2: 0.7300944025212808 Bias: -0.5828251333756036\n",
      "Epoch: 276 Loss: 0.6326500589004274Weight 1: 0.9006641119988715 Weight 2: 0.7295902636476911 Bias: -0.5841976610378649\n",
      "Epoch: 277 Loss: 0.6324360215532829Weight 1: 0.9005890069505943 Weight 2: 0.7290887562886347 Bias: -0.5855661564137078\n",
      "Epoch: 278 Loss: 0.6322233750473989Weight 1: 0.9005154385029595 Weight 2: 0.7285898716312829 Bias: -0.5869306331526317\n",
      "Epoch: 279 Loss: 0.6320121096051937Weight 1: 0.900443401454513 Weight 2: 0.7280936008787571 Bias: -0.5882911048715092\n",
      "Epoch: 280 Loss: 0.6318022155112278Weight 1: 0.9003728906155192 Weight 2: 0.7275999352502521 Bias: -0.589647585154493\n",
      "Epoch: 281 Loss: 0.6315936831119162Weight 1: 0.9003039008080039 Weight 2: 0.7271088659811562 Bias: -0.5910000875529259\n",
      "Epoch: 282 Loss: 0.6313865028152387Weight 1: 0.9002364268657964 Weight 2: 0.7266203843231701 Bias: -0.5923486255852519\n",
      "Epoch: 283 Loss: 0.6311806650904515Weight 1: 0.9001704636345701 Weight 2: 0.7261344815444233 Bias: -0.5936932127369313\n",
      "Epoch: 284 Loss: 0.6309761604677974Weight 1: 0.9001060059718827 Weight 2: 0.7256511489295886 Bias: -0.5950338624603567\n",
      "Epoch: 285 Loss: 0.6307729795382161Weight 1: 0.9000430487472152 Weight 2: 0.7251703777799947 Bias: -0.5963705881747722\n",
      "Epoch: 286 Loss: 0.6305711129530548Weight 1: 0.8999815868420098 Weight 2: 0.7246921594137367 Bias: -0.5977034032661945\n",
      "Epoch: 287 Loss: 0.6303705514237784Weight 1: 0.8999216151497074 Weight 2: 0.7242164851657841 Bias: -0.5990323210873373\n",
      "Epoch: 288 Loss: 0.6301712857216774Weight 1: 0.8998631285757835 Weight 2: 0.723743346388088 Bias: -0.6003573549575362\n",
      "Epoch: 289 Loss: 0.6299733066775797Weight 1: 0.8998061220377838 Weight 2: 0.7232727344496853 Bias: -0.6016785181626776\n",
      "Epoch: 290 Loss: 0.6297766051815598Weight 1: 0.899750590465358 Weight 2: 0.7228046407368012 Bias: -0.6029958239551289\n",
      "Epoch: 291 Loss: 0.6295811721826474Weight 1: 0.8996965288002943 Weight 2: 0.72233905665295 Bias: -0.6043092855536708\n",
      "Epoch: 292 Loss: 0.6293869986885382Weight 1: 0.899643931996551 Weight 2: 0.7218759736190339 Bias: -0.6056189161434328\n",
      "Epoch: 293 Loss: 0.6291940757653017Weight 1: 0.8995927950202891 Weight 2: 0.7214153830734402 Bias: -0.6069247288758295\n",
      "Epoch: 294 Loss: 0.6290023945370931Weight 1: 0.8995431128499024 Weight 2: 0.7209572764721358 Bias: -0.6082267368685003\n",
      "Epoch: 295 Loss: 0.62881194618586Weight 1: 0.899494880476048 Weight 2: 0.7205016452887608 Bias: -0.6095249532052501\n",
      "Epoch: 296 Loss: 0.6286227219510546Weight 1: 0.8994480929016753 Weight 2: 0.7200484810147196 Bias: -0.6108193909359931\n",
      "Epoch: 297 Loss: 0.6284347131293418Weight 1: 0.8994027451420542 Weight 2: 0.7195977751592707 Bias: -0.6121100630766981\n",
      "Epoch: 298 Loss: 0.6282479110743103Weight 1: 0.899358832224803 Weight 2: 0.7191495192496141 Bias: -0.6133969826093358\n",
      "Epoch: 299 Loss: 0.6280623071961814Weight 1: 0.8993163491899142 Weight 2: 0.7187037048309777 Bias: -0.6146801624818286\n",
      "Epoch: 300 Loss: 0.6278778929615202Weight 1: 0.8992752910897814 Weight 2: 0.718260323466701 Bias: -0.6159596156080017\n",
      "Epoch: 301 Loss: 0.6276946598929448Weight 1: 0.8992356529892235 Weight 2: 0.717819366738318 Bias: -0.6172353548675371\n",
      "Epoch: 302 Loss: 0.627512599568839Weight 1: 0.899197429965509 Weight 2: 0.7173808262456378 Bias: -0.6185073931059288\n",
      "Epoch: 303 Loss: 0.6273317036230611Weight 1: 0.8991606171083799 Weight 2: 0.7169446936068232 Bias: -0.6197757431344402\n",
      "Epoch: 304 Loss: 0.6271519637446556Weight 1: 0.8991252095200738 Weight 2: 0.7165109604584686 Bias: -0.6210404177300634\n",
      "Epoch: 305 Loss: 0.6269733716775658Weight 1: 0.899091202315346 Weight 2: 0.7160796184556751 Bias: -0.6223014296354805\n",
      "Epoch: 306 Loss: 0.6267959192203439Weight 1: 0.8990585906214906 Weight 2: 0.7156506592721249 Bias: -0.6235587915590269\n",
      "Epoch: 307 Loss: 0.6266195982258642Weight 1: 0.8990273695783608 Weight 2: 0.715224074600153 Bias: -0.6248125161746559\n",
      "Epoch: 308 Loss: 0.6264444006010351Weight 1: 0.8989975343383886 Weight 2: 0.7147998561508188 Bias: -0.6260626161219058\n",
      "Epoch: 309 Loss: 0.6262703183065123Weight 1: 0.898969080066603 Weight 2: 0.714377995653974 Bias: -0.6273091040058683\n",
      "Epoch: 310 Loss: 0.6260973433564111Weight 1: 0.8989420019406492 Weight 2: 0.713958484858331 Bias: -0.6285519923971589\n",
      "Epoch: 311 Loss: 0.6259254678180216Weight 1: 0.8989162951508051 Weight 2: 0.7135413155315283 Bias: -0.6297912938318894\n",
      "Epoch: 312 Loss: 0.6257546838115218Weight 1: 0.898891954899998 Weight 2: 0.7131264794601949 Bias: -0.6310270208116414\n",
      "Epoch: 313 Loss: 0.6255849835096917Weight 1: 0.898868976403821 Weight 2: 0.712713968450013 Bias: -0.6322591858034424\n",
      "Epoch: 314 Loss: 0.6254163591376295Weight 1: 0.8988473548905481 Weight 2: 0.7123037743257793 Bias: -0.6334878012397427\n",
      "Epoch: 315 Loss: 0.6252488029724664Weight 1: 0.8988270856011484 Weight 2: 0.7118958889314645 Bias: -0.6347128795183948\n",
      "Epoch: 316 Loss: 0.6250823073430828Weight 1: 0.8988081637893002 Weight 2: 0.7114903041302716 Bias: -0.6359344330026342\n",
      "Epoch: 317 Loss: 0.6249168646298249Weight 1: 0.8987905847214042 Weight 2: 0.7110870118046926 Bias: -0.6371524740210615\n",
      "Epoch: 318 Loss: 0.6247524672642224Weight 1: 0.8987743436765959 Weight 2: 0.7106860038565636 Bias: -0.6383670148676264\n",
      "Epoch: 319 Loss: 0.624589107728704Weight 1: 0.8987594359467577 Weight 2: 0.7102872722071185 Bias: -0.6395780678016137\n",
      "Epoch: 320 Loss: 0.6244267785563192Weight 1: 0.8987458568365294 Weight 2: 0.7098908087970418 Bias: -0.6407856450476304\n",
      "Epoch: 321 Loss: 0.6242654723304542Weight 1: 0.8987336016633197 Weight 2: 0.7094966055865187 Bias: -0.641989758795594\n",
      "Epoch: 322 Loss: 0.6241051816845529Weight 1: 0.8987226657573154 Weight 2: 0.709104654555285 Bias: -0.6431904212007235\n",
      "Epoch: 323 Loss: 0.6239458993018362Weight 1: 0.8987130444614907 Weight 2: 0.7087149477026752 Bias: -0.6443876443835309\n",
      "Epoch: 324 Loss: 0.6237876179150234Weight 1: 0.898704733131616 Weight 2: 0.7083274770476689 Bias: -0.6455814404298149\n",
      "Epoch: 325 Loss: 0.6236303303060535Weight 1: 0.8986977271362661 Weight 2: 0.7079422346289364 Bias: -0.6467718213906555\n",
      "Epoch: 326 Loss: 0.6234740293058071Weight 1: 0.8986920218568271 Weight 2: 0.7075592125048823 Bias: -0.6479587992824103\n",
      "Epoch: 327 Loss: 0.6233187077938287Weight 1: 0.8986876126875035 Weight 2: 0.7071784027536885 Bias: -0.6491423860867127\n",
      "Epoch: 328 Loss: 0.6231643586980522Weight 1: 0.8986844950353244 Weight 2: 0.7067997974733552 Bias: -0.650322593750471\n",
      "Epoch: 329 Loss: 0.6230109749945227Weight 1: 0.8986826643201491 Weight 2: 0.7064233887817409 Bias: -0.6514994341858688\n",
      "Epoch: 330 Loss: 0.6228585497071221Weight 1: 0.8986821159746718 Weight 2: 0.7060491688166012 Bias: -0.6526729192703674\n",
      "Epoch: 331 Loss: 0.622707075907296Weight 1: 0.8986828454444268 Weight 2: 0.7056771297356259 Bias: -0.6538430608467095\n",
      "Epoch: 332 Loss: 0.622556546713779Weight 1: 0.8986848481877913 Weight 2: 0.7053072637164756 Bias: -0.6550098707229236\n",
      "Epoch: 333 Loss: 0.6224069552923222Weight 1: 0.8986881196759895 Weight 2: 0.7049395629568159 Bias: -0.6561733606723302\n",
      "Epoch: 334 Loss: 0.622258294855421Weight 1: 0.8986926553930954 Weight 2: 0.7045740196743517 Bias: -0.6573335424335498\n",
      "Epoch: 335 Loss: 0.6221105586620443Weight 1: 0.8986984508360344 Weight 2: 0.7042106261068592 Bias: -0.6584904277105111\n",
      "Epoch: 336 Loss: 0.6219637400173639Weight 1: 0.8987055015145855 Weight 2: 0.7038493745122173 Bias: -0.6596440281724618\n",
      "Epoch: 337 Loss: 0.6218178322724848Weight 1: 0.8987138029513821 Weight 2: 0.703490257168437 Bias: -0.6607943554539796\n",
      "Epoch: 338 Loss: 0.6216728288241763Weight 1: 0.8987233506819129 Weight 2: 0.7031332663736911 Bias: -0.6619414211549849\n",
      "Epoch: 339 Loss: 0.6215287231146046Weight 1: 0.8987341402545216 Weight 2: 0.702778394446341 Bias: -0.663085236840755\n",
      "Epoch: 340 Loss: 0.6213855086310655Weight 1: 0.8987461672304068 Weight 2: 0.7024256337249639 Bias: -0.6642258140419391\n",
      "Epoch: 341 Loss: 0.6212431789057171Weight 1: 0.898759427183621 Weight 2: 0.7020749765683775 Bias: -0.6653631642545746\n",
      "Epoch: 342 Loss: 0.6211017275153167Weight 1: 0.898773915701069 Weight 2: 0.7017264153556643 Bias: -0.6664972989401049\n",
      "Epoch: 343 Loss: 0.6209611480809533Weight 1: 0.8987896283825061 Weight 2: 0.7013799424861951 Bias: -0.6676282295253979\n",
      "Epoch: 344 Loss: 0.6208214342677877Weight 1: 0.8988065608405356 Weight 2: 0.7010355503796504 Bias: -0.6687559674027661\n",
      "Epoch: 345 Loss: 0.620682579784786Weight 1: 0.8988247087006057 Weight 2: 0.7006932314760417 Bias: -0.6698805239299876\n",
      "Epoch: 346 Loss: 0.6205445783844605Weight 1: 0.8988440676010067 Weight 2: 0.700352978235731 Bias: -0.6710019104303286\n",
      "Epoch: 347 Loss: 0.6204074238626072Weight 1: 0.8988646331928664 Weight 2: 0.7000147831394495 Bias: -0.6721201381925661\n",
      "Epoch: 348 Loss: 0.6202711100580467Weight 1: 0.8988864011401462 Weight 2: 0.6996786386883157 Bias: -0.673235218471013\n",
      "Epoch: 349 Loss: 0.6201356308523648Weight 1: 0.8989093671196362 Weight 2: 0.6993445374038515 Bias: -0.6743471624855429\n",
      "Epoch: 350 Loss: 0.6200009801696544Weight 1: 0.8989335268209503 Weight 2: 0.6990124718279979 Bias: -0.6754559814216177\n",
      "Epoch: 351 Loss: 0.6198671519762585Weight 1: 0.8989588759465198 Weight 2: 0.6986824345231298 Bias: -0.6765616864303141\n",
      "Epoch: 352 Loss: 0.6197341402805134Weight 1: 0.898985410211588 Weight 2: 0.6983544180720695 Bias: -0.6776642886283532\n",
      "Epoch: 353 Loss: 0.6196019391324943Weight 1: 0.899013125344203 Weight 2: 0.6980284150780991 Bias: -0.6787637990981295\n",
      "Epoch: 354 Loss: 0.6194705426237594Weight 1: 0.8990420170852114 Weight 2: 0.6977044181649722 Bias: -0.679860228887742\n",
      "Epoch: 355 Loss: 0.6193399448870995Weight 1: 0.8990720811882504 Weight 2: 0.6973824199769246 Bias: -0.6809535890110262\n",
      "Epoch: 356 Loss: 0.6192101400962815Weight 1: 0.8991033134197403 Weight 2: 0.697062413178684 Bias: -0.682043890447586\n",
      "Epoch: 357 Loss: 0.6190811224658006Weight 1: 0.8991357095588756 Weight 2: 0.6967443904554783 Bias: -0.683131144142828\n",
      "Epoch: 358 Loss: 0.6189528862506284Weight 1: 0.8991692653976173 Weight 2: 0.6964283445130441 Bias: -0.6842153610079961\n",
      "Epoch: 359 Loss: 0.6188254257459629Weight 1: 0.8992039767406834 Weight 2: 0.696114268077633 Bias: -0.6852965519202064\n",
      "Epoch: 360 Loss: 0.6186987352869815Weight 1: 0.8992398394055394 Weight 2: 0.6958021538960176 Bias: -0.6863747277224848\n",
      "Epoch: 361 Loss: 0.6185728092485923Weight 1: 0.8992768492223885 Weight 2: 0.695491994735497 Bias: -0.6874498992238032\n",
      "Epoch: 362 Loss: 0.6184476420451881Weight 1: 0.8993150020341615 Weight 2: 0.6951837833839006 Bias: -0.6885220771991186\n",
      "Epoch: 363 Loss: 0.6183232281304016Weight 1: 0.8993542936965062 Weight 2: 0.6948775126495913 Bias: -0.6895912723894121\n",
      "Epoch: 364 Loss: 0.6181995619968599Weight 1: 0.8993947200777764 Weight 2: 0.6945731753614682 Bias: -0.6906574955017287\n",
      "Epoch: 365 Loss: 0.6180766381759423Weight 1: 0.8994362770590207 Weight 2: 0.6942707643689683 Bias: -0.6917207572092183\n",
      "Epoch: 366 Loss: 0.6179544512375367Weight 1: 0.8994789605339706 Weight 2: 0.6939702725420666 Bias: -0.6927810681511777\n",
      "Epoch: 367 Loss: 0.6178329957897998Weight 1: 0.8995227664090287 Weight 2: 0.6936716927712766 Bias: -0.6938384389330927\n",
      "Epoch: 368 Loss: 0.6177122664789149Weight 1: 0.8995676906032561 Weight 2: 0.6933750179676494 Bias: -0.694892880126682\n",
      "Epoch: 369 Loss: 0.6175922579888549Weight 1: 0.89961372904836 Weight 2: 0.6930802410627716 Bias: -0.695944402269941\n",
      "Epoch: 370 Loss: 0.6174729650411419Weight 1: 0.8996608776886802 Weight 2: 0.6927873550087628 Bias: -0.6969930158671871\n",
      "Epoch: 371 Loss: 0.6173543823946116Weight 1: 0.8997091324811759 Weight 2: 0.6924963527782725 Bias: -0.698038731389105\n",
      "Epoch: 372 Loss: 0.6172365048451766Weight 1: 0.899758489395412 Weight 2: 0.6922072273644762 Bias: -0.6990815592727938\n",
      "Epoch: 373 Loss: 0.6171193272255913Weight 1: 0.8998089444135451 Weight 2: 0.6919199717810698 Bias: -0.700121509921814\n",
      "Epoch: 374 Loss: 0.617002844405218Weight 1: 0.8998604935303087 Weight 2: 0.6916345790622647 Bias: -0.7011585937062353\n",
      "Epoch: 375 Loss: 0.6168870512897939Weight 1: 0.8999131327529992 Weight 2: 0.6913510422627811 Bias: -0.7021928209626861\n",
      "Epoch: 376 Loss: 0.6167719428211994Weight 1: 0.8999668581014603 Weight 2: 0.6910693544578409 Bias: -0.7032242019944019\n",
      "Epoch: 377 Loss: 0.6166575139772266Weight 1: 0.9000216656080676 Weight 2: 0.6907895087431599 Bias: -0.7042527470712765\n",
      "Epoch: 378 Loss: 0.6165437597713509Weight 1: 0.9000775513177138 Weight 2: 0.6905114982349394 Bias: -0.7052784664299121\n",
      "Epoch: 379 Loss: 0.6164306752524997Weight 1: 0.9001345112877919 Weight 2: 0.6902353160698566 Bias: -0.7063013702736715\n",
      "Epoch: 380 Loss: 0.6163182555048287Weight 1: 0.9001925415881792 Weight 2: 0.6899609554050546 Bias: -0.7073214687727298\n",
      "Epoch: 381 Loss: 0.6162064956474915Weight 1: 0.9002516383012212 Weight 2: 0.6896884094181326 Bias: -0.7083387720641279\n",
      "Epoch: 382 Loss: 0.6160953908344159Weight 1: 0.9003117975217145 Weight 2: 0.6894176713071332 Bias: -0.709353290251825\n",
      "Epoch: 383 Loss: 0.6159849362540798Weight 1: 0.9003730153568897 Weight 2: 0.6891487342905315 Bias: -0.710365033406754\n",
      "Epoch: 384 Loss: 0.6158751271292866Weight 1: 0.9004352879263943 Weight 2: 0.688881591607222 Bias: -0.7113740115668756\n",
      "Epoch: 385 Loss: 0.615765958716944Weight 1: 0.9004986113622746 Weight 2: 0.6886162365165052 Bias: -0.7123802347372338\n",
      "Epoch: 386 Loss: 0.6156574263078425Weight 1: 0.9005629818089586 Weight 2: 0.6883526622980738 Bias: -0.7133837128900119\n",
      "Epoch: 387 Loss: 0.6155495252264344Weight 1: 0.9006283954232371 Weight 2: 0.6880908622519982 Bias: -0.7143844559645892\n",
      "Epoch: 388 Loss: 0.615442250830616Weight 1: 0.9006948483742462 Weight 2: 0.6878308296987111 Bias: -0.7153824738675985\n",
      "Epoch: 389 Loss: 0.6153355985115091Weight 1: 0.9007623368434475 Weight 2: 0.6875725579789916 Bias: -0.7163777764729831\n",
      "Epoch: 390 Loss: 0.6152295636932442Weight 1: 0.9008308570246104 Weight 2: 0.687316040453949 Bias: -0.7173703736220558\n",
      "Epoch: 391 Loss: 0.6151241418327438Weight 1: 0.900900405123792 Weight 2: 0.6870612705050057 Bias: -0.7183602751235577\n",
      "Epoch: 392 Loss: 0.6150193284195091Weight 1: 0.9009709773593184 Weight 2: 0.6868082415338792 Bias: -0.7193474907537173\n",
      "Epoch: 393 Loss: 0.6149151189754056Weight 1: 0.9010425699617648 Weight 2: 0.6865569469625646 Bias: -0.7203320302563108\n",
      "Epoch: 394 Loss: 0.6148115090544498Weight 1: 0.9011151791739356 Weight 2: 0.6863073802333153 Bias: -0.7213139033427224\n",
      "Epoch: 395 Loss: 0.6147084942425991Weight 1: 0.9011888012508444 Weight 2: 0.6860595348086236 Bias: -0.7222931196920053\n",
      "Epoch: 396 Loss: 0.6146060701575403Weight 1: 0.9012634324596941 Weight 2: 0.6858134041712012 Bias: -0.7232696889509432\n",
      "Epoch: 397 Loss: 0.6145042324484807Weight 1: 0.9013390690798557 Weight 2: 0.6855689818239585 Bias: -0.7242436207341125\n",
      "Epoch: 398 Loss: 0.6144029767959398Weight 1: 0.901415707402848 Weight 2: 0.6853262612899838 Bias: -0.7252149246239444\n",
      "Epoch: 399 Loss: 0.6143022989115419Weight 1: 0.9014933437323167 Weight 2: 0.6850852361125211 Bias: -0.7261836101707881\n",
      "Epoch: 400 Loss: 0.6142021945378097Weight 1: 0.901571974384013 Weight 2: 0.6848458998549495 Bias: -0.7271496868929742\n",
      "Epoch: 401 Loss: 0.6141026594479603Weight 1: 0.9016515956857725 Weight 2: 0.684608246100759 Bias: -0.7281131642768783\n",
      "Epoch: 402 Loss: 0.6140036894456998Weight 1: 0.9017322039774933 Weight 2: 0.6843722684535286 Bias: -0.7290740517769857\n",
      "Epoch: 403 Loss: 0.6139052803650217Weight 1: 0.9018137956111149 Weight 2: 0.6841379605369023 Bias: -0.7300323588159559\n",
      "Epoch: 404 Loss: 0.6138074280700045Weight 1: 0.9018963669505953 Weight 2: 0.683905315994565 Bias: -0.7309880947846876\n",
      "Epoch: 405 Loss: 0.6137101284546099Weight 1: 0.9019799143718897 Weight 2: 0.6836743284902183 Bias: -0.731941269042385\n",
      "Epoch: 406 Loss: 0.6136133774424858Weight 1: 0.9020644342629281 Weight 2: 0.6834449917075549 Bias: -0.732891890916623\n",
      "Epoch: 407 Loss: 0.6135171709867646Weight 1: 0.9021499230235923 Weight 2: 0.6832172993502338 Bias: -0.7338399697034139\n",
      "Epoch: 408 Loss: 0.6134215050698679Weight 1: 0.9022363770656935 Weight 2: 0.682991245141854 Bias: -0.7347855146672744\n",
      "Epoch: 409 Loss: 0.6133263757033083Weight 1: 0.9023237928129494 Weight 2: 0.6827668228259284 Bias: -0.7357285350412923\n",
      "Epoch: 410 Loss: 0.6132317789274959Weight 1: 0.9024121667009614 Weight 2: 0.6825440261658562 Bias: -0.7366690400271948\n",
      "Epoch: 411 Loss: 0.6131377108115422Weight 1: 0.902501495177191 Weight 2: 0.6823228489448966 Bias: -0.7376070387954157\n",
      "Epoch: 412 Loss: 0.6130441674530674Weight 1: 0.902591774700937 Weight 2: 0.6821032849661406 Bias: -0.738542540485164\n",
      "Epoch: 413 Loss: 0.6129511449780091Weight 1: 0.9026830017433112 Weight 2: 0.6818853280524828 Bias: -0.7394755542044925\n",
      "Epoch: 414 Loss: 0.6128586395404292Weight 1: 0.9027751727872153 Weight 2: 0.6816689720465932 Bias: -0.7404060890303671\n",
      "Epoch: 415 Loss: 0.6127666473223256Weight 1: 0.9028682843273169 Weight 2: 0.6814542108108878 Bias: -0.7413341540087354\n",
      "Epoch: 416 Loss: 0.6126751645334422Weight 1: 0.9029623328700255 Weight 2: 0.6812410382274996 Bias: -0.742259758154597\n",
      "Epoch: 417 Loss: 0.6125841874110808Weight 1: 0.9030573149334682 Weight 2: 0.6810294481982486 Bias: -0.7431829104520733\n",
      "Epoch: 418 Loss: 0.6124937122199149Weight 1: 0.9031532270474656 Weight 2: 0.6808194346446119 Bias: -0.7441036198544776\n",
      "Epoch: 419 Loss: 0.6124037352518029Weight 1: 0.9032500657535073 Weight 2: 0.680610991507693 Bias: -0.7450218952843858\n",
      "Epoch: 420 Loss: 0.6123142528256037Weight 1: 0.9033478276047273 Weight 2: 0.6804041127481907 Bias: -0.7459377456337073\n",
      "Epoch: 421 Loss: 0.6122252612869934Weight 1: 0.9034465091658794 Weight 2: 0.6801987923463682 Bias: -0.7468511797637564\n",
      "Epoch: 422 Loss: 0.6121367570082813Weight 1: 0.9035461070133122 Weight 2: 0.6799950243020212 Bias: -0.7477622065053232\n",
      "Epoch: 423 Loss: 0.6120487363882284Weight 1: 0.9036466177349439 Weight 2: 0.6797928026344461 Bias: -0.748670834658746\n",
      "Epoch: 424 Loss: 0.6119611958518684Weight 1: 0.9037480379302378 Weight 2: 0.6795921213824072 Bias: -0.7495770729939827\n",
      "Epoch: 425 Loss: 0.6118741318503255Weight 1: 0.9038503642101766 Weight 2: 0.6793929746041045 Bias: -0.7504809302506835\n",
      "Epoch: 426 Loss: 0.6117875408606372Weight 1: 0.9039535931972371 Weight 2: 0.6791953563771406 Bias: -0.7513824151382634\n",
      "Epoch: 427 Loss: 0.6117014193855771Weight 1: 0.9040577215253647 Weight 2: 0.6789992607984867 Bias: -0.7522815363359746\n",
      "Epoch: 428 Loss: 0.6116157639534768Weight 1: 0.9041627458399479 Weight 2: 0.6788046819844499 Bias: -0.7531783024929799\n",
      "Epoch: 429 Loss: 0.6115305711180518Weight 1: 0.9042686627977927 Weight 2: 0.6786116140706383 Bias: -0.7540727222284258\n",
      "Epoch: 430 Loss: 0.6114458374582261Weight 1: 0.9043754690670964 Weight 2: 0.678420051211927 Bias: -0.754964804131516\n",
      "Epoch: 431 Loss: 0.6113615595779588Weight 1: 0.904483161327422 Weight 2: 0.6782299875824237 Bias: -0.7558545567615851\n",
      "Epoch: 432 Loss: 0.6112777341060719Weight 1: 0.9045917362696719 Weight 2: 0.6780414173754332 Bias: -0.7567419886481725\n",
      "Epoch: 433 Loss: 0.6111943576960789Weight 1: 0.9047011905960621 Weight 2: 0.6778543348034226 Bias: -0.7576271082910967\n",
      "Epoch: 434 Loss: 0.6111114270260134Weight 1: 0.9048115210200957 Weight 2: 0.6776687340979853 Bias: -0.7585099241605292\n",
      "Epoch: 435 Loss: 0.6110289387982606Weight 1: 0.9049227242665363 Weight 2: 0.6774846095098059 Bias: -0.7593904446970695\n",
      "Epoch: 436 Loss: 0.6109468897393884Weight 1: 0.9050347970713822 Weight 2: 0.6773019553086232 Bias: -0.7602686783118197\n",
      "Epoch: 437 Loss: 0.6108652765999799Weight 1: 0.9051477361818394 Weight 2: 0.6771207657831945 Bias: -0.7611446333864591\n",
      "Epoch: 438 Loss: 0.6107840961544672Weight 1: 0.905261538356295 Weight 2: 0.6769410352412583 Bias: -0.7620183182733197\n",
      "Epoch: 439 Loss: 0.6107033452009653Weight 1: 0.9053762003642905 Weight 2: 0.6767627580094981 Bias: -0.7628897412954612\n",
      "Epoch: 440 Loss: 0.6106230205611081Weight 1: 0.9054917189864952 Weight 2: 0.6765859284335048 Bias: -0.7637589107467465\n",
      "Epoch: 441 Loss: 0.6105431190798849Weight 1: 0.905608091014679 Weight 2: 0.6764105408777391 Bias: -0.7646258348919174\n",
      "Epoch: 442 Loss: 0.6104636376254777Weight 1: 0.9057253132516857 Weight 2: 0.676236589725494 Bias: -0.7654905219666699\n",
      "Epoch: 443 Loss: 0.6103845730890997Weight 1: 0.9058433825114058 Weight 2: 0.6760640693788571 Bias: -0.7663529801777308\n",
      "Epoch: 444 Loss: 0.6103059223848342Weight 1: 0.9059622956187495 Weight 2: 0.6758929742586718 Bias: -0.767213217702933\n",
      "Epoch: 445 Loss: 0.6102276824494761Weight 1: 0.9060820494096192 Weight 2: 0.6757232988044996 Bias: -0.7680712426912925\n",
      "Epoch: 446 Loss: 0.6101498502423724Weight 1: 0.9062026407308825 Weight 2: 0.6755550374745808 Bias: -0.7689270632630836\n",
      "Epoch: 447 Loss: 0.6100724227452644Weight 1: 0.9063240664403448 Weight 2: 0.6753881847457962 Bias: -0.7697806875099165\n",
      "Epoch: 448 Loss: 0.609995396962132Weight 1: 0.9064463234067217 Weight 2: 0.6752227351136275 Bias: -0.770632123494813\n",
      "Epoch: 449 Loss: 0.6099187699190367Weight 1: 0.9065694085096119 Weight 2: 0.6750586830921184 Bias: -0.7714813792522838\n",
      "Epoch: 450 Loss: 0.6098425386639679Weight 1: 0.9066933186394692 Weight 2: 0.6748960232138348 Bias: -0.7723284627884047\n",
      "Epoch: 451 Loss: 0.609766700266688Weight 1: 0.9068180506975754 Weight 2: 0.6747347500298252 Bias: -0.7731733820808941\n",
      "Epoch: 452 Loss: 0.6096912518185805Weight 1: 0.9069436015960118 Weight 2: 0.6745748581095808 Bias: -0.7740161450791896\n",
      "Epoch: 453 Loss: 0.6096161904324972Weight 1: 0.9070699682576326 Weight 2: 0.6744163420409953 Bias: -0.774856759704525\n",
      "Epoch: 454 Loss: 0.6095415132426084Weight 1: 0.9071971476160362 Weight 2: 0.6742591964303246 Bias: -0.7756952338500082\n",
      "Epoch: 455 Loss: 0.6094672174042507Weight 1: 0.9073251366155378 Weight 2: 0.6741034159021464 Bias: -0.7765315753806974\n",
      "Epoch: 456 Loss: 0.60939330009378Weight 1: 0.9074539322111413 Weight 2: 0.6739489950993193 Bias: -0.7773657921336796\n",
      "Epoch: 457 Loss: 0.6093197585084227Weight 1: 0.9075835313685116 Weight 2: 0.673795928682942 Bias: -0.7781978919181473\n",
      "Epoch: 458 Loss: 0.6092465898661277Weight 1: 0.9077139310639462 Weight 2: 0.6736442113323126 Bias: -0.779027882515476\n",
      "Epoch: 459 Loss: 0.6091737914054198Weight 1: 0.9078451282843477 Weight 2: 0.6734938377448867 Bias: -0.7798557716793023\n",
      "Epoch: 460 Loss: 0.6091013603852568Weight 1: 0.9079771200271954 Weight 2: 0.6733448026362366 Bias: -0.7806815671356014\n",
      "Epoch: 461 Loss: 0.609029294084881Weight 1: 0.9081099033005173 Weight 2: 0.6731971007400097 Bias: -0.7815052765827646\n",
      "Epoch: 462 Loss: 0.6089575898036793Weight 1: 0.9082434751228616 Weight 2: 0.6730507268078864 Bias: -0.7823269076916769\n",
      "Epoch: 463 Loss: 0.608886244861038Weight 1: 0.9083778325232691 Weight 2: 0.6729056756095385 Bias: -0.7831464681057955\n",
      "Epoch: 464 Loss: 0.6088152565962021Weight 1: 0.9085129725412444 Weight 2: 0.6727619419325874 Bias: -0.783963965441227\n",
      "Epoch: 465 Loss: 0.6087446223681341Weight 1: 0.9086488922267281 Weight 2: 0.6726195205825616 Bias: -0.784779407286806\n",
      "Epoch: 466 Loss: 0.6086743395553736Weight 1: 0.908785588640068 Weight 2: 0.6724784063828544 Bias: -0.7855928012041721\n",
      "Epoch: 467 Loss: 0.6086044055558993Weight 1: 0.9089230588519911 Weight 2: 0.6723385941746819 Bias: -0.786404154727849\n",
      "Epoch: 468 Loss: 0.6085348177869895Weight 1: 0.9090612999435753 Weight 2: 0.6722000788170399 Bias: -0.7872134753653217\n",
      "Epoch: 469 Loss: 0.6084655736850855Weight 1: 0.9092003090062207 Weight 2: 0.6720628551866614 Bias: -0.7880207705971151\n",
      "Epoch: 470 Loss: 0.6083966707056545Weight 1: 0.9093400831416214 Weight 2: 0.6719269181779739 Bias: -0.7888260478768715\n",
      "Epoch: 471 Loss: 0.6083281063230546Weight 1: 0.9094806194617369 Weight 2: 0.6717922627030561 Bias: -0.7896293146314294\n",
      "Epoch: 472 Loss: 0.6082598780303999Weight 1: 0.9096219150887637 Weight 2: 0.6716588836915954 Bias: -0.790430578260901\n",
      "Epoch: 473 Loss: 0.6081919833394264Weight 1: 0.9097639671551069 Weight 2: 0.671526776090844 Bias: -0.7912298461387509\n",
      "Epoch: 474 Loss: 0.6081244197803589Weight 1: 0.9099067728033516 Weight 2: 0.671395934865576 Bias: -0.7920271256118736\n",
      "Epoch: 475 Loss: 0.6080571849017798Weight 1: 0.9100503291862344 Weight 2: 0.6712663549980441 Bias: -0.7928224240006723\n",
      "Epoch: 476 Loss: 0.6079902762704962Weight 1: 0.9101946334666147 Weight 2: 0.6711380314879357 Bias: -0.7936157485991364\n",
      "Epoch: 477 Loss: 0.6079236914714105Weight 1: 0.9103396828174463 Weight 2: 0.6710109593523295 Bias: -0.7944071066749204\n",
      "Epoch: 478 Loss: 0.6078574281073909Weight 1: 0.9104854744217487 Weight 2: 0.6708851336256517 Bias: -0.7951965054694213\n",
      "Epoch: 479 Loss: 0.6077914837991426Weight 1: 0.9106320054725786 Weight 2: 0.6707605493596324 Bias: -0.7959839521978571\n",
      "Epoch: 480 Loss: 0.607725856185079Weight 1: 0.9107792731730014 Weight 2: 0.6706372016232611 Bias: -0.7967694540493451\n",
      "Epoch: 481 Loss: 0.6076605429211954Weight 1: 0.9109272747360624 Weight 2: 0.6705150855027434 Bias: -0.7975530181869795\n",
      "Epoch: 482 Loss: 0.6075955416809431Weight 1: 0.9110760073847579 Weight 2: 0.6703941961014565 Bias: -0.7983346517479102\n",
      "Epoch: 483 Loss: 0.6075308501551026Weight 1: 0.9112254683520072 Weight 2: 0.6702745285399049 Bias: -0.7991143618434199\n",
      "Epoch: 484 Loss: 0.6074664660516604Weight 1: 0.9113756548806238 Weight 2: 0.6701560779556766 Bias: -0.7998921555590032\n",
      "Epoch: 485 Loss: 0.6074023870956851Weight 1: 0.911526564223286 Weight 2: 0.6700388395033983 Bias: -0.8006680399544438\n",
      "Epoch: 486 Loss: 0.6073386110292028Weight 1: 0.9116781936425096 Weight 2: 0.6699228083546912 Bias: -0.801442022063893\n",
      "Epoch: 487 Loss: 0.6072751356110772Weight 1: 0.911830540410618 Weight 2: 0.6698079796981266 Bias: -0.8022141088959474\n",
      "Epoch: 488 Loss: 0.6072119586168864Weight 1: 0.911983601809714 Weight 2: 0.669694348739181 Bias: -0.8029843074337266\n",
      "Epoch: 489 Loss: 0.6071490778388037Weight 1: 0.9121373751316517 Weight 2: 0.6695819107001919 Bias: -0.8037526246349517\n",
      "Epoch: 490 Loss: 0.6070864910854771Weight 1: 0.9122918576780069 Weight 2: 0.6694706608203129 Bias: -0.8045190674320226\n",
      "Epoch: 491 Loss: 0.60702419618191Weight 1: 0.9124470467600492 Weight 2: 0.6693605943554688 Bias: -0.805283642732096\n",
      "Epoch: 492 Loss: 0.6069621909693437Weight 1: 0.9126029396987128 Weight 2: 0.6692517065783112 Bias: -0.806046357417163\n",
      "Epoch: 493 Loss: 0.6069004733051404Weight 1: 0.9127595338245682 Weight 2: 0.6691439927781733 Bias: -0.806807218344127\n",
      "Epoch: 494 Loss: 0.6068390410626648Weight 1: 0.9129168264777937 Weight 2: 0.669037448261025 Bias: -0.8075662323448812\n",
      "Epoch: 495 Loss: 0.6067778921311707Weight 1: 0.9130748150081465 Weight 2: 0.6689320683494282 Bias: -0.808323406226386\n",
      "Epoch: 496 Loss: 0.6067170244156838Weight 1: 0.9132334967749339 Weight 2: 0.6688278483824917 Bias: -0.8090787467707469\n",
      "Epoch: 497 Loss: 0.6066564358368884Weight 1: 0.9133928691469855 Weight 2: 0.6687247837158258 Bias: -0.8098322607352916\n",
      "Epoch: 498 Loss: 0.6065961243310145Weight 1: 0.9135529295026236 Weight 2: 0.6686228697214976 Bias: -0.8105839548526477\n",
      "Epoch: 499 Loss: 0.6065360878497232Weight 1: 0.9137136752296352 Weight 2: 0.6685221017879861 Bias: -0.8113338358308197\n",
      "Epoch: 500 Loss: 0.6064763243599965Weight 1: 0.9138751037252435 Weight 2: 0.6684224753201362 Bias: -0.8120819103532668\n",
      "Epoch: 501 Loss: 0.6064168318440248Weight 1: 0.914037212396079 Weight 2: 0.6683239857391142 Bias: -0.8128281850789791\n",
      "Epoch: 502 Loss: 0.6063576082990976Weight 1: 0.9141999986581514 Weight 2: 0.6682266284823625 Bias: -0.8135726666425558\n",
      "Epoch: 503 Loss: 0.6062986517374923Weight 1: 0.9143634599368203 Weight 2: 0.6681303990035539 Bias: -0.8143153616542814\n",
      "Epoch: 504 Loss: 0.6062399601863664Weight 1: 0.9145275936667678 Weight 2: 0.6680352927725467 Bias: -0.8150562767002032\n",
      "Epoch: 505 Loss: 0.6061815316876487Weight 1: 0.9146923972919692 Weight 2: 0.6679413052753395 Bias: -0.8157954183422079\n",
      "Epoch: 506 Loss: 0.6061233642979311Weight 1: 0.9148578682656645 Weight 2: 0.6678484320140253 Bias: -0.8165327931180986\n",
      "Epoch: 507 Loss: 0.6060654560883635Weight 1: 0.9150240040503306 Weight 2: 0.667756668506747 Bias: -0.817268407541671\n",
      "Epoch: 508 Loss: 0.6060078051445458Weight 1: 0.9151908021176522 Weight 2: 0.6676660102876509 Bias: -0.8180022681027905\n",
      "Epoch: 509 Loss: 0.6059504095664239Weight 1: 0.9153582599484941 Weight 2: 0.6675764529068424 Bias: -0.8187343812674689\n",
      "Epoch: 510 Loss: 0.6058932674681841Weight 1: 0.9155263750328718 Weight 2: 0.6674879919303399 Bias: -0.81946475347794\n",
      "Epoch: 511 Loss: 0.6058363769781496Weight 1: 0.9156951448699243 Weight 2: 0.6674006229400297 Bias: -0.8201933911527368\n",
      "Epoch: 512 Loss: 0.6057797362386774Weight 1: 0.915864566967885 Weight 2: 0.6673143415336203 Bias: -0.8209203006867674\n",
      "Epoch: 513 Loss: 0.6057233434060553Weight 1: 0.9160346388440537 Weight 2: 0.6672291433245975 Bias: -0.8216454884513908\n",
      "Epoch: 514 Loss: 0.6056671966504004Weight 1: 0.916205358024768 Weight 2: 0.6671450239421783 Bias: -0.8223689607944938\n",
      "Epoch: 515 Loss: 0.6056112941555575Weight 1: 0.9163767220453756 Weight 2: 0.6670619790312661 Bias: -0.823090724040566\n",
      "Epoch: 516 Loss: 0.6055556341189999Weight 1: 0.9165487284502056 Weight 2: 0.6669800042524044 Bias: -0.8238107844907762\n",
      "Epoch: 517 Loss: 0.6055002147517279Weight 1: 0.9167213747925406 Weight 2: 0.6668990952817325 Bias: -0.8245291484230478\n",
      "Epoch: 518 Loss: 0.6054450342781705Weight 1: 0.9168946586345882 Weight 2: 0.6668192478109392 Bias: -0.825245822092135\n",
      "Epoch: 519 Loss: 0.6053900909360876Weight 1: 0.9170685775474533 Weight 2: 0.6667404575472174 Bias: -0.8259608117296976\n",
      "Epoch: 520 Loss: 0.605335382976472Weight 1: 0.9172431291111096 Weight 2: 0.6666627202132195 Bias: -0.8266741235443767\n",
      "Epoch: 521 Loss: 0.6052809086634506Weight 1: 0.9174183109143719 Weight 2: 0.6665860315470108 Bias: -0.8273857637218703\n",
      "Epoch: 522 Loss: 0.605226666274191Weight 1: 0.9175941205548677 Weight 2: 0.6665103873020249 Bias: -0.8280957384250079\n",
      "Epoch: 523 Loss: 0.6051726540988039Weight 1: 0.9177705556390094 Weight 2: 0.6664357832470182 Bias: -0.828804053793826\n",
      "Epoch: 524 Loss: 0.6051188704402478Weight 1: 0.9179476137819665 Weight 2: 0.6663622151660242 Bias: -0.8295107159456429\n",
      "Epoch: 525 Loss: 0.6050653136142361Weight 1: 0.9181252926076372 Weight 2: 0.6662896788583086 Bias: -0.8302157309751331\n",
      "Epoch: 526 Loss: 0.605011981949142Weight 1: 0.9183035897486209 Weight 2: 0.6662181701383234 Bias: -0.8309191049544031\n",
      "Epoch: 527 Loss: 0.6049588737859058Weight 1: 0.9184825028461903 Weight 2: 0.6661476848356622 Bias: -0.8316208439330647\n",
      "Epoch: 528 Loss: 0.6049059874779428Weight 1: 0.9186620295502632 Weight 2: 0.6660782187950144 Bias: -0.8323209539383102\n",
      "Epoch: 529 Loss: 0.604853321391051Weight 1: 0.9188421675193754 Weight 2: 0.66600976787612 Bias: -0.8330194409749867\n",
      "Epoch: 530 Loss: 0.6048008739033206Weight 1: 0.9190229144206523 Weight 2: 0.6659423279537244 Bias: -0.8337163110256699\n",
      "Epoch: 531 Loss: 0.6047486434050421Weight 1: 0.9192042679297816 Weight 2: 0.6658758949175335 Bias: -0.8344115700507386\n",
      "Epoch: 532 Loss: 0.6046966282986188Weight 1: 0.9193862257309853 Weight 2: 0.665810464672168 Bias: -0.8351052239884483\n",
      "Epoch: 533 Loss: 0.6046448269984738Weight 1: 0.9195687855169925 Weight 2: 0.6657460331371182 Bias: -0.8357972787550054\n",
      "Epoch: 534 Loss: 0.6045932379309664Weight 1: 0.9197519449890115 Weight 2: 0.6656825962466995 Bias: -0.8364877402446405\n",
      "Epoch: 535 Loss: 0.6045418595342991Weight 1: 0.9199357018567023 Weight 2: 0.6656201499500064 Bias: -0.8371766143296818\n",
      "Epoch: 536 Loss: 0.6044906902584326Weight 1: 0.9201200538381491 Weight 2: 0.6655586902108681 Bias: -0.8378639068606294\n",
      "Epoch: 537 Loss: 0.6044397285649995Weight 1: 0.920304998659833 Weight 2: 0.6654982130078032 Bias: -0.8385496236662274\n",
      "Epoch: 538 Loss: 0.6043889729272172Weight 1: 0.9204905340566043 Weight 2: 0.6654387143339747 Bias: -0.8392337705535379\n",
      "Epoch: 539 Loss: 0.6043384218298015Weight 1: 0.9206766577716556 Weight 2: 0.6653801901971449 Bias: -0.8399163533080134\n",
      "Epoch: 540 Loss: 0.6042880737688833Weight 1: 0.9208633675564939 Weight 2: 0.6653226366196308 Bias: -0.8405973776935702\n",
      "Epoch: 541 Loss: 0.6042379272519232Weight 1: 0.9210506611709136 Weight 2: 0.6652660496382587 Bias: -0.8412768494526608\n",
      "Epoch: 542 Loss: 0.604187980797628Weight 1: 0.9212385363829695 Weight 2: 0.6652104253043202 Bias: -0.8419547743063464\n",
      "Epoch: 543 Loss: 0.6041382329358673Weight 1: 0.9214269909689491 Weight 2: 0.6651557596835261 Bias: -0.8426311579543693\n",
      "Epoch: 544 Loss: 0.6040886822075906Weight 1: 0.921616022713346 Weight 2: 0.6651020488559631 Bias: -0.8433060060752254\n",
      "Epoch: 545 Loss: 0.6040393271647464Weight 1: 0.9218056294088323 Weight 2: 0.6650492889160479 Bias: -0.8439793243262365\n",
      "Epoch: 546 Loss: 0.6039901663701992Weight 1: 0.9219958088562318 Weight 2: 0.6649974759724829 Bias: -0.8446511183436214\n",
      "Epoch: 547 Loss: 0.6039411983976496Weight 1: 0.9221865588644932 Weight 2: 0.6649466061482122 Bias: -0.8453213937425689\n",
      "Epoch: 548 Loss: 0.6038924218315533Weight 1: 0.9223778772506629 Weight 2: 0.664896675580376 Bias: -0.8459901561173085\n",
      "Epoch: 549 Loss: 0.6038438352670429Weight 1: 0.922569761839858 Weight 2: 0.6648476804202668 Bias: -0.8466574110411829\n",
      "Epoch: 550 Loss: 0.6037954373098462Weight 1: 0.9227622104652397 Weight 2: 0.6647996168332844 Bias: -0.8473231640667181\n",
      "Epoch: 551 Loss: 0.6037472265762097Weight 1: 0.9229552209679864 Weight 2: 0.6647524809988922 Bias: -0.8479874207256961\n",
      "Epoch: 552 Loss: 0.6036992016928191Weight 1: 0.9231487911972671 Weight 2: 0.6647062691105722 Bias: -0.8486501865292247\n",
      "Epoch: 553 Loss: 0.6036513612967236Weight 1: 0.9233429190102143 Weight 2: 0.6646609773757808 Bias: -0.8493114669678093\n",
      "Epoch: 554 Loss: 0.6036037040352562Weight 1: 0.9235376022718976 Weight 2: 0.6646166020159048 Bias: -0.8499712675114233\n",
      "Epoch: 555 Loss: 0.6035562285659599Weight 1: 0.9237328388552976 Weight 2: 0.664573139266217 Bias: -0.8506295936095785\n",
      "Epoch: 556 Loss: 0.6035089335565107Weight 1: 0.9239286266412782 Weight 2: 0.6645305853758321 Bias: -0.851286450691396\n",
      "Epoch: 557 Loss: 0.6034618176846417Weight 1: 0.9241249635185612 Weight 2: 0.6644889366076627 Bias: -0.8519418441656763\n",
      "Epoch: 558 Loss: 0.6034148796380692Weight 1: 0.9243218473836994 Weight 2: 0.6644481892383753 Bias: -0.8525957794209695\n",
      "Epoch: 559 Loss: 0.6033681181144183Weight 1: 0.9245192761410501 Weight 2: 0.664408339558346 Bias: -0.8532482618256451\n",
      "Epoch: 560 Loss: 0.6033215318211491Weight 1: 0.9247172477027493 Weight 2: 0.664369383871617 Bias: -0.8538992967279619\n",
      "Epoch: 561 Loss: 0.6032751194754825Weight 1: 0.9249157599886847 Weight 2: 0.6643313184958528 Bias: -0.8545488894561379\n",
      "Epoch: 562 Loss: 0.6032288798043296Weight 1: 0.9251148109264699 Weight 2: 0.6642941397622961 Bias: -0.8551970453184196\n",
      "Epoch: 563 Loss: 0.6031828115442169Weight 1: 0.9253143984514183 Weight 2: 0.6642578440157244 Bias: -0.8558437696031509\n",
      "Epoch: 564 Loss: 0.6031369134412174Weight 1: 0.9255145205065168 Weight 2: 0.6642224276144061 Bias: -0.8564890675788432\n",
      "Epoch: 565 Loss: 0.6030911842508774Weight 1: 0.9257151750424 Weight 2: 0.6641878869300573 Bias: -0.8571329444942438\n",
      "Epoch: 566 Loss: 0.6030456227381463Weight 1: 0.9259163600173236 Weight 2: 0.6641542183477978 Bias: -0.8577754055784048\n",
      "Epoch: 567 Loss: 0.6030002276773074Weight 1: 0.9261180733971393 Weight 2: 0.6641214182661083 Bias: -0.8584164560407518\n",
      "Epoch: 568 Loss: 0.602954997851907Weight 1: 0.9263203131552682 Weight 2: 0.6640894830967864 Bias: -0.8590561010711526\n",
      "Epoch: 569 Loss: 0.6029099320546863Weight 1: 0.9265230772726755 Weight 2: 0.6640584092649039 Bias: -0.8596943458399853\n",
      "Epoch: 570 Loss: 0.602865029087512Weight 1: 0.9267263637378441 Weight 2: 0.664028193208763 Bias: -0.8603311954982065\n",
      "Epoch: 571 Loss: 0.6028202877613091Weight 1: 0.9269301705467498 Weight 2: 0.6639988313798538 Bias: -0.8609666551774195\n",
      "Epoch: 572 Loss: 0.6027757068959916Weight 1: 0.9271344957028346 Weight 2: 0.6639703202428107 Bias: -0.8616007299899423\n",
      "Epoch: 573 Loss: 0.6027312853203974Weight 1: 0.927339337216982 Weight 2: 0.6639426562753694 Bias: -0.8622334250288747\n",
      "Epoch: 574 Loss: 0.60268702187222Weight 1: 0.9275446931074909 Weight 2: 0.6639158359683246 Bias: -0.862864745368166\n",
      "Epoch: 575 Loss: 0.6026429153979433Weight 1: 0.9277505614000502 Weight 2: 0.6638898558254864 Bias: -0.863494696062683\n",
      "Epoch: 576 Loss: 0.6025989647527754Weight 1: 0.9279569401277137 Weight 2: 0.6638647123636381 Bias: -0.8641232821482763\n",
      "Epoch: 577 Loss: 0.6025551688005831Weight 1: 0.9281638273308743 Weight 2: 0.6638404021124931 Bias: -0.8647505086418475\n",
      "Epoch: 578 Loss: 0.6025115264138282Weight 1: 0.9283712210572391 Weight 2: 0.6638169216146524 Bias: -0.8653763805414167\n",
      "Epoch: 579 Loss: 0.6024680364735019Weight 1: 0.9285791193618038 Weight 2: 0.6637942674255626 Bias: -0.8660009028261882\n",
      "Epoch: 580 Loss: 0.6024246978690614Weight 1: 0.9287875203068277 Weight 2: 0.6637724361134723 Bias: -0.8666240804566175\n",
      "Epoch: 581 Loss: 0.6023815094983673Weight 1: 0.9289964219618084 Weight 2: 0.6637514242593908 Bias: -0.8672459183744776\n",
      "Epoch: 582 Loss: 0.6023384702676197Weight 1: 0.9292058224034572 Weight 2: 0.6637312284570454 Bias: -0.8678664215029251\n",
      "Epoch: 583 Loss: 0.6022955790912955Weight 1: 0.9294157197156734 Weight 2: 0.6637118453128389 Bias: -0.8684855947465661\n",
      "Epoch: 584 Loss: 0.6022528348920878Weight 1: 0.92962611198952 Weight 2: 0.6636932714458081 Bias: -0.869103442991522\n",
      "Epoch: 585 Loss: 0.6022102366008435Weight 1: 0.9298369973231986 Weight 2: 0.6636755034875813 Bias: -0.8697199711054953\n",
      "Epoch: 586 Loss: 0.6021677831565012Weight 1: 0.9300483738220241 Weight 2: 0.6636585380823363 Bias: -0.8703351839378347\n",
      "Epoch: 587 Loss: 0.6021254735060324Weight 1: 0.9302602395984008 Weight 2: 0.6636423718867588 Bias: -0.8709490863196009\n",
      "Epoch: 588 Loss: 0.60208330660438Weight 1: 0.9304725927717968 Weight 2: 0.6636270015700003 Bias: -0.8715616830636311\n",
      "Epoch: 589 Loss: 0.6020412814143988Weight 1: 0.9306854314687204 Weight 2: 0.6636124238136367 Bias: -0.8721729789646044\n",
      "Epoch: 590 Loss: 0.6019993969067967Weight 1: 0.9308987538226945 Weight 2: 0.6635986353116264 Bias: -0.8727829787991063\n",
      "Epoch: 591 Loss: 0.6019576520600745Weight 1: 0.9311125579742325 Weight 2: 0.663585632770269 Bias: -0.8733916873256931\n",
      "Epoch: 592 Loss: 0.6019160458604685Weight 1: 0.9313268420708142 Weight 2: 0.6635734129081637 Bias: -0.8739991092849568\n",
      "Epoch: 593 Loss: 0.6018745773018928Weight 1: 0.9315416042668607 Weight 2: 0.6635619724561678 Bias: -0.8746052493995892\n",
      "Epoch: 594 Loss: 0.6018332453858791Weight 1: 0.9317568427237107 Weight 2: 0.6635513081573555 Bias: -0.8752101123744452\n",
      "Epoch: 595 Loss: 0.6017920491215235Weight 1: 0.931972555609596 Weight 2: 0.6635414167669771 Bias: -0.875813702896608\n",
      "Epoch: 596 Loss: 0.6017509875254263Weight 1: 0.932188741099617 Weight 2: 0.6635322950524173 Bias: -0.8764160256354514\n",
      "Epoch: 597 Loss: 0.6017100596216367Weight 1: 0.9324053973757191 Weight 2: 0.6635239397931544 Bias: -0.8770170852427044\n",
      "Epoch: 598 Loss: 0.6016692644415974Weight 1: 0.9326225226266682 Weight 2: 0.6635163477807197 Bias: -0.8776168863525138\n",
      "Epoch: 599 Loss: 0.601628601024088Weight 1: 0.932840115048027 Weight 2: 0.663509515818656 Bias: -0.8782154335815079\n",
      "Epoch: 600 Loss: 0.601588068415171Weight 1: 0.9330581728421307 Weight 2: 0.6635034407224777 Bias: -0.8788127315288592\n",
      "Epoch: 601 Loss: 0.6015476656681361Weight 1: 0.9332766942180634 Weight 2: 0.6634981193196292 Bias: -0.8794087847763472\n",
      "Epoch: 602 Loss: 0.6015073918434458Weight 1: 0.9334956773916341 Weight 2: 0.6634935484494452 Bias: -0.8800035978884211\n",
      "Epoch: 603 Loss: 0.6014672460086818Weight 1: 0.9337151205853531 Weight 2: 0.6634897249631095 Bias: -0.8805971754122621\n",
      "Epoch: 604 Loss: 0.6014272272384921Weight 1: 0.9339350220284082 Weight 2: 0.6634866457236153 Bias: -0.881189521877846\n",
      "Epoch: 605 Loss: 0.6013873346145361Weight 1: 0.934155379956641 Weight 2: 0.6634843076057242 Bias: -0.8817806417980051\n",
      "Epoch: 606 Loss: 0.6013475672254335Weight 1: 0.9343761926125236 Weight 2: 0.6634827074959265 Bias: -0.8823705396684898\n",
      "Epoch: 607 Loss: 0.6013079241667106Weight 1: 0.9345974582451345 Weight 2: 0.6634818422924013 Bias: -0.8829592199680308\n",
      "Epoch: 608 Loss: 0.6012684045407497Weight 1: 0.934819175110136 Weight 2: 0.6634817089049756 Bias: -0.8835466871584008\n",
      "Epoch: 609 Loss: 0.6012290074567352Weight 1: 0.9350413414697502 Weight 2: 0.6634823042550854 Bias: -0.8841329456844751\n",
      "Epoch: 610 Loss: 0.6011897320306058Weight 1: 0.9352639555927357 Weight 2: 0.663483625275735 Bias: -0.8847179999742935\n",
      "Epoch: 611 Loss: 0.6011505773849997Weight 1: 0.9354870157543647 Weight 2: 0.6634856689114581 Bias: -0.885301854439121\n",
      "Epoch: 612 Loss: 0.6011115426492066Weight 1: 0.9357105202363996 Weight 2: 0.6634884321182776 Bias: -0.8858845134735089\n",
      "Epoch: 613 Loss: 0.6010726269591173Weight 1: 0.9359344673270699 Weight 2: 0.663491911863666 Bias: -0.8864659814553552\n",
      "Epoch: 614 Loss: 0.6010338294571731Weight 1: 0.936158855321049 Weight 2: 0.6634961051265065 Bias: -0.887046262745965\n",
      "Epoch: 615 Loss: 0.6009951492923169Weight 1: 0.9363836825194316 Weight 2: 0.6635010088970531 Bias: -0.8876253616901112\n",
      "Epoch: 616 Loss: 0.6009565856199445Weight 1: 0.9366089472297102 Weight 2: 0.6635066201768918 Bias: -0.8882032826160944\n",
      "Epoch: 617 Loss: 0.6009181376018549Weight 1: 0.9368346477657529 Weight 2: 0.6635129359789009 Bias: -0.8887800298358028\n",
      "Epoch: 618 Loss: 0.6008798044062029Weight 1: 0.9370607824477799 Weight 2: 0.6635199533272126 Bias: -0.8893556076447721\n",
      "Epoch: 619 Loss: 0.6008415852074513Weight 1: 0.9372873496023414 Weight 2: 0.6635276692571734 Bias: -0.8899300203222448\n",
      "Epoch: 620 Loss: 0.6008034791863219Weight 1: 0.9375143475622945 Weight 2: 0.6635360808153059 Bias: -0.89050327213123\n",
      "Epoch: 621 Loss: 0.6007654855297501Weight 1: 0.9377417746667808 Weight 2: 0.6635451850592694 Bias: -0.8910753673185625\n",
      "Epoch: 622 Loss: 0.6007276034308362Weight 1: 0.9379696292612038 Weight 2: 0.6635549790578215 Bias: -0.8916463101149616\n",
      "Epoch: 623 Loss: 0.6006898320888001Weight 1: 0.9381979096972063 Weight 2: 0.6635654598907796 Bias: -0.8922161047350904\n",
      "Epoch: 624 Loss: 0.6006521707089354Weight 1: 0.9384266143326483 Weight 2: 0.6635766246489826 Bias: -0.8927847553776139\n",
      "Epoch: 625 Loss: 0.6006146185025613Weight 1: 0.9386557415315844 Weight 2: 0.6635884704342518 Bias: -0.8933522662252584\n",
      "Epoch: 626 Loss: 0.6005771746869795Weight 1: 0.9388852896642415 Weight 2: 0.6636009943593535 Bias: -0.893918641444869\n",
      "Epoch: 627 Loss: 0.600539838485428Weight 1: 0.9391152571069966 Weight 2: 0.6636141935479603 Bias: -0.8944838851874681\n",
      "Epoch: 628 Loss: 0.6005026091270363Weight 1: 0.9393456422423551 Weight 2: 0.663628065134613 Bias: -0.8950480015883134\n",
      "Epoch: 629 Loss: 0.6004654858467803Weight 1: 0.9395764434589278 Weight 2: 0.6636426062646832 Bias: -0.8956109947669558\n",
      "Epoch: 630 Loss: 0.6004284678854392Weight 1: 0.9398076591514097 Weight 2: 0.6636578140943344 Bias: -0.8961728688272966\n",
      "Epoch: 631 Loss: 0.6003915544895512Weight 1: 0.9400392877205579 Weight 2: 0.6636736857904855 Bias: -0.8967336278576453\n",
      "Epoch: 632 Loss: 0.6003547449113692Weight 1: 0.9402713275731691 Weight 2: 0.6636902185307717 Bias: -0.897293275930777\n",
      "Epoch: 633 Loss: 0.6003180384088185Weight 1: 0.9405037771220586 Weight 2: 0.6637074095035083 Bias: -0.8978518171039891\n",
      "Epoch: 634 Loss: 0.6002814342454535Weight 1: 0.9407366347860379 Weight 2: 0.6637252559076522 Bias: -0.8984092554191583\n",
      "Epoch: 635 Loss: 0.6002449316904154Weight 1: 0.9409698989898935 Weight 2: 0.6637437549527649 Bias: -0.8989655949027976\n",
      "Epoch: 636 Loss: 0.6002085300183894Weight 1: 0.9412035681643648 Weight 2: 0.6637629038589754 Bias: -0.8995208395661126\n",
      "Epoch: 637 Loss: 0.6001722285095629Weight 1: 0.941437640746123 Weight 2: 0.6637826998569426 Bias: -0.900074993405058\n",
      "Epoch: 638 Loss: 0.6001360264495844Weight 1: 0.9416721151777492 Weight 2: 0.6638031401878186 Bias: -0.9006280604003938\n",
      "Epoch: 639 Loss: 0.6000999231295218Weight 1: 0.941906989907713 Weight 2: 0.6638242221032116 Bias: -0.901180044517741\n",
      "Epoch: 640 Loss: 0.6000639178458204Weight 1: 0.9421422633903516 Weight 2: 0.6638459428651486 Bias: -0.901730949707638\n",
      "Epoch: 641 Loss: 0.6000280099002644Weight 1: 0.9423779340858476 Weight 2: 0.6638682997460397 Bias: -0.9022807799055959\n",
      "Epoch: 642 Loss: 0.5999921985999336Weight 1: 0.9426140004602088 Weight 2: 0.6638912900286399 Bias: -0.9028295390321539\n",
      "Epoch: 643 Loss: 0.5999564832571667Weight 1: 0.9428504609852463 Weight 2: 0.663914911006014 Bias: -0.9033772309929352\n",
      "Epoch: 644 Loss: 0.5999208631895177Weight 1: 0.9430873141385535 Weight 2: 0.6639391599814991 Bias: -0.9039238596787013\n",
      "Epoch: 645 Loss: 0.5998853377197197Weight 1: 0.9433245584034853 Weight 2: 0.6639640342686689 Bias: -0.9044694289654075\n",
      "Epoch: 646 Loss: 0.5998499061756433Weight 1: 0.9435621922691367 Weight 2: 0.6639895311912969 Bias: -0.9050139427142577\n",
      "Epoch: 647 Loss: 0.5998145678902588Weight 1: 0.9438002142303226 Weight 2: 0.6640156480833204 Bias: -0.905557404771759\n",
      "Epoch: 648 Loss: 0.5997793222015978Weight 1: 0.9440386227875558 Weight 2: 0.6640423822888046 Bias: -0.9060998189697754\n",
      "Epoch: 649 Loss: 0.5997441684527136Weight 1: 0.9442774164470276 Weight 2: 0.6640697311619066 Bias: -0.9066411891255836\n",
      "Epoch: 650 Loss: 0.5997091059916446Weight 1: 0.9445165937205857 Weight 2: 0.6640976920668392 Bias: -0.9071815190419252\n",
      "Epoch: 651 Loss: 0.5996741341713754Weight 1: 0.9447561531257147 Weight 2: 0.6641262623778357 Bias: -0.9077208125070624\n",
      "Epoch: 652 Loss: 0.5996392523497994Weight 1: 0.9449960931855147 Weight 2: 0.6641554394791135 Bias: -0.9082590732948304\n",
      "Epoch: 653 Loss: 0.5996044598896825Weight 1: 0.9452364124286812 Weight 2: 0.6641852207648392 Bias: -0.9087963051646915\n",
      "Epoch: 654 Loss: 0.5995697561586248Weight 1: 0.9454771093894844 Weight 2: 0.6642156036390929 Bias: -0.9093325118617885\n",
      "Epoch: 655 Loss: 0.5995351405290251Weight 1: 0.9457181826077488 Weight 2: 0.6642465855158328 Bias: -0.9098676971169981\n",
      "Epoch: 656 Loss: 0.5995006123780441Weight 1: 0.945959630628833 Weight 2: 0.6642781638188598 Bias: -0.9104018646469834\n",
      "Epoch: 657 Loss: 0.5994661710875671Weight 1: 0.9462014520036095 Weight 2: 0.6643103359817828 Bias: -0.910935018154247\n",
      "Epoch: 658 Loss: 0.5994318160441702Weight 1: 0.9464436452884442 Weight 2: 0.6643430994479831 Bias: -0.9114671613271842\n",
      "Epoch: 659 Loss: 0.5993975466390838Weight 1: 0.9466862090451762 Weight 2: 0.6643764516705797 Bias: -0.9119982978401344\n",
      "Epoch: 660 Loss: 0.5993633622681566Weight 1: 0.9469291418410982 Weight 2: 0.6644103901123946 Bias: -0.9125284313534346\n",
      "Epoch: 661 Loss: 0.5993292623318207Weight 1: 0.9471724422489362 Weight 2: 0.6644449122459177 Bias: -0.9130575655134708\n",
      "Epoch: 662 Loss: 0.5992952462350583Weight 1: 0.947416108846829 Weight 2: 0.6644800155532726 Bias: -0.9135857039527305\n",
      "Epoch: 663 Loss: 0.5992613133873653Weight 1: 0.9476601402183096 Weight 2: 0.6645156975261817 Bias: -0.9141128502898541\n",
      "Epoch: 664 Loss: 0.5992274632027181Weight 1: 0.9479045349522839 Weight 2: 0.6645519556659316 Bias: -0.9146390081296869\n",
      "Epoch: 665 Loss: 0.5991936950995392Weight 1: 0.9481492916430119 Weight 2: 0.6645887874833395 Bias: -0.9151641810633303\n",
      "Epoch: 666 Loss: 0.5991600085006629Weight 1: 0.9483944088900877 Weight 2: 0.664626190498718 Bias: -0.9156883726681934\n",
      "Epoch: 667 Loss: 0.5991264028333029Weight 1: 0.9486398852984199 Weight 2: 0.6646641622418417 Bias: -0.9162115865080437\n",
      "Epoch: 668 Loss: 0.5990928775290186Weight 1: 0.948885719478212 Weight 2: 0.6647027002519127 Bias: -0.9167338261330588\n",
      "Epoch: 669 Loss: 0.5990594320236814Weight 1: 0.9491319100449427 Weight 2: 0.6647418020775271 Bias: -0.9172550950798763\n",
      "Epoch: 670 Loss: 0.5990260657574428Weight 1: 0.9493784556193466 Weight 2: 0.6647814652766407 Bias: -0.9177753968716453\n",
      "Epoch: 671 Loss: 0.5989927781747016Weight 1: 0.9496253548273952 Weight 2: 0.6648216874165357 Bias: -0.9182947350180761\n",
      "Epoch: 672 Loss: 0.5989595687240716Weight 1: 0.9498726063002768 Weight 2: 0.6648624660737865 Bias: -0.9188131130154911\n",
      "Epoch: 673 Loss: 0.5989264368583491Weight 1: 0.9501202086743779 Weight 2: 0.6649037988342269 Bias: -0.9193305343468744\n",
      "Epoch: 674 Loss: 0.5988933820344821Weight 1: 0.9503681605912634 Weight 2: 0.664945683292916 Bias: -0.9198470024819223\n",
      "Epoch: 675 Loss: 0.5988604037135375Weight 1: 0.9506164606976581 Weight 2: 0.6649881170541053 Bias: -0.9203625208770926\n",
      "Epoch: 676 Loss: 0.5988275013606715Weight 1: 0.9508651076454273 Weight 2: 0.6650310977312054 Bias: -0.9208770929756545\n",
      "Epoch: 677 Loss: 0.5987946744450958Weight 1: 0.9511141000915576 Weight 2: 0.6650746229467526 Bias: -0.9213907222077378\n",
      "Epoch: 678 Loss: 0.5987619224400502Weight 1: 0.9513634366981383 Weight 2: 0.6651186903323761 Bias: -0.9219034119903825\n",
      "Epoch: 679 Loss: 0.5987292448227691Weight 1: 0.9516131161323423 Weight 2: 0.6651632975287655 Bias: -0.9224151657275879\n",
      "Epoch: 680 Loss: 0.5986966410744523Weight 1: 0.9518631370664073 Weight 2: 0.6652084421856368 Bias: -0.9229259868103609\n",
      "Epoch: 681 Loss: 0.598664110680235Weight 1: 0.9521134981776173 Weight 2: 0.665254121961701 Bias: -0.9234358786167657\n",
      "Epoch: 682 Loss: 0.5986316531291571Weight 1: 0.9523641981482832 Weight 2: 0.6653003345246306 Bias: -0.9239448445119719\n",
      "Epoch: 683 Loss: 0.5985992679141346Weight 1: 0.952615235665725 Weight 2: 0.6653470775510274 Bias: -0.9244528878483029\n",
      "Epoch: 684 Loss: 0.5985669545319291Weight 1: 0.9528666094222528 Weight 2: 0.6653943487263903 Bias: -0.9249600119652845\n",
      "Epoch: 685 Loss: 0.5985347124831187Weight 1: 0.953118318115148 Weight 2: 0.6654421457450822 Bias: -0.9254662201896927\n",
      "Epoch: 686 Loss: 0.5985025412720698Weight 1: 0.9533703604466456 Weight 2: 0.665490466310299 Bias: -0.9259715158356018\n",
      "Epoch: 687 Loss: 0.5984704404069066Weight 1: 0.9536227351239149 Weight 2: 0.6655393081340361 Bias: -0.9264759022044322\n",
      "Epoch: 688 Loss: 0.5984384093994847Weight 1: 0.9538754408590422 Weight 2: 0.6655886689370575 Bias: -0.926979382584998\n",
      "Epoch: 689 Loss: 0.5984064477653607Weight 1: 0.9541284763690114 Weight 2: 0.6656385464488633 Bias: -0.9274819602535544\n",
      "Epoch: 690 Loss: 0.5983745550237654Weight 1: 0.9543818403756867 Weight 2: 0.6656889384076581 Bias: -0.9279836384738451\n",
      "Epoch: 691 Loss: 0.5983427306975745Weight 1: 0.954635531605794 Weight 2: 0.665739842560319 Bias: -0.9284844204971493\n",
      "Epoch: 692 Loss: 0.5983109743132824Weight 1: 0.9548895487909026 Weight 2: 0.6657912566623646 Bias: -0.9289843095623288\n",
      "Epoch: 693 Loss: 0.5982792854009733Weight 1: 0.9551438906674079 Weight 2: 0.6658431784779227 Bias: -0.9294833088958747\n",
      "Epoch: 694 Loss: 0.598247663494295Weight 1: 0.9553985559765129 Weight 2: 0.6658956057796994 Bias: -0.9299814217119542\n",
      "Epoch: 695 Loss: 0.5982161081304305Weight 1: 0.9556535434642102 Weight 2: 0.6659485363489476 Bias: -0.9304786512124569\n",
      "Epoch: 696 Loss: 0.5981846188500722Weight 1: 0.9559088518812644 Weight 2: 0.6660019679754358 Bias: -0.9309750005870411\n",
      "Epoch: 697 Loss: 0.5981531951973946Weight 1: 0.9561644799831944 Weight 2: 0.666055898457417 Bias: -0.9314704730131802\n",
      "Epoch: 698 Loss: 0.5981218367200278Weight 1: 0.9564204265302555 Weight 2: 0.6661103256015977 Bias: -0.9319650716562086\n",
      "Epoch: 699 Loss: 0.5980905429690315Weight 1: 0.9566766902874216 Weight 2: 0.6661652472231068 Bias: -0.9324587996693672\n",
      "Epoch: 700 Loss: 0.5980593134988684Weight 1: 0.9569332700243679 Weight 2: 0.6662206611454651 Bias: -0.9329516601938497\n",
      "Epoch: 701 Loss: 0.5980281478673787Weight 1: 0.957190164515453 Weight 2: 0.6662765652005543 Bias: -0.9334436563588476\n",
      "Epoch: 702 Loss: 0.5979970456357541Weight 1: 0.9574473725397018 Weight 2: 0.6663329572285865 Bias: -0.933934791281596\n",
      "Epoch: 703 Loss: 0.5979660063685116Weight 1: 0.9577048928807878 Weight 2: 0.6663898350780736 Bias: -0.9344250680674181\n",
      "Epoch: 704 Loss: 0.5979350296334706Weight 1: 0.9579627243270158 Weight 2: 0.6664471966057968 Bias: -0.9349144898097711\n",
      "Epoch: 705 Loss: 0.5979041150017244Weight 1: 0.9582208656713046 Weight 2: 0.6665050396767763 Bias: -0.9354030595902906\n",
      "Epoch: 706 Loss: 0.5978732620476177Weight 1: 0.9584793157111698 Weight 2: 0.6665633621642415 Bias: -0.9358907804788352\n",
      "Epoch: 707 Loss: 0.5978424703487207Weight 1: 0.9587380732487065 Weight 2: 0.6666221619496002 Bias: -0.9363776555335316\n",
      "Epoch: 708 Loss: 0.597811739485805Weight 1: 0.9589971370905722 Weight 2: 0.6666814369224089 Bias: -0.9368636878008184\n",
      "Epoch: 709 Loss: 0.5977810690428186Weight 1: 0.9592565060479697 Weight 2: 0.6667411849803427 Bias: -0.9373488803154909\n",
      "Epoch: 710 Loss: 0.5977504586068624Weight 1: 0.9595161789366303 Weight 2: 0.6668014040291659 Bias: -0.9378332361007448\n",
      "Epoch: 711 Loss: 0.5977199077681659Weight 1: 0.9597761545767964 Weight 2: 0.6668620919827014 Bias: -0.9383167581682202\n",
      "Epoch: 712 Loss: 0.597689416120063Weight 1: 0.9600364317932052 Weight 2: 0.6669232467628019 Bias: -0.9387994495180458\n",
      "Epoch: 713 Loss: 0.5976589832589686Weight 1: 0.9602970094150711 Weight 2: 0.66698486629932 Bias: -0.9392813131388819\n",
      "Epoch: 714 Loss: 0.5976286087843555Weight 1: 0.9605578862760698 Weight 2: 0.6670469485300785 Bias: -0.9397623520079643\n",
      "Epoch: 715 Loss: 0.5975982922987306Weight 1: 0.9608190612143207 Weight 2: 0.6671094914008416 Bias: -0.9402425690911477\n",
      "Epoch: 716 Loss: 0.5975680334076111Weight 1: 0.961080533072371 Weight 2: 0.6671724928652852 Bias: -0.9407219673429483\n",
      "Epoch: 717 Loss: 0.5975378317195031Weight 1: 0.9613423006971784 Weight 2: 0.6672359508849678 Bias: -0.9412005497065877\n",
      "Epoch: 718 Loss: 0.5975076868458783Weight 1: 0.9616043629400951 Weight 2: 0.6672998634293015 Bias: -0.941678319114035\n",
      "Epoch: 719 Loss: 0.59747759840115Weight 1: 0.961866718656851 Weight 2: 0.6673642284755229 Bias: -0.9421552784860497\n",
      "Epoch: 720 Loss: 0.5974475660026523Weight 1: 0.9621293667075375 Weight 2: 0.6674290440086644 Bias: -0.9426314307322247\n",
      "Epoch: 721 Loss: 0.5974175892706175Weight 1: 0.9623923059565906 Weight 2: 0.6674943080215255 Bias: -0.943106778751028\n",
      "Epoch: 722 Loss: 0.5973876678281531Weight 1: 0.9626555352727755 Weight 2: 0.6675600185146437 Bias: -0.9435813254298456\n",
      "Epoch: 723 Loss: 0.5973578013012214Weight 1: 0.9629190535291692 Weight 2: 0.6676261734962662 Bias: -0.9440550736450233\n",
      "Epoch: 724 Loss: 0.5973279893186157Weight 1: 0.9631828596031452 Weight 2: 0.6676927709823214 Bias: -0.9445280262619085\n",
      "Epoch: 725 Loss: 0.5972982315119407Weight 1: 0.9634469523763569 Weight 2: 0.6677598089963903 Bias: -0.9450001861348922\n",
      "Epoch: 726 Loss: 0.5972685275155899Weight 1: 0.9637113307347217 Weight 2: 0.6678272855696785 Bias: -0.945471556107451\n",
      "Epoch: 727 Loss: 0.5972388769667245Weight 1: 0.9639759935684047 Weight 2: 0.6678951987409878 Bias: -0.9459421390121879\n",
      "Epoch: 728 Loss: 0.5972092795052525Weight 1: 0.964240939771803 Weight 2: 0.667963546556688 Bias: -0.9464119376708742\n",
      "Epoch: 729 Loss: 0.5971797347738071Weight 1: 0.9645061682435297 Weight 2: 0.6680323270706889 Bias: -0.9468809548944904\n",
      "Epoch: 730 Loss: 0.5971502424177274Weight 1: 0.9647716778863981 Weight 2: 0.6681015383444125 Bias: -0.9473491934832675\n",
      "Epoch: 731 Loss: 0.5971208020850359Weight 1: 0.9650374676074053 Weight 2: 0.6681711784467652 Bias: -0.9478166562267278\n",
      "Epoch: 732 Loss: 0.5970914134264194Weight 1: 0.9653035363177174 Weight 2: 0.6682412454541098 Bias: -0.9482833459037256\n",
      "Epoch: 733 Loss: 0.5970620760952072Weight 1: 0.965569882932653 Weight 2: 0.6683117374502379 Bias: -0.948749265282488\n",
      "Epoch: 734 Loss: 0.5970327897473531Weight 1: 0.965836506371668 Weight 2: 0.6683826525263425 Bias: -0.9492144171206551\n",
      "Epoch: 735 Loss: 0.5970035540414135Weight 1: 0.9661034055583397 Weight 2: 0.6684539887809906 Bias: -0.9496788041653207\n",
      "Epoch: 736 Loss: 0.5969743686385276Weight 1: 0.9663705794203516 Weight 2: 0.6685257443200954 Bias: -0.950142429153072\n",
      "Epoch: 737 Loss: 0.5969452332023995Weight 1: 0.9666380268894778 Weight 2: 0.6685979172568894 Bias: -0.9506052948100302\n",
      "Epoch: 738 Loss: 0.5969161473992762Weight 1: 0.9669057469015669 Weight 2: 0.6686705057118973 Bias: -0.95106740385189\n",
      "Epoch: 739 Loss: 0.5968871108979301Weight 1: 0.967173738396528 Weight 2: 0.6687435078129085 Bias: -0.9515287589839594\n",
      "Epoch: 740 Loss: 0.5968581233696386Weight 1: 0.967442000318314 Weight 2: 0.6688169216949501 Bias: -0.9519893629011993\n",
      "Epoch: 741 Loss: 0.5968291844881651Weight 1: 0.9677105316149072 Weight 2: 0.6688907455002605 Bias: -0.9524492182882632\n",
      "Epoch: 742 Loss: 0.5968002939297407Weight 1: 0.9679793312383037 Weight 2: 0.6689649773782622 Bias: -0.9529083278195362\n",
      "Epoch: 743 Loss: 0.5967714513730445Weight 1: 0.9682483981444986 Weight 2: 0.669039615485535 Bias: -0.9533666941591742\n",
      "Epoch: 744 Loss: 0.5967426564991861Weight 1: 0.9685177312934703 Weight 2: 0.6691146579857896 Bias: -0.9538243199611434\n",
      "Epoch: 745 Loss: 0.596713908991685Weight 1: 0.968787329649166 Weight 2: 0.6691901030498407 Bias: -0.9542812078692584\n",
      "Epoch: 746 Loss: 0.596685208536454Weight 1: 0.9690571921794865 Weight 2: 0.6692659488555811 Bias: -0.9547373605172216\n",
      "Epoch: 747 Loss: 0.5966565548217813Weight 1: 0.969327317856271 Weight 2: 0.6693421935879548 Bias: -0.9551927805286615\n",
      "Epoch: 748 Loss: 0.5966279475383096Weight 1: 0.9695977056552828 Weight 2: 0.6694188354389308 Bias: -0.9556474705171714\n",
      "Epoch: 749 Loss: 0.5965993863790211Weight 1: 0.9698683545561939 Weight 2: 0.6694958726074772 Bias: -0.9561014330863473\n",
      "Epoch: 750 Loss: 0.5965708710392185Weight 1: 0.9701392635425705 Weight 2: 0.669573303299535 Bias: -0.9565546708298266\n",
      "Epoch: 751 Loss: 0.5965424012165067Weight 1: 0.9704104316018582 Weight 2: 0.6696511257279919 Bias: -0.9570071863313258\n",
      "Epoch: 752 Loss: 0.5965139766107762Weight 1: 0.9706818577253674 Weight 2: 0.6697293381126564 Bias: -0.9574589821646784\n",
      "Epoch: 753 Loss: 0.596485596924185Weight 1: 0.9709535409082584 Weight 2: 0.6698079386802324 Bias: -0.957910060893873\n",
      "Epoch: 754 Loss: 0.596457261861141Weight 1: 0.971225480149527 Weight 2: 0.6698869256642926 Bias: -0.9583604250730906\n",
      "Epoch: 755 Loss: 0.5964289711282864Weight 1: 0.9714976744519904 Weight 2: 0.6699662973052539 Bias: -0.9588100772467422\n",
      "Epoch: 756 Loss: 0.5964007244344782Weight 1: 0.9717701228222718 Weight 2: 0.6700460518503509 Bias: -0.959259019949506\n",
      "Epoch: 757 Loss: 0.5963725214907736Weight 1: 0.9720428242707868 Weight 2: 0.6701261875536111 Bias: -0.9597072557063652\n",
      "Epoch: 758 Loss: 0.5963443620104117Weight 1: 0.9723157778117287 Weight 2: 0.670206702675829 Bias: -0.9601547870326442\n",
      "Epoch: 759 Loss: 0.5963162457087973Weight 1: 0.9725889824630541 Weight 2: 0.6702875954845414 Bias: -0.9606016164340463\n",
      "Epoch: 760 Loss: 0.5962881723034845Weight 1: 0.972862437246469 Weight 2: 0.6703688642540014 Bias: -0.9610477464066901\n",
      "Epoch: 761 Loss: 0.5962601415141605Weight 1: 0.9731361411874141 Weight 2: 0.670450507265154 Bias: -0.9614931794371462\n",
      "Epoch: 762 Loss: 0.596232153062628Weight 1: 0.9734100933150509 Weight 2: 0.6705325228056105 Bias: -0.961937918002474\n",
      "Epoch: 763 Loss: 0.5962042066727904Weight 1: 0.9736842926622477 Weight 2: 0.6706149091696241 Bias: -0.9623819645702578\n",
      "Epoch: 764 Loss: 0.5961763020706358Weight 1: 0.9739587382655652 Weight 2: 0.6706976646580645 Bias: -0.9628253215986433\n",
      "Epoch: 765 Loss: 0.59614843898422Weight 1: 0.9742334291652431 Weight 2: 0.6707807875783934 Bias: -0.9632679915363737\n",
      "Epoch: 766 Loss: 0.5961206171436517Weight 1: 0.9745083644051854 Weight 2: 0.6708642762446401 Bias: -0.9637099768228252\n",
      "Epoch: 767 Loss: 0.5960928362810758Weight 1: 0.9747835430329469 Weight 2: 0.6709481289773761 Bias: -0.964151279888044\n",
      "Epoch: 768 Loss: 0.5960650961306592Weight 1: 0.9750589640997194 Weight 2: 0.6710323441036913 Bias: -0.9645919031527809\n",
      "Epoch: 769 Loss: 0.5960373964285739Weight 1: 0.9753346266603176 Weight 2: 0.6711169199571693 Bias: -0.9650318490285275\n",
      "Epoch: 770 Loss: 0.5960097369129831Weight 1: 0.9756105297731656 Weight 2: 0.6712018548778629 Bias: -0.9654711199175513\n",
      "Epoch: 771 Loss: 0.5959821173240241Weight 1: 0.9758866725002833 Weight 2: 0.6712871472122702 Bias: -0.9659097182129317\n",
      "Epoch: 772 Loss: 0.5959545374037957Weight 1: 0.9761630539072721 Weight 2: 0.6713727953133102 Bias: -0.9663476462985946\n",
      "Epoch: 773 Loss: 0.5959269968963409Weight 1: 0.9764396730633021 Weight 2: 0.6714587975402986 Bias: -0.9667849065493476\n",
      "Epoch: 774 Loss: 0.5958994955476334Weight 1: 0.9767165290410983 Weight 2: 0.671545152258924 Bias: -0.9672215013309151\n",
      "Epoch: 775 Loss: 0.5958720331055622Weight 1: 0.9769936209169265 Weight 2: 0.6716318578412238 Bias: -0.9676574329999731\n",
      "Epoch: 776 Loss: 0.5958446093199176Weight 1: 0.9772709477705808 Weight 2: 0.6717189126655607 Bias: -0.9680927039041837\n",
      "Epoch: 777 Loss: 0.595817223942376Weight 1: 0.9775485086853694 Weight 2: 0.6718063151165985 Bias: -0.96852731638223\n",
      "Epoch: 778 Loss: 0.5957898767264859Weight 1: 0.9778263027481016 Weight 2: 0.6718940635852787 Bias: -0.9689612727638502\n",
      "Epoch: 779 Loss: 0.5957625674276529Weight 1: 0.9781043290490745 Weight 2: 0.6719821564687968 Bias: -0.9693945753698723\n",
      "Epoch: 780 Loss: 0.5957352958031269Weight 1: 0.9783825866820598 Weight 2: 0.6720705921705787 Bias: -0.9698272265122476\n",
      "Epoch: 781 Loss: 0.5957080616119866Weight 1: 0.9786610747442901 Weight 2: 0.6721593691002576 Bias: -0.9702592284940857\n",
      "Epoch: 782 Loss: 0.595680864615126Weight 1: 0.9789397923364463 Weight 2: 0.6722484856736505 Bias: -0.9706905836096876\n",
      "Epoch: 783 Loss: 0.5956537045752414Weight 1: 0.9792187385626443 Weight 2: 0.6723379403127346 Bias: -0.97112129414458\n",
      "Epoch: 784 Loss: 0.5956265812568156Weight 1: 0.9794979125304218 Weight 2: 0.672427731445625 Bias: -0.9715513623755487\n",
      "Epoch: 785 Loss: 0.5955994944261064Weight 1: 0.9797773133507254 Weight 2: 0.6725178575065502 Bias: -0.9719807905706723\n",
      "Epoch: 786 Loss: 0.5955724438511315Weight 1: 0.9800569401378976 Weight 2: 0.6726083169358308 Bias: -0.9724095809893556\n",
      "Epoch: 787 Loss: 0.5955454293016563Weight 1: 0.9803367920096637 Weight 2: 0.6726991081798551 Bias: -0.9728377358823628\n",
      "Epoch: 788 Loss: 0.5955184505491794Weight 1: 0.9806168680871193 Weight 2: 0.6727902296910571 Bias: -0.9732652574918509\n",
      "Epoch: 789 Loss: 0.5954915073669196Weight 1: 0.9808971674947173 Weight 2: 0.6728816799278934 Bias: -0.9736921480514026\n",
      "Epoch: 790 Loss: 0.5954645995298036Weight 1: 0.9811776893602547 Weight 2: 0.6729734573548206 Bias: -0.974118409786059\n",
      "Epoch: 791 Loss: 0.5954377268144517Weight 1: 0.9814584328148606 Weight 2: 0.6730655604422727 Bias: -0.974544044912353\n",
      "Epoch: 792 Loss: 0.5954108889991662Weight 1: 0.9817393969929828 Weight 2: 0.6731579876666386 Bias: -0.9749690556383415\n",
      "Epoch: 793 Loss: 0.5953840858639169Weight 1: 0.9820205810323758 Weight 2: 0.6732507375102394 Bias: -0.9753934441636379\n",
      "Epoch: 794 Loss: 0.5953573171903299Weight 1: 0.9823019840740875 Weight 2: 0.6733438084613067 Bias: -0.9758172126794451\n",
      "Epoch: 795 Loss: 0.5953305827616743Weight 1: 0.9825836052624475 Weight 2: 0.6734371990139595 Bias: -0.9762403633685872\n",
      "Epoch: 796 Loss: 0.595303882362849Weight 1: 0.9828654437450536 Weight 2: 0.6735309076681824 Bias: -0.9766628984055421\n",
      "Epoch: 797 Loss: 0.5952772157803718Weight 1: 0.9831474986727602 Weight 2: 0.6736249329298034 Bias: -0.9770848199564732\n",
      "Epoch: 798 Loss: 0.5952505828023654Weight 1: 0.9834297691996654 Weight 2: 0.6737192733104721 Bias: -0.9775061301792619\n",
      "Epoch: 799 Loss: 0.5952239832185465Weight 1: 0.9837122544830988 Weight 2: 0.6738139273276373 Bias: -0.9779268312235389\n",
      "Epoch: 800 Loss: 0.5951974168202117Weight 1: 0.9839949536836092 Weight 2: 0.6739088935045255 Bias: -0.9783469252307162\n",
      "Epoch: 801 Loss: 0.5951708834002282Weight 1: 0.9842778659649521 Weight 2: 0.6740041703701188 Bias: -0.9787664143340187\n",
      "Epoch: 802 Loss: 0.5951443827530188Weight 1: 0.9845609904940777 Weight 2: 0.6740997564591333 Bias: -0.9791853006585156\n",
      "Epoch: 803 Loss: 0.5951179146745529Weight 1: 0.9848443264411187 Weight 2: 0.6741956503119975 Bias: -0.9796035863211519\n",
      "Epoch: 804 Loss: 0.5950914789623319Weight 1: 0.9851278729793781 Weight 2: 0.6742918504748303 Bias: -0.9800212734307792\n",
      "Epoch: 805 Loss: 0.5950650754153798Weight 1: 0.985411629285317 Weight 2: 0.6743883554994204 Bias: -0.9804383640881874\n",
      "Epoch: 806 Loss: 0.5950387038342297Weight 1: 0.9856955945385426 Weight 2: 0.674485163943204 Bias: -0.9808548603861356\n",
      "Epoch: 807 Loss: 0.595012364020914Weight 1: 0.9859797679217964 Weight 2: 0.6745822743692439 Bias: -0.9812707644093824\n",
      "Epoch: 808 Loss: 0.5949860557789516Weight 1: 0.986264148620942 Weight 2: 0.6746796853462079 Bias: -0.9816860782347178\n",
      "Epoch: 809 Loss: 0.5949597789133371Weight 1: 0.9865487358249533 Weight 2: 0.6747773954483481 Bias: -0.9821008039309925\n",
      "Epoch: 810 Loss: 0.5949335332305293Weight 1: 0.9868335287259024 Weight 2: 0.6748754032554793 Bias: -0.9825149435591497\n",
      "Epoch: 811 Loss: 0.5949073185384401Weight 1: 0.9871185265189479 Weight 2: 0.6749737073529584 Bias: -0.9829284991722547\n",
      "Epoch: 812 Loss: 0.594881134646424Weight 1: 0.9874037284023236 Weight 2: 0.6750723063316627 Bias: -0.9833414728155255\n",
      "Epoch: 813 Loss: 0.5948549813652656Weight 1: 0.9876891335773258 Weight 2: 0.6751711987879702 Bias: -0.9837538665263632\n",
      "Epoch: 814 Loss: 0.5948288585071703Weight 1: 0.9879747412483023 Weight 2: 0.6752703833237375 Bias: -0.9841656823343816\n",
      "Epoch: 815 Loss: 0.5948027658857519Weight 1: 0.9882605506226406 Weight 2: 0.67536985854628 Bias: -0.9845769222614377\n",
      "Epoch: 816 Loss: 0.5947767033160235Weight 1: 0.9885465609107561 Weight 2: 0.6754696230683508 Bias: -0.984987588321661\n",
      "Epoch: 817 Loss: 0.5947506706143855Weight 1: 0.9888327713260808 Weight 2: 0.6755696755081202 Bias: -0.985397682521484\n",
      "Epoch: 818 Loss: 0.5947246675986153Weight 1: 0.9891191810850515 Weight 2: 0.6756700144891553 Bias: -0.985807206859671\n",
      "Epoch: 819 Loss: 0.5946986940878567Weight 1: 0.9894057894070984 Weight 2: 0.6757706386403993 Bias: -0.9862161633273484\n",
      "Epoch: 820 Loss: 0.5946727499026102Weight 1: 0.9896925955146341 Weight 2: 0.6758715465961513 Bias: -0.9866245539080334\n",
      "Epoch: 821 Loss: 0.5946468348647218Weight 1: 0.9899795986330412 Weight 2: 0.6759727369960462 Bias: -0.9870323805776638\n",
      "Epoch: 822 Loss: 0.5946209487973729Weight 1: 0.990266797990662 Weight 2: 0.6760742084850341 Bias: -0.9874396453046272\n",
      "Epoch: 823 Loss: 0.5945950915250701Weight 1: 0.9905541928187865 Weight 2: 0.6761759597133603 Bias: -0.9878463500497897\n",
      "Epoch: 824 Loss: 0.5945692628736354Weight 1: 0.9908417823516416 Weight 2: 0.6762779893365455 Bias: -0.988252496766525\n",
      "Epoch: 825 Loss: 0.5945434626701954Weight 1: 0.9911295658263792 Weight 2: 0.6763802960153653 Bias: -0.9886580874007437\n",
      "Epoch: 826 Loss: 0.5945176907431725Weight 1: 0.9914175424830659 Weight 2: 0.6764828784158308 Bias: -0.9890631238909213\n",
      "Epoch: 827 Loss: 0.5944919469222736Weight 1: 0.991705711564671 Weight 2: 0.6765857352091683 Bias: -0.9894676081681275\n",
      "Epoch: 828 Loss: 0.5944662310384813Weight 1: 0.9919940723170562 Weight 2: 0.6766888650717998 Bias: -0.9898715421560544\n",
      "Epoch: 829 Loss: 0.5944405429240438Weight 1: 0.9922826239889636 Weight 2: 0.6767922666853232 Bias: -0.9902749277710451\n",
      "Epoch: 830 Loss: 0.5944148824124651Weight 1: 0.9925713658320056 Weight 2: 0.6768959387364927 Bias: -0.9906777669221217\n",
      "Epoch: 831 Loss: 0.5943892493384957Weight 1: 0.9928602971006533 Weight 2: 0.676999879917199 Bias: -0.991080061511014\n",
      "Epoch: 832 Loss: 0.5943636435381227Weight 1: 0.9931494170522259 Weight 2: 0.6771040889244503 Bias: -0.9914818134321872\n",
      "Epoch: 833 Loss: 0.5943380648485608Weight 1: 0.9934387249468797 Weight 2: 0.6772085644603524 Bias: -0.99188302457287\n",
      "Epoch: 834 Loss: 0.5943125131082424Weight 1: 0.993728220047597 Weight 2: 0.6773133052320895 Bias: -0.9922836968130826\n",
      "Epoch: 835 Loss: 0.5942869881568084Weight 1: 0.9940179016201756 Weight 2: 0.6774183099519052 Bias: -0.9926838320256643\n",
      "Epoch: 836 Loss: 0.5942614898350997Weight 1: 0.9943077689332179 Weight 2: 0.6775235773370828 Bias: -0.9930834320763016\n",
      "Epoch: 837 Loss: 0.5942360179851474Weight 1: 0.9945978212581204 Weight 2: 0.6776291061099265 Bias: -0.993482498823555\n",
      "Epoch: 838 Loss: 0.5942105724501631Weight 1: 0.9948880578690623 Weight 2: 0.6777348949977423 Bias: -0.9938810341188873\n",
      "Epoch: 839 Loss: 0.5941851530745307Weight 1: 0.9951784780429958 Weight 2: 0.6778409427328187 Bias: -0.9942790398066905\n",
      "Epoch: 840 Loss: 0.5941597597037978Weight 1: 0.9954690810596346 Weight 2: 0.6779472480524081 Bias: -0.9946765177243132\n",
      "Epoch: 841 Loss: 0.5941343921846653Weight 1: 0.9957598662014442 Weight 2: 0.6780538096987081 Bias: -0.9950734697020877\n",
      "Epoch: 842 Loss: 0.5941090503649803Weight 1: 0.9960508327536304 Weight 2: 0.6781606264188421 Bias: -0.9954698975633568\n",
      "Epoch: 843 Loss: 0.5940837340937268Weight 1: 0.9963419800041295 Weight 2: 0.6782676969648411 Bias: -0.9958658031245016\n",
      "Epoch: 844 Loss: 0.5940584432210158Weight 1: 0.9966333072435979 Weight 2: 0.6783750200936248 Bias: -0.9962611881949672\n",
      "Epoch: 845 Loss: 0.5940331775980782Weight 1: 0.9969248137654009 Weight 2: 0.6784825945669831 Bias: -0.9966560545772906\n",
      "Epoch: 846 Loss: 0.5940079370772561Weight 1: 0.997216498865603 Weight 2: 0.6785904191515575 Bias: -0.9970504040671262\n",
      "Epoch: 847 Loss: 0.5939827215119928Weight 1: 0.9975083618429577 Weight 2: 0.6786984926188229 Bias: -0.9974442384532733\n",
      "Epoch: 848 Loss: 0.5939575307568267Weight 1: 0.9978004019988963 Weight 2: 0.6788068137450687 Bias: -0.9978375595177021\n",
      "Epoch: 849 Loss: 0.5939323646673812Weight 1: 0.9980926186375189 Weight 2: 0.6789153813113812 Bias: -0.99823036903558\n",
      "Epoch: 850 Loss: 0.5939072231003564Weight 1: 0.9983850110655829 Weight 2: 0.6790241941036247 Bias: -0.9986226687752979\n",
      "Epoch: 851 Loss: 0.5938821059135223Weight 1: 0.9986775785924937 Weight 2: 0.6791332509124237 Bias: -0.9990144604984966\n",
      "Epoch: 852 Loss: 0.5938570129657091Weight 1: 0.9989703205302943 Weight 2: 0.6792425505331448 Bias: -0.9994057459600924\n",
      "Epoch: 853 Loss: 0.5938319441168002Weight 1: 0.999263236193655 Weight 2: 0.6793520917658781 Bias: -0.9997965269083033\n",
      "Epoch: 854 Loss: 0.5938068992277232Weight 1: 0.9995563248998635 Weight 2: 0.6794618734154201 Bias: -1.000186805084675\n",
      "Epoch: 855 Loss: 0.5937818781604421Weight 1: 0.9998495859688149 Weight 2: 0.6795718942912551 Bias: -1.0005765822241062\n",
      "Epoch: 856 Loss: 0.5937568807779509Weight 1: 1.0001430187230016 Weight 2: 0.6796821532075376 Bias: -1.0009658600548748\n",
      "Epoch: 857 Loss: 0.5937319069442628Weight 1: 1.0004366224875034 Weight 2: 0.6797926489830746 Bias: -1.0013546402986628\n",
      "Epoch: 858 Loss: 0.5937069565244054Weight 1: 1.0007303965899776 Weight 2: 0.6799033804413076 Bias: -1.0017429246705825\n",
      "Epoch: 859 Loss: 0.5936820293844111Weight 1: 1.0010243403606491 Weight 2: 0.6800143464102953 Bias: -1.0021307148792011\n",
      "Epoch: 860 Loss: 0.5936571253913099Weight 1: 1.0013184531323005 Weight 2: 0.6801255457226959 Bias: -1.0025180126265665\n",
      "Epoch: 861 Loss: 0.593632244413122Weight 1: 1.001612734240262 Weight 2: 0.6802369772157493 Bias: -1.0029048196082322\n",
      "Epoch: 862 Loss: 0.59360738631885Weight 1: 1.0019071830224024 Weight 2: 0.68034863973126 Bias: -1.0032911375132827\n",
      "Epoch: 863 Loss: 0.5935825509784712Weight 1: 1.002201798819119 Weight 2: 0.6804605321155797 Bias: -1.0036769680243576\n",
      "Epoch: 864 Loss: 0.5935577382629311Weight 1: 1.002496580973327 Weight 2: 0.6805726532195896 Bias: -1.0040623128176778\n",
      "Epoch: 865 Loss: 0.5935329480441344Weight 1: 1.0027915288304519 Weight 2: 0.6806850018986835 Bias: -1.004447173563069\n",
      "Epoch: 866 Loss: 0.5935081801949393Weight 1: 1.0030866417384174 Weight 2: 0.6807975770127506 Bias: -1.0048315519239872\n",
      "Epoch: 867 Loss: 0.5934834345891491Weight 1: 1.0033819190476378 Weight 2: 0.680910377426158 Bias: -1.0052154495575432\n",
      "Epoch: 868 Loss: 0.5934587111015052Weight 1: 1.0036773601110074 Weight 2: 0.6810234020077341 Bias: -1.0055988681145265\n",
      "Epoch: 869 Loss: 0.5934340096076806Weight 1: 1.0039729642838913 Weight 2: 0.6811366496307514 Bias: -1.0059818092394304\n",
      "Epoch: 870 Loss: 0.5934093299842719Weight 1: 1.0042687309241158 Weight 2: 0.6812501191729092 Bias: -1.006364274570476\n",
      "Epoch: 871 Loss: 0.593384672108793Weight 1: 1.0045646593919595 Weight 2: 0.6813638095163174 Bias: -1.0067462657396364\n",
      "Epoch: 872 Loss: 0.5933600358596668Weight 1: 1.0048607490501427 Weight 2: 0.681477719547479 Bias: -1.0071277843726612\n",
      "Epoch: 873 Loss: 0.59333542111622Weight 1: 1.0051569992638192 Weight 2: 0.6815918481572741 Bias: -1.0075088320890995\n",
      "Epoch: 874 Loss: 0.5933108277586754Weight 1: 1.0054534094005667 Weight 2: 0.6817061942409424 Bias: -1.0078894105023253\n",
      "Epoch: 875 Loss: 0.5932862556681445Weight 1: 1.0057499788303768 Weight 2: 0.6818207566980669 Bias: -1.00826952121956\n",
      "Epoch: 876 Loss: 0.5932617047266211Weight 1: 1.0060467069256465 Weight 2: 0.6819355344325575 Bias: -1.0086491658418972\n",
      "Epoch: 877 Loss: 0.5932371748169755Weight 1: 1.0063435930611688 Weight 2: 0.6820505263526345 Bias: -1.0090283459643254\n",
      "Epoch: 878 Loss: 0.593212665822946Weight 1: 1.0066406366141234 Weight 2: 0.6821657313708117 Bias: -1.0094070631757526\n",
      "Epoch: 879 Loss: 0.593188177629134Weight 1: 1.0069378369640671 Weight 2: 0.6822811484038804 Bias: -1.009785319059029\n",
      "Epoch: 880 Loss: 0.5931637101209962Weight 1: 1.0072351934929258 Weight 2: 0.6823967763728932 Bias: -1.0101631151909705\n",
      "Epoch: 881 Loss: 0.5931392631848383Weight 1: 1.0075327055849843 Weight 2: 0.6825126142031471 Bias: -1.0105404531423823\n",
      "Epoch: 882 Loss: 0.59311483670781Weight 1: 1.007830372626878 Weight 2: 0.6826286608241681 Bias: -1.0109173344780822\n",
      "Epoch: 883 Loss: 0.5930904305778952Weight 1: 1.008128194007583 Weight 2: 0.6827449151696944 Bias: -1.0112937607569232\n",
      "Epoch: 884 Loss: 0.5930660446839094Weight 1: 1.0084261691184082 Weight 2: 0.6828613761776607 Bias: -1.0116697335318168\n",
      "Epoch: 885 Loss: 0.5930416789154912Weight 1: 1.0087242973529855 Weight 2: 0.682978042790182 Bias: -1.012045254349756\n",
      "Epoch: 886 Loss: 0.5930173331630957Weight 1: 1.0090225781072613 Weight 2: 0.6830949139535378 Bias: -1.0124203247518384\n",
      "Epoch: 887 Loss: 0.5929930073179904Weight 1: 1.0093210107794872 Weight 2: 0.6832119886181559 Bias: -1.0127949462732884\n",
      "Epoch: 888 Loss: 0.5929687012722467Weight 1: 1.009619594770212 Weight 2: 0.6833292657385969 Bias: -1.0131691204434803\n",
      "Epoch: 889 Loss: 0.5929444149187344Weight 1: 1.0099183294822718 Weight 2: 0.683446744273538 Bias: -1.0135428487859608\n",
      "Epoch: 890 Loss: 0.5929201481511166Weight 1: 1.010217214320782 Weight 2: 0.6835644231857578 Bias: -1.0139161328184714\n",
      "Epoch: 891 Loss: 0.5928959008638425Weight 1: 1.010516248693128 Weight 2: 0.6836823014421202 Bias: -1.0142889740529708\n",
      "Epoch: 892 Loss: 0.5928716729521419Weight 1: 1.010815432008957 Weight 2: 0.6838003780135589 Bias: -1.0146613739956576\n",
      "Epoch: 893 Loss: 0.5928474643120197Weight 1: 1.011114763680169 Weight 2: 0.6839186518750618 Bias: -1.0150333341469924\n",
      "Epoch: 894 Loss: 0.5928232748402482Weight 1: 1.0114142431209079 Weight 2: 0.6840371220056559 Bias: -1.0154048560017195\n",
      "Epoch: 895 Loss: 0.5927991044343637Weight 1: 1.0117138697475538 Weight 2: 0.6841557873883912 Bias: -1.0157759410488894\n",
      "Epoch: 896 Loss: 0.5927749529926584Weight 1: 1.0120136429787132 Weight 2: 0.6842746470103259 Bias: -1.016146590771881\n",
      "Epoch: 897 Loss: 0.5927508204141765Weight 1: 1.0123135622352113 Weight 2: 0.6843936998625106 Bias: -1.0165168066484231\n",
      "Epoch: 898 Loss: 0.5927267065987074Weight 1: 1.0126136269400832 Weight 2: 0.6845129449399735 Bias: -1.0168865901506166\n",
      "Epoch: 899 Loss: 0.5927026114467797Weight 1: 1.0129138365185655 Weight 2: 0.6846323812417048 Bias: -1.0172559427449555\n",
      "Epoch: 900 Loss: 0.5926785348596568Weight 1: 1.0132141903980874 Weight 2: 0.6847520077706417 Bias: -1.0176248658923495\n",
      "Epoch: 901 Loss: 0.5926544767393304Weight 1: 1.013514688008263 Weight 2: 0.6848718235336535 Bias: -1.017993361048145\n",
      "Epoch: 902 Loss: 0.5926304369885144Weight 1: 1.0138153287808827 Weight 2: 0.6849918275415262 Bias: -1.018361429662147\n",
      "Epoch: 903 Loss: 0.5926064155106409Weight 1: 1.0141161121499038 Weight 2: 0.6851120188089478 Bias: -1.0187290731786398\n",
      "Epoch: 904 Loss: 0.5925824122098536Weight 1: 1.014417037551444 Weight 2: 0.6852323963544932 Bias: -1.0190962930364091\n",
      "Epoch: 905 Loss: 0.5925584269910033Weight 1: 1.0147181044237719 Weight 2: 0.6853529592006095 Bias: -1.019463090668763\n",
      "Epoch: 906 Loss: 0.5925344597596404Weight 1: 1.0150193122072984 Weight 2: 0.6854737063736008 Bias: -1.0198294675035526\n",
      "Epoch: 907 Loss: 0.5925105104220125Weight 1: 1.0153206603445697 Weight 2: 0.6855946369036142 Bias: -1.0201954249631944\n",
      "Epoch: 908 Loss: 0.5924865788850567Weight 1: 1.0156221482802583 Weight 2: 0.6857157498246242 Bias: -1.0205609644646896\n",
      "Epoch: 909 Loss: 0.5924626650563959Weight 1: 1.015923775461155 Weight 2: 0.6858370441744187 Bias: -1.0209260874196464\n",
      "Epoch: 910 Loss: 0.5924387688443327Weight 1: 1.0162255413361603 Weight 2: 0.685958518994584 Bias: -1.0212907952343004\n",
      "Epoch: 911 Loss: 0.592414890157844Weight 1: 1.016527445356277 Weight 2: 0.6860801733304908 Bias: -1.021655089309535\n",
      "Epoch: 912 Loss: 0.5923910289065767Weight 1: 1.016829486974602 Weight 2: 0.6862020062312788 Bias: -1.0220189710409027\n",
      "Epoch: 913 Loss: 0.5923671850008418Weight 1: 1.0171316656463176 Weight 2: 0.6863240167498432 Bias: -1.022382441818645\n",
      "Epoch: 914 Loss: 0.5923433583516106Weight 1: 1.0174339808286845 Weight 2: 0.68644620394282 Bias: -1.0227455030277135\n",
      "Epoch: 915 Loss: 0.5923195488705075Weight 1: 1.0177364319810331 Weight 2: 0.6865685668705713 Bias: -1.0231081560477902\n",
      "Epoch: 916 Loss: 0.5922957564698073Weight 1: 1.0180390185647554 Weight 2: 0.6866911045971718 Bias: -1.0234704022533074\n",
      "Epoch: 917 Loss: 0.5922719810624282Weight 1: 1.0183417400432977 Weight 2: 0.6868138161903937 Bias: -1.023832243013469\n",
      "Epoch: 918 Loss: 0.592248222561929Weight 1: 1.0186445958821522 Weight 2: 0.6869367007216933 Bias: -1.0241936796922695\n",
      "Epoch: 919 Loss: 0.5922244808825023Weight 1: 1.0189475855488495 Weight 2: 0.6870597572661965 Bias: -1.0245547136485151\n",
      "Epoch: 920 Loss: 0.5922007559389707Weight 1: 1.0192507085129503 Weight 2: 0.6871829849026847 Bias: -1.0249153462358433\n",
      "Epoch: 921 Loss: 0.5921770476467821Weight 1: 1.0195539642460383 Weight 2: 0.687306382713581 Bias: -1.0252755788027428\n",
      "Epoch: 922 Loss: 0.5921533559220037Weight 1: 1.0198573522217116 Weight 2: 0.6874299497849362 Bias: -1.0256354126925735\n",
      "Epoch: 923 Loss: 0.5921296806813191Weight 1: 1.0201608719155755 Weight 2: 0.6875536852064148 Bias: -1.0259948492435864\n",
      "Epoch: 924 Loss: 0.5921060218420223Weight 1: 1.0204645228052347 Weight 2: 0.6876775880712812 Bias: -1.0263538897889435\n",
      "Epoch: 925 Loss: 0.5920823793220132Weight 1: 1.0207683043702853 Weight 2: 0.6878016574763861 Bias: -1.026712535656737\n",
      "Epoch: 926 Loss: 0.5920587530397937Weight 1: 1.0210722160923076 Weight 2: 0.6879258925221525 Bias: -1.0270707881700092\n",
      "Epoch: 927 Loss: 0.5920351429144616Weight 1: 1.0213762574548582 Weight 2: 0.6880502923125621 Bias: -1.0274286486467719\n",
      "Epoch: 928 Loss: 0.5920115488657083Weight 1: 1.0216804279434626 Weight 2: 0.6881748559551415 Bias: -1.0277861184000259\n",
      "Epoch: 929 Loss: 0.5919879708138122Weight 1: 1.021984727045607 Weight 2: 0.6882995825609491 Bias: -1.0281431987377807\n",
      "Epoch: 930 Loss: 0.5919644086796348Weight 1: 1.022289154250732 Weight 2: 0.6884244712445611 Bias: -1.028499890963073\n",
      "Epoch: 931 Loss: 0.5919408623846173Weight 1: 1.0225937090502235 Weight 2: 0.688549521124058 Bias: -1.0288561963739864\n",
      "Epoch: 932 Loss: 0.5919173318507749Weight 1: 1.0228983909374065 Weight 2: 0.6886747313210115 Bias: -1.029212116263671\n",
      "Epoch: 933 Loss: 0.5918938170006929Weight 1: 1.0232031994075372 Weight 2: 0.6888001009604711 Bias: -1.0295676519203614\n",
      "Epoch: 934 Loss: 0.5918703177575223Weight 1: 1.0235081339577954 Weight 2: 0.6889256291709502 Bias: -1.0299228046273965\n",
      "Epoch: 935 Loss: 0.5918468340449755Weight 1: 1.023813194087277 Weight 2: 0.6890513150844136 Bias: -1.030277575663238\n",
      "Epoch: 936 Loss: 0.5918233657873224Weight 1: 1.0241183792969875 Weight 2: 0.6891771578362638 Bias: -1.03063196630149\n",
      "Epoch: 937 Loss: 0.5917999129093849Weight 1: 1.0244236890898337 Weight 2: 0.6893031565653277 Bias: -1.0309859778109165\n",
      "Epoch: 938 Loss: 0.591776475336535Weight 1: 1.0247291229706166 Weight 2: 0.6894293104138439 Bias: -1.0313396114554612\n",
      "Epoch: 939 Loss: 0.5917530529946876Weight 1: 1.0250346804460244 Weight 2: 0.6895556185274495 Bias: -1.0316928684942654\n",
      "Epoch: 940 Loss: 0.5917296458102992Weight 1: 1.0253403610246252 Weight 2: 0.6896820800551667 Bias: -1.0320457501816875\n",
      "Epoch: 941 Loss: 0.5917062537103613Weight 1: 1.0256461642168593 Weight 2: 0.6898086941493903 Bias: -1.0323982577673203\n",
      "Epoch: 942 Loss: 0.5916828766223993Weight 1: 1.0259520895350327 Weight 2: 0.6899354599658744 Bias: -1.0327503924960102\n",
      "Epoch: 943 Loss: 0.5916595144744643Weight 1: 1.0262581364933092 Weight 2: 0.6900623766637197 Bias: -1.0331021556078752\n",
      "Epoch: 944 Loss: 0.5916361671951337Weight 1: 1.026564304607704 Weight 2: 0.6901894434053607 Bias: -1.0334535483383236\n",
      "Epoch: 945 Loss: 0.5916128347135033Weight 1: 1.0268705933960758 Weight 2: 0.6903166593565528 Bias: -1.0338045719180717\n",
      "Epoch: 946 Loss: 0.5915895169591862Weight 1: 1.0271770023781206 Weight 2: 0.6904440236863596 Bias: -1.0341552275731623\n",
      "Epoch: 947 Loss: 0.5915662138623069Weight 1: 1.0274835310753636 Weight 2: 0.6905715355671401 Bias: -1.0345055165249821\n",
      "Epoch: 948 Loss: 0.591542925353498Weight 1: 1.027790179011153 Weight 2: 0.6906991941745363 Bias: -1.0348554399902807\n",
      "Epoch: 949 Loss: 0.5915196513638971Weight 1: 1.0280969457106528 Weight 2: 0.6908269986874603 Bias: -1.035204999181188\n",
      "Epoch: 950 Loss: 0.5914963918251422Weight 1: 1.0284038307008354 Weight 2: 0.6909549482880822 Bias: -1.0355541953052316\n",
      "Epoch: 951 Loss: 0.5914731466693672Weight 1: 1.0287108335104749 Weight 2: 0.691083042161817 Bias: -1.0359030295653555\n",
      "Epoch: 952 Loss: 0.5914499158292Weight 1: 1.0290179536701405 Weight 2: 0.6912112794973126 Bias: -1.0362515031599373\n",
      "Epoch: 953 Loss: 0.5914266992377576Weight 1: 1.0293251907121892 Weight 2: 0.6913396594864373 Bias: -1.0365996172828056\n",
      "Epoch: 954 Loss: 0.5914034968286412Weight 1: 1.029632544170759 Weight 2: 0.6914681813242672 Bias: -1.0369473731232581\n",
      "Epoch: 955 Loss: 0.591380308535935Weight 1: 1.029940013581762 Weight 2: 0.6915968442090743 Bias: -1.037294771866079\n",
      "Epoch: 956 Loss: 0.5913571342942009Weight 1: 1.0302475984828778 Weight 2: 0.6917256473423138 Bias: -1.037641814691556\n",
      "Epoch: 957 Loss: 0.5913339740384749Weight 1: 1.0305552984135464 Weight 2: 0.6918545899286122 Bias: -1.0379885027754985\n",
      "Epoch: 958 Loss: 0.5913108277042644Weight 1: 1.0308631129149617 Weight 2: 0.691983671175755 Bias: -1.0383348372892536\n",
      "Epoch: 959 Loss: 0.5912876952275435Weight 1: 1.0311710415300643 Weight 2: 0.6921128902946746 Bias: -1.038680819399725\n",
      "Epoch: 960 Loss: 0.5912645765447504Weight 1: 1.0314790838035355 Weight 2: 0.6922422464994381 Bias: -1.039026450269389\n",
      "Epoch: 961 Loss: 0.591241471592783Weight 1: 1.03178723928179 Weight 2: 0.6923717390072355 Bias: -1.0393717310563113\n",
      "Epoch: 962 Loss: 0.591218380308996Weight 1: 1.0320955075129694 Weight 2: 0.6925013670383675 Bias: -1.0397166629141659\n",
      "Epoch: 963 Loss: 0.5911953026311972Weight 1: 1.0324038880469357 Weight 2: 0.6926311298162336 Bias: -1.0400612469922497\n",
      "Epoch: 964 Loss: 0.5911722384976446Weight 1: 1.0327123804352647 Weight 2: 0.6927610265673204 Bias: -1.0404054844355013\n",
      "Epoch: 965 Loss: 0.5911491878470415Weight 1: 1.0330209842312388 Weight 2: 0.6928910565211892 Bias: -1.0407493763845168\n",
      "Epoch: 966 Loss: 0.591126150618535Weight 1: 1.0333296989898413 Weight 2: 0.693021218910465 Bias: -1.0410929239755669\n",
      "Epoch: 967 Loss: 0.5911031267517111Weight 1: 1.0336385242677493 Weight 2: 0.6931515129708239 Bias: -1.0414361283406133\n",
      "Epoch: 968 Loss: 0.5910801161865921Weight 1: 1.0339474596233273 Weight 2: 0.693281937940982 Bias: -1.041778990607326\n",
      "Epoch: 969 Loss: 0.5910571188636331Weight 1: 1.034256504616621 Weight 2: 0.6934124930626836 Bias: -1.0421215118990996\n",
      "Epoch: 970 Loss: 0.5910341347237191Weight 1: 1.0345656588093501 Weight 2: 0.6935431775806892 Bias: -1.0424636933350695\n",
      "Epoch: 971 Loss: 0.5910111637081612Weight 1: 1.034874921764903 Weight 2: 0.6936739907427643 Bias: -1.0428055360301285\n",
      "Epoch: 972 Loss: 0.5909882057586929Weight 1: 1.035184293048329 Weight 2: 0.6938049317996676 Bias: -1.0431470410949435\n",
      "Epoch: 973 Loss: 0.5909652608174681Weight 1: 1.035493772226333 Weight 2: 0.69393600000514 Bias: -1.0434882096359714\n",
      "Epoch: 974 Loss: 0.5909423288270577Weight 1: 1.035803358867269 Weight 2: 0.6940671946158924 Bias: -1.0438290427554757\n",
      "Epoch: 975 Loss: 0.5909194097304445Weight 1: 1.036113052541133 Weight 2: 0.6941985148915948 Bias: -1.0441695415515426\n",
      "Epoch: 976 Loss: 0.5908965034710236Weight 1: 1.0364228528195576 Weight 2: 0.6943299600948647 Bias: -1.044509707118097\n",
      "Epoch: 977 Loss: 0.5908736099925957Weight 1: 1.0367327592758047 Weight 2: 0.6944615294912561 Bias: -1.044849540544919\n",
      "Epoch: 978 Loss: 0.5908507292393664Weight 1: 1.0370427714847603 Weight 2: 0.6945932223492476 Bias: -1.045189042917659\n",
      "Epoch: 979 Loss: 0.5908278611559419Weight 1: 1.037352889022928 Weight 2: 0.6947250379402319 Bias: -1.0455282153178547\n",
      "Epoch: 980 Loss: 0.5908050056873262Weight 1: 1.0376631114684218 Weight 2: 0.6948569755385041 Bias: -1.0458670588229464\n",
      "Epoch: 981 Loss: 0.5907821627789187Weight 1: 1.0379734384009613 Weight 2: 0.6949890344212507 Bias: -1.0462055745062933\n",
      "Epoch: 982 Loss: 0.5907593323765105Weight 1: 1.0382838694018646 Weight 2: 0.6951212138685384 Bias: -1.0465437634371884\n",
      "Epoch: 983 Loss: 0.5907365144262812Weight 1: 1.0385944040540422 Weight 2: 0.6952535131633032 Bias: -1.0468816266808751\n",
      "Epoch: 984 Loss: 0.5907137088747968Weight 1: 1.0389050419419916 Weight 2: 0.6953859315913392 Bias: -1.0472191652985625\n",
      "Epoch: 985 Loss: 0.5906909156690063Weight 1: 1.0392157826517903 Weight 2: 0.6955184684412876 Bias: -1.0475563803474408\n",
      "Epoch: 986 Loss: 0.5906681347562389Weight 1: 1.0395266257710898 Weight 2: 0.6956511230046261 Bias: -1.0478932728806973\n",
      "Epoch: 987 Loss: 0.5906453660842005Weight 1: 1.0398375708891106 Weight 2: 0.6957838945756575 Bias: -1.0482298439475313\n",
      "Epoch: 988 Loss: 0.590622609600972Weight 1: 1.0401486175966348 Weight 2: 0.6959167824514991 Bias: -1.0485660945931696\n",
      "Epoch: 989 Loss: 0.5905998652550053Weight 1: 1.040459765486001 Weight 2: 0.696049785932072 Bias: -1.0489020258588824\n",
      "Epoch: 990 Loss: 0.590577132995121Weight 1: 1.040771014151098 Weight 2: 0.69618290432009 Bias: -1.049237638781998\n",
      "Epoch: 991 Loss: 0.590554412770506Weight 1: 1.0410823631873585 Weight 2: 0.696316136921049 Bias: -1.0495729343959184\n",
      "Epoch: 992 Loss: 0.59053170453071Weight 1: 1.0413938121917539 Weight 2: 0.6964494830432165 Bias: -1.0499079137301341\n",
      "Epoch: 993 Loss: 0.5905090082256431Weight 1: 1.0417053607627875 Weight 2: 0.6965829419976207 Bias: -1.0502425778102396\n",
      "Epoch: 994 Loss: 0.5904863238055724Weight 1: 1.0420170085004896 Weight 2: 0.69671651309804 Bias: -1.050576927657948\n",
      "Epoch: 995 Loss: 0.5904636512211209Weight 1: 1.0423287550064106 Weight 2: 0.6968501956609922 Bias: -1.0509109642911063\n",
      "Epoch: 996 Loss: 0.590440990423263Weight 1: 1.0426405998836161 Weight 2: 0.6969839890057242 Bias: -1.0512446887237106\n",
      "Epoch: 997 Loss: 0.5904183413633233Weight 1: 1.0429525427366804 Weight 2: 0.6971178924542017 Bias: -1.05157810196592\n",
      "Epoch: 998 Loss: 0.5903957039929719Weight 1: 1.043264583171681 Weight 2: 0.6972519053310983 Bias: -1.0519112050240729\n",
      "Epoch: 999 Loss: 0.5903730782642246Weight 1: 1.0435767207961923 Weight 2: 0.6973860269637852 Bias: -1.0522439989007002\n",
      "Epoch: 1000 Loss: 0.5903504641294379Weight 1: 1.043888955219281 Weight 2: 0.697520256682321 Bias: -1.0525764845945411\n"
     ]
    }
   ],
   "source": [
    "w1, w2, bias = gradient_descent(X_train_scaled['age'],\n",
    "                 X_train_scaled['affordibility'], y_train, 1000, 0.5681)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.043888955219281, 0.697520256682321, -1.0525764845945411)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without tensorflow\n",
    "w1, w2, bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.6956285], dtype=float32),\n",
       " array([0.63263583], dtype=float32),\n",
       " array([-1.1933192], dtype=float32))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with tensorflow\n",
    "coef[0], coef[1], intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f04500d8b91e362b0082c4fdd322d5d5d9540d13200024b86d78e7daf6d8bf4b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
